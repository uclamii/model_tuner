

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>iPython Notebooks &mdash; Model Tuner 0.0.15a0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=f712845e" />

  
    <link rel="canonical" href="https://uclamii.github.io/model_tuner/usage_guide.html" />
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=e34472b7"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
      <script src="_static/custom.js?v=59429b38"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Zero Variance Columns" href="caveats.html" />
    <link rel="prev" title="Welcome to Model Tuner’s Documentation!" href="getting_started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Model Tuner
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Welcome to Model Tuner’s Documentation!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">iPython Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#binary-classification-examples">Binary Classification Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-example">Regression Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#key-methods-and-functionalities">Key Methods and Functionalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="#helper-functions">Helper Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="#input-parameters">Input Parameters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#binary-classification">Binary Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#aids-clinical-trials-group-study">AIDS Clinical Trials Group Study</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-import-necessary-libraries">Step 1: Import Necessary Libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-load-the-dataset-define-x-y">Step 2: Load the dataset, define X, y</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-check-for-zero-variance-columns-and-drop-accordingly">Step 3: Check for zero-variance columns and drop accordingly</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-create-an-instance-of-the-xgbclassifier">Step 4: Create an Instance of the XGBClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-define-hyperparameters-for-xgboost">Step 5: Define Hyperparameters for XGBoost</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-6-initialize-and-configure-the-model">Step 6: Initialize and Configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-7-perform-grid-search-parameter-tuning">Step 7: Perform Grid Search Parameter Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-8-fit-the-model">Step 8: Fit the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-9-return-metrics-optional">Step 9: Return Metrics (Optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-10-calibrate-the-model-if-needed">Step 10: Calibrate the Model (if needed)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classification-report-optional">Classification Report (Optional)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#regression">Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#california-housing-with-xgboost">California Housing with XGBoost</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Step 1: Import Necessary Libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-load-the-dataset">Step 2: Load the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-create-an-instance-of-the-xgbclassifier">Step 3: Create an Instance of the XGBClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-define-hyperparameters-for-xgboost">Step 4: Define Hyperparameters for XGBoost</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-initialize-and-configure-the-model">Step 5: Initialize and Configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-6-fit-the-model">Step 6: Fit the Model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Caveats</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="caveats.html">Zero Variance Columns</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#dependent-variable">Dependent Variable</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#imputation-before-scaling">Imputation Before Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#column-stratification-with-cross-validation">Column Stratification with Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#model-calibration">Model Calibration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About Model Tuner</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">GitHub Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#acknowledgements">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#citing-model-tuner">Citing Model Tuner</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Model Tuner</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">iPython Notebooks</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="no-click"><a class="reference internal image-reference" href="_images/ModelTunerTarget.png"><img alt="Model Tuner Logo" class="align-left" src="_images/ModelTunerTarget.png" style="width: 250px;" />
</a>
</div><div style="height: 150px;"></div><p></p>
<section id="ipython-notebooks">
<h1>iPython Notebooks<a class="headerlink" href="#ipython-notebooks" title="Link to this heading"></a></h1>
<section id="binary-classification-examples">
<h2>Binary Classification Examples<a class="headerlink" href="#binary-classification-examples" title="Link to this heading"></a></h2>
<blockquote>
<div><p><strong>Google Colab Notebooks</strong></p>
<ul>
<li><a href="https://colab.research.google.com/drive/1ujLL2mRtIWwGamnpWKIo2f271_Q103t-?usp=sharing#scrollTo=uMxyy0yvd2xQ" target="_blank">Binary Classification + KFold Example: Titanic Dataset - Categorical Data</a></li>
<li><a href="https://colab.research.google.com/drive/12XywbGBiwlZIbi0C3JKu9NOQPPRgVwcp?usp=sharing#scrollTo=rm5TA__pC3M-" target="_blank">Binary Classification: AIDS Clinical Trials - Numerical Data</a></li>
</ul>
<p><strong>HTML Files</strong></p>
<ul>
<li><a href="./example_htmls/Model_Tuner_Titanic_KFold.html" target="_blank">Binary Classification + KFold Example: Titanic Dataset - Categorical Data</a></li>
<li><a href="./example_htmls/Model_Tuner_Binary_Classification_AIDS_Clinical_Trials.html" target="_blank">Binary Classification: AIDS Clinical Trials HTML File</a></li>
</ul>
</div></blockquote>
</section>
<section id="regression-example">
<h2>Regression Example<a class="headerlink" href="#regression-example" title="Link to this heading"></a></h2>
<blockquote>
<div><p><strong>Google Colab Notebook</strong></p>
<ul>
<li><a href="https://colab.research.google.com/drive/151kdlsW-WyJ0pwwt_iWpjXDuqj1Ktam_?authuser=1#scrollTo=UhfZKVoq3sAN" target="_blank">Redfin Real Estate - Los Angeles Data Colab Notebook</a></li>
</ul>
<p><strong>HTML File</strong></p>
<ul>
<li><a href="./example_htmls/Model_Tuner_Regression_Redfin_Real_Estate.html" target="_blank">Redfin Real Estate - Los Angeles Data HTML File</a></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="key-methods-and-functionalities">
<h1>Key Methods and Functionalities<a class="headerlink" href="#key-methods-and-functionalities" title="Link to this heading"></a></h1>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">__init__(...)</span></code></dt><dd><p>Initializes the model tuner with configurations, including estimator, cross-validation settings, scoring metrics, pipeline steps, feature selection, imbalance sampler, Bayesian search, and model calibration options.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">reset_estimator()</span></code></dt><dd><p>Resets the estimator and pipeline configuration.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">process_imbalance_sampler(X_train,</span> <span class="pre">y_train)</span></code></dt><dd><p>Processes the imbalance sampler, applying it to resample the training data.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">calibrateModel(X,</span> <span class="pre">y,</span> <span class="pre">score=None)</span></code></dt><dd><p>Calibrates the model with cross-validation support and configurable calibration methods, improving probability estimates.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">get_train_data(X,</span> <span class="pre">y),</span> <span class="pre">get_valid_data(X,</span> <span class="pre">y),</span> <span class="pre">get_test_data(X,</span> <span class="pre">y)</span></code></dt><dd><p>Retrieves train, validation, and test data based on specified indices.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">calibrate_report(X,</span> <span class="pre">y,</span> <span class="pre">score=None)</span></code></dt><dd><p>Generates a calibration report, including a confusion matrix and classification report.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">fit(X,</span> <span class="pre">y,</span> <span class="pre">validation_data=None,</span> <span class="pre">score=None)</span></code></dt><dd><p>Fits the model to training data and, if applicable, tunes threshold and performs early stopping. Allows feature selection and processing steps as part of the pipeline.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">return_metrics(X_test,</span> <span class="pre">y_test,</span> <span class="pre">optimal_threshold=False)</span></code></dt><dd><p>Returns evaluation metrics with confusion matrix and classification report, optionally using optimized classification thresholds.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">predict(X,</span> <span class="pre">y=None,</span> <span class="pre">optimal_threshold=False),</span> <span class="pre">predict_proba(X,</span> <span class="pre">y=None)</span></code></dt><dd><p>Makes predictions and predicts probabilities, allowing threshold tuning.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning(X,</span> <span class="pre">y,</span> <span class="pre">f1_beta_tune=False,</span> <span class="pre">betas=[1,</span> <span class="pre">2])</span></code></dt><dd><p>Performs grid or Bayesian search parameter tuning, optionally tuning F-beta score thresholds for classification.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">print_selected_best_features(X)</span></code></dt><dd><p>Prints and returns the selected top K best features based on the feature selection step.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">tune_threshold_Fbeta(score,</span> <span class="pre">y_valid,</span> <span class="pre">betas,</span> <span class="pre">y_valid_proba,</span> <span class="pre">kfold=False)</span></code></dt><dd><p>Tunes classification threshold for optimal F-beta score, balancing precision and recall across various thresholds.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">train_val_test_split(X,</span> <span class="pre">y,</span> <span class="pre">stratify_y,</span> <span class="pre">train_size,</span> <span class="pre">validation_size,</span> <span class="pre">test_size,</span> <span class="pre">random_state,</span> <span class="pre">stratify_cols)</span></code></dt><dd><p>Splits data into train, validation, and test sets, supporting stratification by specific columns or the target variable.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">get_best_score_params(X,</span> <span class="pre">y)</span></code></dt><dd><p>Retrieves the best hyperparameters for the model based on cross-validation scores for specified metrics.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">conf_mat_class_kfold(X,</span> <span class="pre">y,</span> <span class="pre">test_model,</span> <span class="pre">score=None)</span></code></dt><dd><p>Generates and averages confusion matrices across k-folds, producing a combined classification report.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">regression_report_kfold(X,</span> <span class="pre">y,</span> <span class="pre">test_model,</span> <span class="pre">score=None)</span></code></dt><dd><p>Generates averaged regression metrics across k-folds.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">regression_report(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">print_results=True)</span></code></dt><dd><p>Generates a regression report with metrics like Mean Absolute Error, R-squared, and Root Mean Squared Error.</p>
</dd>
</dl>
</section>
<section id="helper-functions">
<h1>Helper Functions<a class="headerlink" href="#helper-functions" title="Link to this heading"></a></h1>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">kfold_split(classifier,</span> <span class="pre">X,</span> <span class="pre">y,</span> <span class="pre">stratify=False,</span> <span class="pre">scoring=[&quot;roc_auc&quot;],</span> <span class="pre">n_splits=10,</span> <span class="pre">random_state=3)</span></code></dt><dd><p>Splits data using k-fold or stratified k-fold cross-validation.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">get_cross_validate(classifier,</span> <span class="pre">X,</span> <span class="pre">y,</span> <span class="pre">kf,</span> <span class="pre">scoring=[&quot;roc_auc&quot;])</span></code></dt><dd><p>Performs cross-validation and returns training scores and estimator instances.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">_confusion_matrix_print(conf_matrix,</span> <span class="pre">labels)</span></code></dt><dd><p>Prints the formatted confusion matrix for binary classification.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">print_pipeline(pipeline)</span></code></dt><dd><p>Displays an ASCII representation of the pipeline steps for visual clarity.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">report_model_metrics(model,</span> <span class="pre">X_valid=None,</span> <span class="pre">y_valid=None,</span> <span class="pre">threshold=0.5)</span></code></dt><dd><p>Generates a DataFrame of key model performance metrics, including Precision, Sensitivity, Specificity, and AUC-ROC.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This class is designed to be flexible and can be extended to include additional functionalities or custom metrics.</p></li>
<li><p>It is essential to properly configure the parameters during initialization to suit the specific requirements of your machine learning task.</p></li>
<li><p>Ensure that all dependencies are installed and properly imported before using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class from the <code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> library.</p></li>
</ul>
</div>
</section>
<section id="input-parameters">
<h1>Input Parameters<a class="headerlink" href="#input-parameters" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kfold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imbalance_sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['roc_auc']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomized_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boost_early</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_selection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sigmoid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_scorer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bayesian</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Model" title="Link to this definition"></a></dt>
<dd><p>A class for building, tuning, and evaluating machine learning models, supporting both classification and regression tasks, as well as multi-label classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – A unique name for the model, helpful for tracking outputs and logs.</p></li>
<li><p><strong>estimator_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Prefix for the estimator in the pipeline, used for setting parameters in tuning (e.g., estimator_name + <code class="docutils literal notranslate"><span class="pre">__param_name</span></code>).</p></li>
<li><p><strong>estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The machine learning model to be trained and tuned.</p></li>
<li><p><strong>calibrate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to calibrate the model’s probability estimates. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>kfold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to perform k-fold cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>imbalance_sampler</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a><em>, </em><em>optional</em>) – An imbalanced data sampler from the imblearn library, e.g., <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code> or <code class="docutils literal notranslate"><span class="pre">RandomOverSampler</span></code>.</p></li>
<li><p><strong>train_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for training. Default is <code class="docutils literal notranslate"><span class="pre">0.6</span></code>.</p></li>
<li><p><strong>validation_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for validation. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>test_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for testing. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>stratify_y</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to stratify by the target variable during data splitting. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>stratify_cols</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – List of columns to use for stratification during data splitting. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>grid</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Hyperparameter grid for model tuning, supporting both regular and Bayesian search.</p></li>
<li><p><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – List of scoring metrics for evaluation, e.g., <code class="docutils literal notranslate"><span class="pre">[&quot;roc_auc&quot;,</span> <span class="pre">&quot;accuracy&quot;]</span></code>.</p></li>
<li><p><strong>n_splits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of splits for k-fold cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed for random number generation to ensure reproducibility. Default is <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of parallel jobs to run for model fitting. Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>display</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to print messages during the tuning and training process. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>randomized_grid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use randomized grid search. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>n_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of iterations for randomized grid search. Default is <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><strong>pipeline_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – List of steps for the pipeline, e.g., preprocessing and feature selection steps. Default is <code class="docutils literal notranslate"><span class="pre">[]</span></code>.</p></li>
<li><p><strong>boost_early</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to enable early stopping for boosting algorithms like XGBoost. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>feature_selection</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to enable feature selection. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the model type, either <code class="docutils literal notranslate"><span class="pre">classification</span></code> or <code class="docutils literal notranslate"><span class="pre">regression</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">classification</span></code>.</p></li>
<li><p><strong>class_labels</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – List of labels for multi-class classification. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>multi_label</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether the task is a multi-label classification problem. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>calibration_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Method for calibration; options include <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> and <code class="docutils literal notranslate"><span class="pre">isotonic</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>.</p></li>
<li><p><strong>custom_scorer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><em>optional</em>) – Dictionary of custom scoring functions, allowing additional metrics to be evaluated. Default is <code class="docutils literal notranslate"><span class="pre">[]</span></code>.</p></li>
<li><p><strong>bayesian</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to perform Bayesian hyperparameter tuning using <code class="docutils literal notranslate"><span class="pre">BayesSearchCV</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ImportError" title="(in Python v3.13)"><strong>ImportError</strong></a> – If the <code class="docutils literal notranslate"><span class="pre">bootstrapper</span></code> module is not found or not installed.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised for various issues, such as invalid hyperparameter configurations, or mismatched <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> shapes.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – Raised if an expected pipeline step is missing, or if <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> is improperly initialized.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – Raised when an incorrect parameter type is provided, such as passing <code class="docutils literal notranslate"><span class="pre">None</span></code> instead of a valid object.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#IndexError" title="(in Python v3.13)"><strong>IndexError</strong></a> – Raised for indexing issues, particularly in confusion matrix formatting functions.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised when accessing dictionary keys that are not available, such as missing scores in <code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.13)"><strong>RuntimeError</strong></a> – Raised for unexpected issues during model fitting or transformations that do not fit into the other exception categories.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="binary-classification">
<h1>Binary Classification<a class="headerlink" href="#binary-classification" title="Link to this heading"></a></h1>
<p>Binary classification is a type of supervised learning where a model is trained
to distinguish between two distinct classes or categories. In essence, the model
learns to classify input data into one of two possible outcomes, typically
labeled as <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, or negative and positive. This is commonly used in
scenarios such as spam detection, disease diagnosis, or fraud detection.</p>
<p>In our library, binary classification is handled seamlessly through the <code class="docutils literal notranslate"><span class="pre">Model</span></code>
class. Users can specify a binary classifier as the estimator, and the library
takes care of essential tasks like data preprocessing, model calibration, and
cross-validation. The library also provides robust support for evaluating the
model’s performance using a variety of metrics, such as accuracy, precision,
recall, and ROC-AUC, ensuring that the model’s ability to distinguish between the
two classes is thoroughly assessed. Additionally, the library supports advanced
techniques like imbalanced data handling and model calibration to fine-tune
decision thresholds, making it easier to deploy effective binary classifiers in
real-world applications.</p>
<section id="aids-clinical-trials-group-study">
<h2>AIDS Clinical Trials Group Study<a class="headerlink" href="#aids-clinical-trials-group-study" title="Link to this heading"></a></h2>
<p>The UCI Machine Learning Repository is a well-known resource for accessing a wide
range of datasets used for machine learning research and practice. One such dataset
is the AIDS Clinical Trials Group Study dataset, which can be used to build and
evaluate predictive models.</p>
<p>You can easily fetch this dataset using the ucimlrepo package. If you haven’t
installed it yet, you can do so by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>ucimlrepo
</pre></div>
</div>
<p>Once installed, you can quickly load the AIDS Clinical Trials Group Study dataset
with a simple command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>
</pre></div>
</div>
<section id="step-1-import-necessary-libraries">
<h3>Step 1: Import Necessary Libraries<a class="headerlink" href="#step-1-import-necessary-libraries" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">model_tuner</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
</pre></div>
</div>
</section>
<section id="step-2-load-the-dataset-define-x-y">
<h3>Step 2: Load the dataset, define X, y<a class="headerlink" href="#step-2-load-the-dataset-define-x-y" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># fetch dataset</span>
<span class="n">aids_clinical_trials_group_study_175</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">890</span><span class="p">)</span>

<span class="c1"># data (as pandas dataframes)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">aids_clinical_trials_group_study_175</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">aids_clinical_trials_group_study_175</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># convert a DataFrame to Series when single column</span>
</pre></div>
</div>
</section>
<section id="step-3-check-for-zero-variance-columns-and-drop-accordingly">
<h3>Step 3: Check for zero-variance columns and drop accordingly<a class="headerlink" href="#step-3-check-for-zero-variance-columns-and-drop-accordingly" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check for zero-variance columns and drop them</span>
<span class="n">zero_variance_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">zero_variance_columns</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
   <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">zero_variance_columns</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-create-an-instance-of-the-xgbclassifier">
<h3>Step 4: Create an Instance of the XGBClassifier<a class="headerlink" href="#step-4-create-an-instance-of-the-xgbclassifier" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating an instance of the XGBClassifier</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-5-define-hyperparameters-for-xgboost">
<h3>Step 5: Define Hyperparameters for XGBoost<a class="headerlink" href="#step-5-define-hyperparameters-for-xgboost" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_name</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">objective</span><span class="o">=</span><span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">xgbearly</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">tuned_parameters_xgb</span> <span class="o">=</span> <span class="p">{</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">xgb_definition</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s2">&quot;clc&quot;</span><span class="p">:</span> <span class="n">xgb</span><span class="p">,</span>
   <span class="s2">&quot;estimator_name&quot;</span><span class="p">:</span> <span class="n">xgb_name</span><span class="p">,</span>
   <span class="s2">&quot;tuned_parameters&quot;</span><span class="p">:</span> <span class="n">tuned_parameters_xgb</span><span class="p">,</span>
   <span class="s2">&quot;randomized_grid&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
   <span class="s2">&quot;n_iter&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
   <span class="s2">&quot;early&quot;</span><span class="p">:</span> <span class="n">xgbearly</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="step-6-initialize-and-configure-the-model">
<h3>Step 6: Initialize and Configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code><a class="headerlink" href="#step-6-initialize-and-configure-the-model" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">clc</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;clc&quot;</span><span class="p">]</span>
<span class="n">estimator_name</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;estimator_name&quot;</span><span class="p">]</span>

<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;tuned_parameters&quot;</span><span class="p">]</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;n_iter&quot;</span><span class="p">]</span>
<span class="n">rand_grid</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;randomized_grid&quot;</span><span class="p">]</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;early&quot;</span><span class="p">]</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">calibrate</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Initialize model_tuner</span>
<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AIDS_Clinical_</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">clc</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
   <span class="n">pipeline_steps</span><span class="o">=</span><span class="p">[</span>
      <span class="p">(</span><span class="s2">&quot;Imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
      <span class="p">(</span><span class="s2">&quot;StandardScalar&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
   <span class="p">],</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">,</span> <span class="s2">&quot;race&quot;</span><span class="p">],</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="n">rand_grid</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="n">early_stop</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-7-perform-grid-search-parameter-tuning">
<h3>Step 7: Perform Grid Search Parameter Tuning<a class="headerlink" href="#step-7-perform-grid-search-parameter-tuning" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform grid search parameter tuning</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Pipeline<span class="w"> </span>Steps:
<span class="o">========================</span>
┌────────────────────────────────────────────┐
│<span class="w"> </span>Step<span class="w"> </span><span class="m">1</span>:<span class="w"> </span>preprocess_imputer_Imputer<span class="w">         </span>│
│<span class="w"> </span>SimpleImputer<span class="w">                              </span>│
└────────────────────────────────────────────┘
<span class="w">                     </span>│
<span class="w">                     </span>▼
┌────────────────────────────────────────────┐
│<span class="w"> </span>Step<span class="w"> </span><span class="m">2</span>:<span class="w"> </span>preprocess_scaler_StandardScalar<span class="w">   </span>│
│<span class="w"> </span>StandardScaler<span class="w">                             </span>│
└────────────────────────────────────────────┘
<span class="w">                     </span>│
<span class="w">                     </span>▼
┌────────────────────────────────────────────┐
│<span class="w"> </span>Step<span class="w"> </span><span class="m">3</span>:<span class="w"> </span>xgb<span class="w">                                </span>│
│<span class="w"> </span>XGBClassifier<span class="w">                              </span>│
└────────────────────────────────────────────┘

<span class="m">100</span>%<span class="p">|</span>██████████<span class="p">|</span><span class="w"> </span><span class="m">5</span>/5<span class="w"> </span><span class="o">[</span><span class="m">00</span>:19&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">3</span>.84s/it<span class="o">]</span>
Fitting<span class="w"> </span>model<span class="w"> </span>with<span class="w"> </span>best<span class="w"> </span>params<span class="w"> </span>and<span class="w"> </span>tuning<span class="w"> </span><span class="k">for</span><span class="w"> </span>best<span class="w"> </span>threshold<span class="w"> </span>...
<span class="m">100</span>%<span class="p">|</span>██████████<span class="p">|</span><span class="w"> </span><span class="m">2</span>/2<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">3</span>.30it/s<span class="o">]</span>Best<span class="w"> </span>score/param<span class="w"> </span><span class="nb">set</span><span class="w"> </span>found<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span>set:
<span class="o">{</span><span class="s1">&#39;params&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;xgb__early_stopping_rounds&#39;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">            </span><span class="s1">&#39;xgb__eval_metric&#39;</span>:<span class="w"> </span><span class="s1">&#39;logloss&#39;</span>,
<span class="w">            </span><span class="s1">&#39;xgb__learning_rate&#39;</span>:<span class="w"> </span><span class="m">0</span>.0001,
<span class="w">            </span><span class="s1">&#39;xgb__max_depth&#39;</span>:<span class="w"> </span><span class="m">3</span>,
<span class="w">            </span><span class="s1">&#39;xgb__n_estimators&#39;</span>:<span class="w"> </span><span class="m">999</span><span class="o">}</span>,
<span class="s1">&#39;score&#39;</span>:<span class="w"> </span><span class="m">0</span>.9260891500474834<span class="o">}</span>
Best<span class="w"> </span>roc_auc:<span class="w"> </span><span class="m">0</span>.926
</pre></div>
</div>
</section>
<section id="step-8-fit-the-model">
<h3>Step 8: Fit the Model<a class="headerlink" href="#step-8-fit-the-model" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the training and validation data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">model_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="step-9-return-metrics-optional">
<h3>Step 9: Return Metrics (Optional)<a class="headerlink" href="#step-9-return-metrics-optional" title="Link to this heading"></a></h3>
<p>You can use this function to evaluate the model by printing the output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ------------------------- VALID AND TEST METRICS -----------------------------</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">class_report_val</span><span class="p">,</span> <span class="n">cm_val</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">class_report_test</span><span class="p">,</span> <span class="n">cm_test</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Validation<span class="w"> </span>Metrics
Confusion<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="nb">set</span><span class="w"> </span>provided:
--------------------------------------------------------------------------------
<span class="w">         </span>Predicted:
<span class="w">            </span>Pos<span class="w">   </span>Neg
--------------------------------------------------------------------------------
Actual:<span class="w"> </span>Pos<span class="w">  </span><span class="m">93</span><span class="w"> </span><span class="o">(</span>tp<span class="o">)</span><span class="w">   </span><span class="m">11</span><span class="w"> </span><span class="o">(</span>fn<span class="o">)</span>
<span class="w">      </span>Neg<span class="w">  </span><span class="m">76</span><span class="w"> </span><span class="o">(</span>fp<span class="o">)</span><span class="w">  </span><span class="m">248</span><span class="w"> </span><span class="o">(</span>tn<span class="o">)</span>
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
<span class="o">{</span><span class="s1">&#39;AUC ROC&#39;</span>:<span class="w"> </span><span class="m">0</span>.9260891500474834,
<span class="s1">&#39;Average Precision&#39;</span>:<span class="w"> </span><span class="m">0</span>.8025676192819657,
<span class="s1">&#39;Brier Score&#39;</span>:<span class="w"> </span><span class="m">0</span>.16665653153377272,
<span class="s1">&#39;Precision/PPV&#39;</span>:<span class="w"> </span><span class="m">0</span>.5502958579881657,
<span class="s1">&#39;Sensitivity&#39;</span>:<span class="w"> </span><span class="m">0</span>.8942307692307693,
<span class="s1">&#39;Specificity&#39;</span>:<span class="w"> </span><span class="m">0</span>.7654320987654321<span class="o">}</span>
--------------------------------------------------------------------------------

<span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.96<span class="w">      </span><span class="m">0</span>.77<span class="w">      </span><span class="m">0</span>.85<span class="w">       </span><span class="m">324</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">0</span>.55<span class="w">      </span><span class="m">0</span>.89<span class="w">      </span><span class="m">0</span>.68<span class="w">       </span><span class="m">104</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.80<span class="w">       </span><span class="m">428</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.75<span class="w">      </span><span class="m">0</span>.83<span class="w">      </span><span class="m">0</span>.77<span class="w">       </span><span class="m">428</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.86<span class="w">      </span><span class="m">0</span>.80<span class="w">      </span><span class="m">0</span>.81<span class="w">       </span><span class="m">428</span>

--------------------------------------------------------------------------------

Test<span class="w"> </span>Metrics
Confusion<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span><span class="nb">set</span><span class="w"> </span>provided:
--------------------------------------------------------------------------------
<span class="w">         </span>Predicted:
<span class="w">            </span>Pos<span class="w">   </span>Neg
--------------------------------------------------------------------------------
Actual:<span class="w"> </span>Pos<span class="w">  </span><span class="m">99</span><span class="w"> </span><span class="o">(</span>tp<span class="o">)</span><span class="w">    </span><span class="m">6</span><span class="w"> </span><span class="o">(</span>fn<span class="o">)</span>
<span class="w">      </span>Neg<span class="w">  </span><span class="m">82</span><span class="w"> </span><span class="o">(</span>fp<span class="o">)</span><span class="w">  </span><span class="m">241</span><span class="w"> </span><span class="o">(</span>tn<span class="o">)</span>
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
<span class="o">{</span><span class="s1">&#39;AUC ROC&#39;</span>:<span class="w"> </span><span class="m">0</span>.9343063541205956,
<span class="s1">&#39;Average Precision&#39;</span>:<span class="w"> </span><span class="m">0</span>.8169018952192892,
<span class="s1">&#39;Brier Score&#39;</span>:<span class="w"> </span><span class="m">0</span>.16737745981389285,
<span class="s1">&#39;Precision/PPV&#39;</span>:<span class="w"> </span><span class="m">0</span>.5469613259668509,
<span class="s1">&#39;Sensitivity&#39;</span>:<span class="w"> </span><span class="m">0</span>.9428571428571428,
<span class="s1">&#39;Specificity&#39;</span>:<span class="w"> </span><span class="m">0</span>.7461300309597523<span class="o">}</span>
--------------------------------------------------------------------------------

<span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.98<span class="w">      </span><span class="m">0</span>.75<span class="w">      </span><span class="m">0</span>.85<span class="w">       </span><span class="m">323</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">0</span>.55<span class="w">      </span><span class="m">0</span>.94<span class="w">      </span><span class="m">0</span>.69<span class="w">       </span><span class="m">105</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.79<span class="w">       </span><span class="m">428</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.76<span class="w">      </span><span class="m">0</span>.84<span class="w">      </span><span class="m">0</span>.77<span class="w">       </span><span class="m">428</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.87<span class="w">      </span><span class="m">0</span>.79<span class="w">      </span><span class="m">0</span>.81<span class="w">       </span><span class="m">428</span>

--------------------------------------------------------------------------------
</pre></div>
</div>
</section>
<section id="step-10-calibrate-the-model-if-needed">
<h3>Step 10: Calibrate the Model (if needed)<a class="headerlink" href="#step-10-calibrate-the-model-if-needed" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="kn">import</span> <span class="n">calibration_curve</span>

<span class="c1"># Get the predicted probabilities for the validation data from the uncalibrated model</span>
<span class="n">y_prob_uncalibrated</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Compute the calibration curve for the uncalibrated model</span>
<span class="n">prob_true_uncalibrated</span><span class="p">,</span> <span class="n">prob_pred_uncalibrated</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">y_prob_uncalibrated</span><span class="p">,</span>
   <span class="n">n_bins</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Calibrate the model</span>
<span class="k">if</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">calibrate</span><span class="p">:</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">calibrateModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>

<span class="c1"># Predict on the validation set</span>
<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Change<span class="w"> </span>back<span class="w"> </span>to<span class="w"> </span>CPU
Confusion<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span><span class="nb">set</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>roc_auc
--------------------------------------------------------------------------------
<span class="w">         </span>Predicted:
<span class="w">            </span>Pos<span class="w">   </span>Neg
--------------------------------------------------------------------------------
Actual:<span class="w"> </span>Pos<span class="w">  </span><span class="m">74</span><span class="w"> </span><span class="o">(</span>tp<span class="o">)</span><span class="w">   </span><span class="m">30</span><span class="w"> </span><span class="o">(</span>fn<span class="o">)</span>
<span class="w">      </span>Neg<span class="w">  </span><span class="m">20</span><span class="w"> </span><span class="o">(</span>fp<span class="o">)</span><span class="w">  </span><span class="m">304</span><span class="w"> </span><span class="o">(</span>tn<span class="o">)</span>
--------------------------------------------------------------------------------

<span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.91<span class="w">      </span><span class="m">0</span>.94<span class="w">      </span><span class="m">0</span>.92<span class="w">       </span><span class="m">324</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">0</span>.79<span class="w">      </span><span class="m">0</span>.71<span class="w">      </span><span class="m">0</span>.75<span class="w">       </span><span class="m">104</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.88<span class="w">       </span><span class="m">428</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.85<span class="w">      </span><span class="m">0</span>.82<span class="w">      </span><span class="m">0</span>.84<span class="w">       </span><span class="m">428</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.88<span class="w">      </span><span class="m">0</span>.88<span class="w">      </span><span class="m">0</span>.88<span class="w">       </span><span class="m">428</span>

--------------------------------------------------------------------------------
roc_auc<span class="w"> </span>after<span class="w"> </span>calibration:<span class="w"> </span><span class="m">0</span>.9260891500474834
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the predicted probabilities for the validation data from calibrated model</span>
<span class="n">y_prob_calibrated</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Compute the calibration curve for the calibrated model</span>
<span class="n">prob_true_calibrated</span><span class="p">,</span> <span class="n">prob_pred_calibrated</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
<span class="n">y_test</span><span class="p">,</span>
<span class="n">y_prob_calibrated</span><span class="p">,</span>
<span class="n">n_bins</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># Plot the calibration curves</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
<span class="n">prob_pred_uncalibrated</span><span class="p">,</span>
<span class="n">prob_true_uncalibrated</span><span class="p">,</span>
<span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
<span class="n">label</span><span class="o">=</span><span class="s2">&quot;Uncalibrated XGBoost&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
<span class="n">prob_pred_calibrated</span><span class="p">,</span>
<span class="n">prob_true_calibrated</span><span class="p">,</span>
<span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
<span class="n">label</span><span class="o">=</span><span class="s2">&quot;Calibrated XGBoost&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span>
<span class="n">label</span><span class="o">=</span><span class="s2">&quot;Perfectly calibrated&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True probability in each bin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Calibration plot (reliability curve)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="no-click"><a class="reference internal image-reference" href="_images/calibration_curve_aids.png"><img alt="Calibration Curve AIDs" class="align-center" src="_images/calibration_curve_aids.png" style="width: 400px;" />
</a>
</div><div style="height: 50px;"></div></section>
<section id="classification-report-optional">
<h3>Classification Report (Optional)<a class="headerlink" href="#classification-report-optional" title="Link to this heading"></a></h3>
<p>A classification report is readily available at this stage, should you wish to
print and examine it. A call to <code class="docutils literal notranslate"><span class="pre">print(model_tuner.classification_report)</span></code> will
output it as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model_tuner</span><span class="o">.</span><span class="n">classification_report</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.91<span class="w">      </span><span class="m">0</span>.94<span class="w">      </span><span class="m">0</span>.92<span class="w">       </span><span class="m">324</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">0</span>.79<span class="w">      </span><span class="m">0</span>.71<span class="w">      </span><span class="m">0</span>.75<span class="w">       </span><span class="m">104</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.88<span class="w">       </span><span class="m">428</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.85<span class="w">      </span><span class="m">0</span>.82<span class="w">      </span><span class="m">0</span>.84<span class="w">       </span><span class="m">428</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.88<span class="w">      </span><span class="m">0</span>.88<span class="w">      </span><span class="m">0</span>.88<span class="w">       </span><span class="m">428</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="regression">
<h1>Regression<a class="headerlink" href="#regression" title="Link to this heading"></a></h1>
<p>Here is an example of using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class for regression using <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> on the California Housing dataset.</p>
<section id="california-housing-with-xgboost">
<h2>California Housing with XGBoost<a class="headerlink" href="#california-housing-with-xgboost" title="Link to this heading"></a></h2>
<section id="id1">
<h3>Step 1: Import Necessary Libraries<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">model_tuner</span>
</pre></div>
</div>
</section>
<section id="step-2-load-the-dataset">
<h3>Step 2: Load the Dataset<a class="headerlink" href="#step-2-load-the-dataset" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the California Housing dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-create-an-instance-of-the-xgbclassifier">
<h3>Step 3: Create an Instance of the XGBClassifier<a class="headerlink" href="#step-3-create-an-instance-of-the-xgbclassifier" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating an instance of the XGBRegressor</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-define-hyperparameters-for-xgboost">
<h3>Step 4: Define Hyperparameters for XGBoost<a class="headerlink" href="#step-4-define-hyperparameters-for-xgboost" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimator name prefix for use in GridSearchCV or similar tools</span>
<span class="n">estimator_name_xgb</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>

<span class="c1"># Define the hyperparameters for XGBoost</span>
<span class="n">xgb_learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>  <span class="c1"># Learning rate or eta</span>
<span class="c1"># Number of trees. Equivalent to n_estimators in GB</span>
<span class="n">xgb_n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">xgb_max_depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">][:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Maximum depth of the trees</span>
<span class="n">xgb_subsamples</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">][:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Subsample ratio of the training instances</span>
<span class="n">xgb_colsample_bytree</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">][:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">xgb_eval_metric</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">]</span>
<span class="n">xgb_early_stopping_rounds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>
<span class="n">xgb_verbose</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>

<span class="c1"># Combining the hyperparameters in a dictionary</span>
<span class="n">xgb_parameters</span> <span class="o">=</span> <span class="p">[</span>
   <span class="p">{</span>
      <span class="s2">&quot;xgb__learning_rate&quot;</span><span class="p">:</span> <span class="n">xgb_learning_rates</span><span class="p">,</span>
      <span class="s2">&quot;xgb__n_estimators&quot;</span><span class="p">:</span> <span class="n">xgb_n_estimators</span><span class="p">,</span>
      <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="n">xgb_max_depths</span><span class="p">,</span>
      <span class="s2">&quot;xgb__subsample&quot;</span><span class="p">:</span> <span class="n">xgb_subsamples</span><span class="p">,</span>
      <span class="s2">&quot;xgb__colsample_bytree&quot;</span><span class="p">:</span> <span class="n">xgb_colsample_bytree</span><span class="p">,</span>
      <span class="s2">&quot;xgb__eval_metric&quot;</span><span class="p">:</span> <span class="n">xgb_eval_metric</span><span class="p">,</span>
      <span class="s2">&quot;xgb__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="n">xgb_early_stopping_rounds</span><span class="p">,</span>
      <span class="s2">&quot;xgb__verbose&quot;</span><span class="p">:</span> <span class="n">xgb_verbose</span><span class="p">,</span>
   <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="step-5-initialize-and-configure-the-model">
<h3>Step 5: Initialize and Configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code><a class="headerlink" href="#step-5-initialize-and-configure-the-model" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize model_tuner</span>
<span class="n">california_housing</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">pipeline_steps</span><span class="o">=</span><span class="p">[</span>
      <span class="p">(</span><span class="s2">&quot;Preprocessor&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
   <span class="p">],</span>
   <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Redfin_model_XGB&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;regression&quot;</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_model</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">xgb_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;r2&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
   <span class="n">xgboost_early</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-6-fit-the-model">
<h3>Step 6: Fit the Model<a class="headerlink" href="#step-6-fit-the-model" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>  <span class="c1"># necessary for early stopping</span>

<span class="c1"># Perform grid search parameter tuning</span>
<span class="n">california_housing</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Get the training and validation data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">california_housing</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">california_housing</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">california_housing</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span>
   <span class="n">y_train</span><span class="p">,</span>
   <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">california_housing</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">100</span>%<span class="p">|</span>██████████<span class="p">|</span><span class="w"> </span><span class="m">9</span>/9<span class="w"> </span><span class="o">[</span><span class="m">00</span>:01&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">4</span>.81it/s<span class="o">]</span>
Best<span class="w"> </span>score/param<span class="w"> </span><span class="nb">set</span><span class="w"> </span>found<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span>set:
<span class="o">{</span><span class="s1">&#39;params&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;xgb__colsample_bytree&#39;</span>:<span class="w"> </span><span class="m">0</span>.8,
<span class="w">            </span><span class="s1">&#39;xgb__early_stopping_rounds&#39;</span>:<span class="w"> </span><span class="m">10</span>,
<span class="w">            </span><span class="s1">&#39;xgb__eval_metric&#39;</span>:<span class="w"> </span><span class="s1">&#39;logloss&#39;</span>,
<span class="w">            </span><span class="s1">&#39;xgb__learning_rate&#39;</span>:<span class="w"> </span><span class="m">0</span>.1,
<span class="w">            </span><span class="s1">&#39;xgb__max_depth&#39;</span>:<span class="w"> </span><span class="m">3</span>,
<span class="w">            </span><span class="s1">&#39;xgb__n_estimators&#39;</span>:<span class="w"> </span><span class="m">172</span>,
<span class="w">            </span><span class="s1">&#39;xgb__subsample&#39;</span>:<span class="w"> </span><span class="m">0</span>.8<span class="o">}</span>,
<span class="s1">&#39;score&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.7979488661159093<span class="o">)}</span>
Best<span class="w"> </span>r2:<span class="w"> </span><span class="m">0</span>.798

********************************************************************************
<span class="o">{</span><span class="s1">&#39;Explained Variance&#39;</span>:<span class="w"> </span><span class="m">0</span>.7979060590722392,
<span class="s1">&#39;Mean Absolute Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.35007797000749163<span class="o">)</span>,
<span class="s1">&#39;Mean Squared Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.2633964855111536<span class="o">)</span>,
<span class="s1">&#39;Median Absolute Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.24205514192581173<span class="o">)</span>,
<span class="s1">&#39;R2&#39;</span>:<span class="w"> </span><span class="m">0</span>.7979050719771986,
<span class="s1">&#39;RMSE&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.5132216728774747<span class="o">)}</span>
********************************************************************************

<span class="o">{</span><span class="s1">&#39;Explained Variance&#39;</span>:<span class="w"> </span><span class="m">0</span>.7979060590722392,
<span class="s1">&#39;R2&#39;</span>:<span class="w"> </span><span class="m">0</span>.7979050719771986,
<span class="s1">&#39;Mean Absolute Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.35007797000749163<span class="o">)</span>,
<span class="s1">&#39;Median Absolute Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.24205514192581173<span class="o">)</span>,
<span class="s1">&#39;Mean Squared Error&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.2633964855111536<span class="o">)</span>,
<span class="s1">&#39;RMSE&#39;</span>:<span class="w"> </span>np.float64<span class="o">(</span><span class="m">0</span>.5132216728774747<span class="o">)}</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="getting_started.html" class="btn btn-neutral float-left" title="Welcome to Model Tuner’s Documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="caveats.html" class="btn btn-neutral float-right" title="Zero Variance Columns" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, UCLA CTSI ML Team: Leonid Shpaner, Arthur Funnell, Panayiotis Petousis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>