<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Usage Guide &mdash; Model Tuner 0.0.8a0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />

  
    <link rel="canonical" href="https://uclamii.github.io/model_tuner/usage_guide.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=28f502ad"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Changelog" href="changelog.html" />
    <link rel="prev" title="Welcome to Model Tuner’s Documentation!" href="getting_started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Model Tuner
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Welcome to Model Tuner’s Documentation!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="#key-methods-and-functionalities">Key Methods and Functionalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="#helper-functions">Helper Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="#notes">Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="#input-parameters">Input Parameters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Model"><code class="docutils literal notranslate"><span class="pre">Model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#usage">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#binary-classification">Binary classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#binary-classification-output">Binary Classification Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-output">Regression Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ipython-notebooks">iPython Notebooks</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Changelog</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">GitHub Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#acknowledgements">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#citing-model-tuner">Citing Model Tuner</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Model Tuner</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Usage Guide</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <a class="reference internal image-reference" href="_images/ModelTunerTarget.png" id="target-link"><span id="usage-guide"></span><span id="usage-guide"></span><img alt="Model Tuner Logo" class="align-left" id="target-link" src="_images/ModelTunerTarget.png" style="width: 350px;" /></a>
<div style="height: 200px;"></div><p></p>
<section id="id1">
<h1>Usage Guide<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>This documentation is for <code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> version <code class="docutils literal notranslate"><span class="pre">0.0.08a</span></code>.</p>
</div>
</section>
<section id="key-methods-and-functionalities">
<h1>Key Methods and Functionalities<a class="headerlink" href="#key-methods-and-functionalities" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__(...)</span></code>: Initializes the model_tuner with various configurations such as estimator, cross-validation settings, scoring metrics, etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reset_estimator()</span></code>: Resets the estimator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">process_imbalance_sampler(X_train,</span> <span class="pre">y_train)</span></code>: Processes imbalance sampler.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">calibrateModel(X,</span> <span class="pre">y,</span> <span class="pre">score=None,</span> <span class="pre">stratify=None)</span></code>: Calibrates the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_train_data(X,</span> <span class="pre">y)</span></code>, <code class="docutils literal notranslate"><span class="pre">get_valid_data(X,</span> <span class="pre">y)</span></code>, <code class="docutils literal notranslate"><span class="pre">get_test_data(X,</span> <span class="pre">y)</span></code>: Methods to retrieve train, validation, and test data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">calibrate_report(X,</span> <span class="pre">y,</span> <span class="pre">score=None)</span></code>: Generates a calibration report.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit(X,</span> <span class="pre">y,</span> <span class="pre">validation_data=None,</span> <span class="pre">score=None)</span></code>: Fits the model to the data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">return_metrics(X_test,</span> <span class="pre">y_test)</span></code>: Returns evaluation metrics.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict(X,</span> <span class="pre">y=None,</span> <span class="pre">optimal_threshold=False)</span></code>, <code class="docutils literal notranslate"><span class="pre">predict_proba(X,</span> <span class="pre">y=None)</span></code>: Methods to make predictions and predict probabilities.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning(X,</span> <span class="pre">y,</span> <span class="pre">f1_beta_tune=False,</span> <span class="pre">betas=[1,</span> <span class="pre">2])</span></code>: Performs grid search parameter tuning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">print_k_best_features(X)</span></code>: Prints the top K best features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tune_threshold_Fbeta(score,</span> <span class="pre">X_train,</span> <span class="pre">y_train,</span> <span class="pre">X_valid,</span> <span class="pre">y_valid,</span> <span class="pre">betas,</span> <span class="pre">kfold=False)</span></code>: Tunes the threshold for F-beta score.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_val_test_split(X,</span> <span class="pre">y,</span> <span class="pre">stratify_y,</span> <span class="pre">train_size,</span> <span class="pre">validation_size,</span> <span class="pre">test_size,</span> <span class="pre">random_state,</span> <span class="pre">stratify_cols,</span> <span class="pre">calibrate)</span></code>: Splits the data into train, validation, and test sets.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_best_score_params(X,</span> <span class="pre">y)</span></code>: Retrieves the best score parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">conf_mat_class_kfold(X,</span> <span class="pre">y,</span> <span class="pre">test_model,</span> <span class="pre">score=None)</span></code>: Generates confusion matrix for k-fold cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">regression_report_kfold(X,</span> <span class="pre">y,</span> <span class="pre">test_model,</span> <span class="pre">score=None)</span></code>: Generates regression report for k-fold cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">regression_report(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">print_results=True)</span></code>: Generates a regression report.</p></li>
</ul>
</section>
<section id="helper-functions">
<h1>Helper Functions<a class="headerlink" href="#helper-functions" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kfold_split(classifier,</span> <span class="pre">X,</span> <span class="pre">y,</span> <span class="pre">stratify=False,</span> <span class="pre">scoring=[&quot;roc_auc&quot;],</span> <span class="pre">n_splits=10,</span> <span class="pre">random_state=3)</span></code>: Splits data using k-fold cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_cross_validate(classifier,</span> <span class="pre">X,</span> <span class="pre">y,</span> <span class="pre">kf,</span> <span class="pre">stratify=False,</span> <span class="pre">scoring=[&quot;roc_auc&quot;])</span></code>: Performs cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_confusion_matrix_print(conf_matrix,</span> <span class="pre">labels)</span></code>: Prints the confusion matrix.</p></li>
</ul>
</section>
<section id="notes">
<h1>Notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p>This class is designed to be flexible and can be extended to include additional functionalities or custom metrics.</p></li>
<li><p>It is essential to properly configure the parameters during initialization to suit the specific requirements of your machine learning task.</p></li>
<li><p>Ensure that all dependencies are installed and properly imported before using the model_tuner class.</p></li>
</ul>
</section>
<section id="input-parameters">
<h1>Input Parameters<a class="headerlink" href="#input-parameters" title="Link to this heading"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="Model">
<span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kfold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imbalance_sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_cols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_strat_feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomized_grid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trained</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaler_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impute_strategy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impute</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgboost_early</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">selectKBest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_scorer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Model" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>str</strong><strong>)</strong> (<em>estimator_name</em>) – A name for the model, useful for identifying the model in outputs and logs.</p></li>
<li><p><strong>(</strong><strong>str</strong><strong>)</strong> – The prefix for the estimator used in the pipeline. This is used in parameter tuning (e.g., estimator_name + <code class="docutils literal notranslate"><span class="pre">__param_name</span></code>).</p></li>
<li><p><strong>(</strong><strong>object</strong><strong>)</strong> (<em>estimator</em>) – The machine learning model to be tuned and trained.</p></li>
<li><p><strong>optional</strong><strong>)</strong> (<em>custom_scorer</em><em> (</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em>,</em>) – Whether to calibrate the classifier. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to use k-fold cross-validation. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – An imbalanced data sampler from the imblearn library, e.g., RandomUnderSampler or RandomOverSampler.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Proportion of the data to use for training. Default is 0.6.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Proportion of the data to use for validation. Default is 0.2.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Proportion of the data to use for testing. Default is 0.2.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to stratify by the target variable during train/validation/test split. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – List of columns to stratify by during train/validation/test split. Default is None.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – List of columns to drop after stratification. Default is None.</p></li>
<li><p><strong>dict</strong><strong>)</strong> (<em>grid</em><em> (</em><em>list of</em>) – Hyperparameter grid for tuning.</p></li>
<li><p><strong>str</strong><strong>)</strong> (<em>scoring</em><em> (</em><em>list of</em>) – Scoring metrics for evaluation.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Number of splits for k-fold cross-validation. Default is 10.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Random state for reproducibility. Default is 3.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Number of jobs to run in parallel for model fitting. Default is 1.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to display output messages during the tuning process. Default is True.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – List of feature names. Default is None.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to use randomized grid search. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Number of iterations for randomized grid search. Default is 100.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether the model has been trained. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to use a pipeline. Default is True.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Type of scaler to use. Options are <code class="docutils literal notranslate"><span class="pre">min_max_scaler</span></code>, <code class="docutils literal notranslate"><span class="pre">standard_scaler</span></code>, <code class="docutils literal notranslate"><span class="pre">max_abs_scaler</span></code>, or None. Default is <code class="docutils literal notranslate"><span class="pre">min_max_scaler</span></code>.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Strategy for imputation. Options are <code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">median</span></code>, <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>, or <code class="docutils literal notranslate"><span class="pre">constant</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">mean</span></code>.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to impute missing values. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – List of pipeline steps. Default is [(<code class="docutils literal notranslate"><span class="pre">min_max_scaler</span></code>, MinMaxScaler())].</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to use early stopping for XGBoost. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether to select K best features. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Type of model, either <code class="docutils literal notranslate"><span class="pre">classification</span></code> or <code class="docutils literal notranslate"><span class="pre">regression</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">classification</span></code>.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – List of class labels for multi-class classification. Default is None.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Whether the problem is a multi-label classification problem. Default is False.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Method for calibration, options are <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> or <code class="docutils literal notranslate"><span class="pre">isotonic</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>.</p></li>
<li><p><strong>optional</strong><strong>)</strong> – Custom scorers for evaluation. Default is <code class="docutils literal notranslate"><span class="pre">[]</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h1>
<section id="binary-classification">
<h2>Binary classification<a class="headerlink" href="#binary-classification" title="Link to this heading"></a></h2>
<p><strong>Breast Cancer Example with XGBoost</strong></p>
<p><strong>Step 1: Import Necessary Libraries</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">model_tuner</span>
</pre></div>
</div>
<p><strong>Step 2: Load the Dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the breast cancer dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3: Create an Instance of the XGBClassifier</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating an instance of the XGBClassifier</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 4: Define Hyperparameters for XGBoost</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimator name prefix for use in GridSearchCV or similar tools</span>
<span class="n">estimator_name_xgb</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>

<span class="c1"># Define the hyperparameters for XGBoost</span>
<span class="n">xgb_learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>  <span class="c1"># Learning rate or eta</span>
<span class="n">xgb_n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>  <span class="c1"># Number of trees. Equivalent to n_estimators in GB</span>
<span class="n">xgb_max_depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>  <span class="c1"># Maximum depth of the trees</span>
<span class="n">xgb_subsamples</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>  <span class="c1"># Subsample ratio of the training instances</span>
<span class="n">xgb_colsample_bytree</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>

<span class="n">xgb_eval_metric</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">]</span>  <span class="c1"># Check out &quot;pr_auc&quot;</span>
<span class="n">xgb_early_stopping_rounds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>
<span class="n">xgb_verbose</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>  <span class="c1"># Subsample ratio of columns when constructing each tree</span>

<span class="c1"># Combining the hyperparameters in a dictionary</span>
<span class="n">xgb_parameters</span> <span class="o">=</span> <span class="p">[</span>
   <span class="p">{</span>
      <span class="s2">&quot;xgb__learning_rate&quot;</span><span class="p">:</span> <span class="n">xgb_learning_rates</span><span class="p">,</span>
      <span class="s2">&quot;xgb__n_estimators&quot;</span><span class="p">:</span> <span class="n">xgb_n_estimators</span><span class="p">,</span>
      <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="n">xgb_max_depths</span><span class="p">,</span>
      <span class="s2">&quot;xgb__subsample&quot;</span><span class="p">:</span> <span class="n">xgb_subsamples</span><span class="p">,</span>
      <span class="s2">&quot;xgb__colsample_bytree&quot;</span><span class="p">:</span> <span class="n">xgb_colsample_bytree</span><span class="p">,</span>
      <span class="s2">&quot;xgb__eval_metric&quot;</span><span class="p">:</span> <span class="n">xgb_eval_metric</span><span class="p">,</span>
      <span class="s2">&quot;xgb__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="n">xgb_early_stopping_rounds</span><span class="p">,</span>
      <span class="s2">&quot;xgb__verbose&quot;</span><span class="p">:</span> <span class="n">xgb_verbose</span><span class="p">,</span>
      <span class="s2">&quot;selectKBest__k&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
   <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>Step 5: Initialize and Configure the model_tuner</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize model_tuner</span>
<span class="n">model_tuner</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="s2">&quot;XGBoost_Breast_Cancer&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name_xgb</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_model</span><span class="p">,</span>
   <span class="n">xgboost_early</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">impute</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">scaler_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Turn off scaling for XGBoost</span>
   <span class="n">selectKBest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">xgb_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 6: Perform Grid Search Parameter Tuning</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform grid search parameter tuning</span>
<span class="n">model_tuner</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 7: Fit the Model</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the training and validation data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Fit the model with the validation data</span>
<span class="n">model_tuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">score</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 8: Return Metrics (Optional)</strong></p>
<p>You can use this function to evaluate the model by printing the output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Return metrics for the validation set</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 9: Calibrate the Model (if needed)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calibrate the model</span>
<span class="k">if</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">calibrate</span><span class="p">:</span>
   <span class="n">model_tuner</span><span class="o">.</span><span class="n">calibrateModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>

<span class="c1"># Predict on the validation set</span>
<span class="n">y_valid_pred</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="binary-classification-output">
<h2>Binary Classification Output<a class="headerlink" href="#binary-classification-output" title="Link to this heading"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">100</span>%<span class="p">|</span>██████████<span class="p">|</span><span class="w"> </span><span class="m">324</span>/324<span class="w"> </span><span class="o">[</span><span class="m">15</span>:39&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">2</span>.90s/it<span class="o">]</span>
Best<span class="w"> </span>score/param<span class="w"> </span><span class="nb">set</span><span class="w"> </span>found<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span>set:
<span class="o">{</span><span class="s1">&#39;params&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;selectKBest__k&#39;</span>:<span class="w"> </span><span class="m">20</span>,
<span class="w">            </span><span class="s1">&#39;xgb__colsample_bytree&#39;</span>:<span class="w"> </span><span class="m">0</span>.8,
<span class="w">            </span><span class="s1">&#39;xgb__early_stopping_rounds&#39;</span>:<span class="w"> </span><span class="m">10</span>,
<span class="w">            </span><span class="s1">&#39;xgb__eval_metric&#39;</span>:<span class="w"> </span><span class="s1">&#39;logloss&#39;</span>,
<span class="w">            </span><span class="s1">&#39;xgb__learning_rate&#39;</span>:<span class="w"> </span><span class="m">0</span>.1,
<span class="w">            </span><span class="s1">&#39;xgb__max_depth&#39;</span>:<span class="w"> </span><span class="m">3</span>,
<span class="w">            </span><span class="s1">&#39;xgb__n_estimators&#39;</span>:<span class="w"> </span><span class="m">200</span>,
<span class="w">            </span><span class="s1">&#39;xgb__subsample&#39;</span>:<span class="w"> </span><span class="m">0</span>.8,
<span class="w">            </span><span class="s1">&#39;xgb__verbose&#39;</span>:<span class="w"> </span>False<span class="o">}</span>,
<span class="s1">&#39;score&#39;</span>:<span class="w"> </span><span class="m">0</span>.9987212276214834<span class="o">}</span>
Best<span class="w"> </span>roc_auc:<span class="w"> </span><span class="m">0</span>.999

Confusion<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span>set:
--------------------------------------------------------------------------------
<span class="w">         </span>Predicted:
<span class="w">            </span>Pos<span class="w">  </span>Neg
--------------------------------------------------------------------------------
Actual:<span class="w"> </span>Pos<span class="w"> </span><span class="m">46</span><span class="w"> </span><span class="o">(</span>tp<span class="o">)</span><span class="w">   </span><span class="m">0</span><span class="w"> </span><span class="o">(</span>fn<span class="o">)</span>
<span class="w">      </span>Neg<span class="w">  </span><span class="m">3</span><span class="w"> </span><span class="o">(</span>fp<span class="o">)</span><span class="w">  </span><span class="m">65</span><span class="w"> </span><span class="o">(</span>tn<span class="o">)</span>
--------------------------------------------------------------------------------

<span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.94<span class="w">      </span><span class="m">1</span>.00<span class="w">      </span><span class="m">0</span>.97<span class="w">        </span><span class="m">46</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">1</span>.00<span class="w">      </span><span class="m">0</span>.96<span class="w">      </span><span class="m">0</span>.98<span class="w">        </span><span class="m">68</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.97<span class="w">      </span><span class="m">0</span>.98<span class="w">      </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.98<span class="w">      </span><span class="m">0</span>.97<span class="w">      </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>

--------------------------------------------------------------------------------

Feature<span class="w"> </span>names<span class="w"> </span>selected:
<span class="o">[</span><span class="s1">&#39;mean radius&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean texture&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean perimeter&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean area&#39;</span>,
<span class="s1">&#39;mean compactness&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean concavity&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean concave points&#39;</span>,
<span class="s1">&#39;radius error&#39;</span>,<span class="w"> </span><span class="s1">&#39;perimeter error&#39;</span>,<span class="w"> </span><span class="s1">&#39;area error&#39;</span>,<span class="w"> </span><span class="s1">&#39;concavity error&#39;</span>,
<span class="s1">&#39;concave points error&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst radius&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst texture&#39;</span>,
<span class="s1">&#39;worst perimeter&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst area&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst smoothness&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst compactness&#39;</span>,
<span class="s1">&#39;worst concavity&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst concave points&#39;</span><span class="o">]</span>

<span class="o">{</span><span class="s1">&#39;Classification Report&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;0&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;precision&#39;</span>:<span class="w"> </span><span class="m">0</span>.9387755102040817,<span class="w"> </span><span class="s1">&#39;recall&#39;</span>:<span class="w"> </span><span class="m">1</span>.0,
<span class="s1">&#39;f1-score&#39;</span>:<span class="w"> </span><span class="m">0</span>.968421052631579,<span class="w"> </span><span class="s1">&#39;support&#39;</span>:<span class="w"> </span><span class="m">46</span>.0<span class="o">}</span>,<span class="w"> </span><span class="s1">&#39;1&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;precision&#39;</span>:<span class="w"> </span><span class="m">1</span>.0,<span class="w"> </span><span class="s1">&#39;recall&#39;</span>:
<span class="m">0</span>.9558823529411765,<span class="w"> </span><span class="s1">&#39;f1-score&#39;</span>:<span class="w"> </span><span class="m">0</span>.9774436090225563,<span class="w"> </span><span class="s1">&#39;support&#39;</span>:<span class="w"> </span><span class="m">68</span>.0<span class="o">}</span>,<span class="w"> </span><span class="s1">&#39;accuracy&#39;</span>:
<span class="m">0</span>.9736842105263158,<span class="w"> </span><span class="s1">&#39;macro avg&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;precision&#39;</span>:<span class="w"> </span><span class="m">0</span>.9693877551020409,<span class="w"> </span><span class="s1">&#39;recall&#39;</span>:
<span class="m">0</span>.9779411764705883,<span class="w"> </span><span class="s1">&#39;f1-score&#39;</span>:<span class="w"> </span><span class="m">0</span>.9729323308270676,<span class="w"> </span><span class="s1">&#39;support&#39;</span>:<span class="w"> </span><span class="m">114</span>.0<span class="o">}</span>,<span class="w"> </span><span class="s1">&#39;weighted</span>
<span class="s1">avg&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;precision&#39;</span>:<span class="w"> </span><span class="m">0</span>.9752953813104189,<span class="w"> </span><span class="s1">&#39;recall&#39;</span>:<span class="w"> </span><span class="m">0</span>.9736842105263158,<span class="w"> </span><span class="s1">&#39;f1-score&#39;</span>:
<span class="m">0</span>.9738029283735655,<span class="w"> </span><span class="s1">&#39;support&#39;</span>:<span class="w"> </span><span class="m">114</span>.0<span class="o">}}</span>,<span class="w"> </span><span class="s1">&#39;Confusion Matrix&#39;</span>:<span class="w"> </span>array<span class="o">([[</span><span class="m">46</span>,<span class="w">  </span><span class="m">0</span><span class="o">]</span>,
<span class="o">[</span><span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">65</span><span class="o">]])</span>,<span class="w"> </span><span class="s1">&#39;K Best Features&#39;</span>:<span class="w"> </span><span class="o">[</span><span class="s1">&#39;mean radius&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean texture&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean perimeter&#39;</span>,
<span class="s1">&#39;mean area&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean compactness&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean concavity&#39;</span>,<span class="w"> </span><span class="s1">&#39;mean concave points&#39;</span>,
<span class="s1">&#39;radius error&#39;</span>,<span class="w"> </span><span class="s1">&#39;perimeter error&#39;</span>,<span class="w"> </span><span class="s1">&#39;area error&#39;</span>,<span class="w"> </span><span class="s1">&#39;concavity error&#39;</span>,<span class="w"> </span><span class="s1">&#39;concave</span>
<span class="s1">points error&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst radius&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst texture&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst perimeter&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst area&#39;</span>,
<span class="s1">&#39;worst smoothness&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst compactness&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst concavity&#39;</span>,<span class="w"> </span><span class="s1">&#39;worst concave</span>
<span class="s1">points&#39;</span><span class="o">]}</span>
Confusion<span class="w"> </span>matrix<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span><span class="nb">set</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>roc_auc
--------------------------------------------------------------------------------
<span class="w">         </span>Predicted:
<span class="w">            </span>Pos<span class="w">  </span>Neg
--------------------------------------------------------------------------------
Actual:<span class="w"> </span>Pos<span class="w"> </span><span class="m">46</span><span class="w"> </span><span class="o">(</span>tp<span class="o">)</span><span class="w">   </span><span class="m">0</span><span class="w"> </span><span class="o">(</span>fn<span class="o">)</span>
<span class="w">      </span>Neg<span class="w">  </span><span class="m">3</span><span class="w"> </span><span class="o">(</span>fp<span class="o">)</span><span class="w">  </span><span class="m">65</span><span class="w"> </span><span class="o">(</span>tn<span class="o">)</span>
--------------------------------------------------------------------------------

<span class="w">            </span>precision<span class="w">    </span>recall<span class="w">  </span>f1-score<span class="w">   </span>support

<span class="w">         </span><span class="m">0</span><span class="w">       </span><span class="m">0</span>.94<span class="w">      </span><span class="m">1</span>.00<span class="w">      </span><span class="m">0</span>.97<span class="w">        </span><span class="m">46</span>
<span class="w">         </span><span class="m">1</span><span class="w">       </span><span class="m">1</span>.00<span class="w">      </span><span class="m">0</span>.96<span class="w">      </span><span class="m">0</span>.98<span class="w">        </span><span class="m">68</span>

<span class="w">   </span>accuracy<span class="w">                           </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>
<span class="w">   </span>macro<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.97<span class="w">      </span><span class="m">0</span>.98<span class="w">      </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>
weighted<span class="w"> </span>avg<span class="w">       </span><span class="m">0</span>.98<span class="w">      </span><span class="m">0</span>.97<span class="w">      </span><span class="m">0</span>.97<span class="w">       </span><span class="m">114</span>

--------------------------------------------------------------------------------
roc_auc<span class="w"> </span>after<span class="w"> </span>calibration:<span class="w"> </span><span class="m">0</span>.9987212276214834
</pre></div>
</div>
</section>
<section id="regression">
<h2>Regression<a class="headerlink" href="#regression" title="Link to this heading"></a></h2>
<p>Here is an example of using the <code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> class for regression using XGBoost on the California Housing dataset.</p>
<p><strong>California Housing with XGBoost</strong></p>
<p><strong>Step 1: Import Necessary Libraries</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">model_tuner</span>
</pre></div>
</div>
<p><strong>Step 2: Load the Dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the California Housing dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3: Create an Instance of the XGBClassifier</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating an instance of the XGBRegressor</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 4: Define Hyperparameters for XGBoost</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimator name prefix for use in GridSearchCV or similar tools</span>
<span class="n">estimator_name_xgb</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>

<span class="c1"># Define the hyperparameters for XGBoost</span>
<span class="n">xgb_learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="n">xgb_n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">xgb_max_depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">xgb_subsamples</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">xgb_colsample_bytree</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>

<span class="c1"># Combining the hyperparameters in a dictionary</span>
<span class="n">xgb_parameters</span> <span class="o">=</span> <span class="p">[</span>
   <span class="p">{</span>
      <span class="s2">&quot;xgb__learning_rate&quot;</span><span class="p">:</span> <span class="n">xgb_learning_rates</span><span class="p">,</span>
      <span class="s2">&quot;xgb__n_estimators&quot;</span><span class="p">:</span> <span class="n">xgb_n_estimators</span><span class="p">,</span>
      <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="n">xgb_max_depths</span><span class="p">,</span>
      <span class="s2">&quot;xgb__subsample&quot;</span><span class="p">:</span> <span class="n">xgb_subsamples</span><span class="p">,</span>
      <span class="s2">&quot;xgb__colsample_bytree&quot;</span><span class="p">:</span> <span class="n">xgb_colsample_bytree</span><span class="p">,</span>
      <span class="s2">&quot;selectKBest__k&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
   <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>Step 5: Initialize and Configure the ``model_tuner``</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize model_tuner</span>
<span class="n">model_tuner</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="s2">&quot;XGBoost_California_Housing&quot;</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;regression&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name_xgb</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_model</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">impute</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">scaler_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
   <span class="n">selectKBest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">xgb_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 6: Fit the Model</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the training and validation data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Fit the model with the validation data</span>
<span class="n">model_tuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
   <span class="n">score</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 7: Return Metrics (Optional)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Return metrics for the validation set</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model_tuner</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="regression-output">
<h2>Regression Output<a class="headerlink" href="#regression-output" title="Link to this heading"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">100</span>%<span class="p">|</span>██████████<span class="p">|</span><span class="w"> </span><span class="m">432</span>/432<span class="w"> </span><span class="o">[</span><span class="m">04</span>:10&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">1</span>.73it/s<span class="o">]</span>
Best<span class="w"> </span>score/param<span class="w"> </span><span class="nb">set</span><span class="w"> </span>found<span class="w"> </span>on<span class="w"> </span>validation<span class="w"> </span>set:
<span class="o">{</span><span class="s1">&#39;params&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;selectKBest__k&#39;</span>:<span class="w"> </span><span class="m">8</span>,
<span class="w">            </span><span class="s1">&#39;xgb__colsample_bytree&#39;</span>:<span class="w"> </span><span class="m">0</span>.8,
<span class="w">            </span><span class="s1">&#39;xgb__learning_rate&#39;</span>:<span class="w"> </span><span class="m">0</span>.05,
<span class="w">            </span><span class="s1">&#39;xgb__max_depth&#39;</span>:<span class="w"> </span><span class="m">7</span>,
<span class="w">            </span><span class="s1">&#39;xgb__n_estimators&#39;</span>:<span class="w"> </span><span class="m">300</span>,
<span class="w">            </span><span class="s1">&#39;xgb__subsample&#39;</span>:<span class="w"> </span><span class="m">0</span>.8<span class="o">}</span>,
<span class="s1">&#39;score&#39;</span>:<span class="w"> </span>-0.21038206511437127<span class="o">}</span>
Best<span class="w"> </span>neg_mean_squared_error:<span class="w"> </span>-0.210

********************************************************************************
<span class="o">{</span><span class="s1">&#39;Explained Variance&#39;</span>:<span class="w"> </span><span class="m">0</span>.8385815985957561,
<span class="s1">&#39;Mean Absolute Error&#39;</span>:<span class="w"> </span><span class="m">0</span>.3008222037008959,
<span class="s1">&#39;Mean Squared Error&#39;</span>:<span class="w"> </span><span class="m">0</span>.21038206511437127,
<span class="s1">&#39;Median Absolute Error&#39;</span>:<span class="w"> </span><span class="m">0</span>.196492121219635,
<span class="s1">&#39;R2&#39;</span>:<span class="w"> </span><span class="m">0</span>.8385811859863378,
<span class="s1">&#39;RMSE&#39;</span>:<span class="w"> </span><span class="m">0</span>.45867424727618106<span class="o">}</span>
********************************************************************************

Feature<span class="w"> </span>names<span class="w"> </span>selected:
<span class="o">[</span><span class="s1">&#39;MedInc&#39;</span>,<span class="w"> </span><span class="s1">&#39;HouseAge&#39;</span>,<span class="w"> </span><span class="s1">&#39;AveRooms&#39;</span>,<span class="w"> </span><span class="s1">&#39;AveBedrms&#39;</span>,<span class="w"> </span><span class="s1">&#39;Population&#39;</span>,
<span class="s1">&#39;AveOccup&#39;</span>,<span class="w"> </span><span class="s1">&#39;Latitude&#39;</span>,<span class="w"> </span><span class="s1">&#39;Longitude&#39;</span><span class="o">]</span>

<span class="o">{</span><span class="s1">&#39;Regression Report&#39;</span>:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;Explained Variance&#39;</span>:<span class="w"> </span><span class="m">0</span>.8385815985957561,<span class="w"> </span><span class="s1">&#39;R2&#39;</span>:
<span class="m">0</span>.8385811859863378,<span class="w"> </span><span class="s1">&#39;Mean Absolute Error&#39;</span>:<span class="w"> </span><span class="m">0</span>.3008222037008959,<span class="w"> </span><span class="s1">&#39;Median</span>
<span class="s1">Absolute Error&#39;</span>:<span class="w"> </span><span class="m">0</span>.196492121219635,<span class="w"> </span><span class="s1">&#39;Mean Squared Error&#39;</span>:
<span class="m">0</span>.21038206511437127,<span class="w"> </span><span class="s1">&#39;RMSE&#39;</span>:<span class="w"> </span><span class="m">0</span>.45867424727618106<span class="o">}</span>,<span class="w"> </span><span class="s1">&#39;K Best Features&#39;</span>:
<span class="o">[</span><span class="s1">&#39;MedInc&#39;</span>,<span class="w"> </span><span class="s1">&#39;HouseAge&#39;</span>,<span class="w"> </span><span class="s1">&#39;AveRooms&#39;</span>,<span class="w"> </span><span class="s1">&#39;AveBedrms&#39;</span>,<span class="w"> </span><span class="s1">&#39;Population&#39;</span>,
<span class="s1">&#39;AveOccup&#39;</span>,<span class="w"> </span><span class="s1">&#39;Latitude&#39;</span>,<span class="w"> </span><span class="s1">&#39;Longitude&#39;</span><span class="o">]}</span>
</pre></div>
</div>
</section>
<section id="ipython-notebooks">
<h2>iPython Notebooks<a class="headerlink" href="#ipython-notebooks" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/drive/1D9nl8rLdwxPEpiZplsU0I0lFSAec7NzP?authuser=1#scrollTo=tumIjsNpSAKC&amp;uniqifier=1">Binary Classification Example</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/drive/151kdlsW-WyJ0pwwt_iWpjXDuqj1Ktam_?authuser=1#scrollTo=UhfZKVoq3sAN">Regression Example</a></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="getting_started.html" class="btn btn-neutral float-left" title="Welcome to Model Tuner’s Documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="changelog.html" class="btn btn-neutral float-right" title="Changelog" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, UCLA CTSI ML Team: Leonid Shpaner, Arthur Funnell, Panayiotis Petousis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>