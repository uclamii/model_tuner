

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>iPython Notebooks &mdash; Model Tuner 0.0.23a0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=72ec8e44" />

  
    <link rel="canonical" href="https://uclamii.github.io/model_tuner/usage_guide.html" />
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=2b808d0e"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
      <script src="_static/custom.js?v=59429b38"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Zero Variance Columns" href="caveats.html" />
    <link rel="prev" title="Welcome to Model Tuner’s Documentation!" href="getting_started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Model Tuner
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Welcome to Model Tuner’s Documentation!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">iPython Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#binary-classification-examples">Binary Classification Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-example">Regression Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#input-parameters">Input Parameters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#key-methods-and-functionalities">Key Methods and Functionalities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#init"><code class="docutils literal notranslate"><span class="pre">__init__(...)</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#reset-estimator"><code class="docutils literal notranslate"><span class="pre">reset_estimator()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#process-imbalance-sampler"><code class="docutils literal notranslate"><span class="pre">process_imbalance_sampler()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#calibratemodel"><code class="docutils literal notranslate"><span class="pre">calibrateModel()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#get-train-val-test-data">Get train, val, test data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#get-train-data"><code class="docutils literal notranslate"><span class="pre">get_train_data()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#get-valid-data"><code class="docutils literal notranslate"><span class="pre">get_valid_data()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#get-test-data"><code class="docutils literal notranslate"><span class="pre">get_test_data()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#calibrate-report"><code class="docutils literal notranslate"><span class="pre">calibrate_report()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#fit"><code class="docutils literal notranslate"><span class="pre">fit()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#return-metrics"><code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#return_metrics"><code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#grid-search-param-tuning"><code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#print-selected-best-features"><code class="docutils literal notranslate"><span class="pre">print_selected_best_features()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#tune-threshold-fbeta"><code class="docutils literal notranslate"><span class="pre">tune_threshold_Fbeta()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#train-val-test-split"><code class="docutils literal notranslate"><span class="pre">train_val_test_split()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#get-best-score-params"><code class="docutils literal notranslate"><span class="pre">get_best_score_params()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#conf-mat-class-kfold"><code class="docutils literal notranslate"><span class="pre">conf_mat_class_kfold()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-report-kfold"><code class="docutils literal notranslate"><span class="pre">regression_report_kfold()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-report"><code class="docutils literal notranslate"><span class="pre">regression_report()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#report-model-metrics"><code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#helper-functions">Helper Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#kfold-split"><code class="docutils literal notranslate"><span class="pre">kfold_split()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#get-cross-validate"><code class="docutils literal notranslate"><span class="pre">get_cross_validate()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#confusion-matrix-print"><code class="docutils literal notranslate"><span class="pre">_confusion_matrix_print()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#print-pipeline"><code class="docutils literal notranslate"><span class="pre">print_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#pipeline-management">Pipeline Management</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#specifying-pipeline-steps">Specifying Pipeline Steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helper-methods-for-pipeline-extraction">Helper Methods for Pipeline Extraction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#get_preprocessing_and_feature_selection_pipeline"><code class="docutils literal notranslate"><span class="pre">get_preprocessing_and_feature_selection_pipeline()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#get_feature_selection_pipeline"><code class="docutils literal notranslate"><span class="pre">get_feature_selection_pipeline()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#get_preprocessing_pipeline"><code class="docutils literal notranslate"><span class="pre">get_preprocessing_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#binary-classification">Binary Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#aids-clinical-trials-group-study">AIDS Clinical Trials Group Study</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-import-necessary-libraries">Step 1: Import Necessary libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-load-the-dataset-define-x-y">Step 2: Load the dataset, define X, y</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-check-for-zero-variance-columns-and-drop-accordingly">Step 3: Check for zero-variance columns and drop accordingly</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-create-an-instance-of-the-xgbclassifier">Step 4: Create an instance of the XGBClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-define-hyperparameters-for-xgboost">Step 5: Define Hyperparameters for XGBoost</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-6-initialize-and-configure-the-model">Step 6: Initialize and configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-7-perform-grid-search-parameter-tuning-and-retrieve-split-data">Step 7: Perform grid search parameter tuning and retrieve split data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-8-fit-the-model">Step 8: Fit the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-9-return-metrics-optional">Step 9: Return metrics (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-10-calibrate-the-model-if-needed">Step 10: Calibrate the model (if needed)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#f1-beta-threshold-tuning">F1 Beta Threshold Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#understanding-f1-beta-score">Understanding F1 Beta Score</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-usage-default-beta-1">Example usage: default (beta = 1)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-usage-custom-betas-higher-recall">Example usage: custom betas (higher recall)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-usage-custom-betas-higher-precision">Example usage: custom betas (higher precision)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#imbalanced-learning">Imbalanced Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#generating-an-imbalanced-dataset">Generating an imbalanced dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-hyperparameters-for-xgboost">Define hyperparameters for XGBoost</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-the-model-object">Define the model object</a></li>
<li class="toctree-l3"><a class="reference internal" href="#addressing-class-imbalance-in-machine-learning">Addressing Class Imbalance in Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#techniques-to-address-class-imbalance">Techniques to Address Class Imbalance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#purpose-of-using-these-techniques">Purpose of Using These Techniques</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#synthetic-minority-oversampling-technique-smote">Synthetic Minority Oversampling Technique (SMOTE)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#step-1-initalize-and-configure-the-model">Step 1: Initalize and configure the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-2-perform-grid-search-parameter-tuning-and-retrieve-split-data">Step 2: Perform grid search parameter tuning and retrieve split data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#smote-distribution-of-y-values-after-resampling">SMOTE: Distribution of y values after resampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-3-fit-the-model">Step 3: Fit the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-4-return-metrics-optional">Step 4: Return metrics (optional)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#recursive-feature-elimination-rfe">Recursive Feature Elimination (RFE)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#elastic-net-for-feature-selection-with-rfe">Elastic Net for feature selection with RFE</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#shap-shapley-additive-explanations">SHAP (SHapley Additive exPlanations)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-transform-the-test-data-using-the-feature-selection-pipeline">Step 1: Transform the test data using the feature selection pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-retrieve-the-trained-xgboost-classifier-from-the-pipeline">Step 2: Retrieve the trained XGBoost classifier from the pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-extract-feature-names-from-the-training-data-and-initialize-the-shap-explainer-for-the-xgboost-classifier">Step 3: Extract feature names from the training data, and initialize the SHAP explainer for the XGBoost classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-compute-shap-values-for-the-transformed-test-dataset-and-generate-a-summary-plot-of-shap-values">Step 4: Compute SHAP values for the transformed test dataset and generate a summary plot of SHAP values</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-generate-a-summary-plot-of-shap-values">Step 5: Generate a summary plot of SHAP values</a></li>
<li class="toctree-l3"><a class="reference internal" href="#feature-importance-and-impact">Feature Importance and Impact</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#multi-class-classification">Multi-Class Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#iris-dataset-with-xgboost">Iris Dataset with XGBoost</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">Step 1: Import Necessary Libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Step 2: Load the dataset. Define X, y</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-define-the-preprocessing-steps">Step 3: Define the preprocessing steps</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-define-the-estimator-and-hyperparameters">Step 4: Define the estimator and hyperparameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-5-initialize-and-configure-the-model">Step 5: Initialize and configure the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-6-perform-grid-search-parameter-tuning">Step 6: Perform grid search parameter tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-7-generate-data-splits">Step 7: Generate data splits</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">Step 8: Fit the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">Step 9: Return metrics (optional)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">Report Model Metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#step-10-predict-probabilities-and-generate-predictions">Step 10: Predict probabilities and generate predictions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#regression">Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#california-housing-with-xgboost">California Housing with XGBoost</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">Step 1: Import necessary libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-load-the-dataset">Step 2: Load the dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-create-an-instance-of-the-xgbregressor">Step 3: Create an instance of the XGBRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-4-define-hyperparameters-for-xgbregressor">Step 4: Define Hyperparameters for XGBRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">Step 5: Initialize and configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-6-perform-grid-search-parameter-tuning-and-retrieve-split-data">Step 6: Perform grid search parameter tuning and retrieve split data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-7-fit-the-model">Step 7: Fit the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-8-return-metrics-optional">Step 8: Return metrics (optional)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#performance-evaluation-metrics">Performance Evaluation Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-report-model-metrics">Using <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-return-metrics">Using <code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#threshold-tuning">Threshold Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-automatically-tune-thresholds">How to Automatically Tune Thresholds</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-threshold-in-report-model-metrics">Using threshold in <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#reporting-threshold-in-return-metrics">Reporting Threshold in <code class="docutils literal notranslate"><span class="pre">return_metrics</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#classification-report-optional">Classification report (optional)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#bootstrap-metrics">Bootstrap Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#check_input_type"><code class="docutils literal notranslate"><span class="pre">check_input_type()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#sampling_method"><code class="docutils literal notranslate"><span class="pre">sampling_method()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#evaluate_bootstrap_metrics"><code class="docutils literal notranslate"><span class="pre">evaluate_bootstrap_metrics()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#return_bootstrap_metrics"><code class="docutils literal notranslate"><span class="pre">return_bootstrap_metrics()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#bootstrap-metrics-example">Bootstrap metrics example</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Caveats</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="caveats.html">Zero Variance Columns</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#dependent-variable">Dependent Variable</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#scaling-before-imputation">Scaling Before Imputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#column-stratification-with-cross-validation">Column Stratification with Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#model-calibration">Model Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#using-imputation-and-scaling-in-pipeline-steps-for-model-preprocessing">Using Imputation and Scaling in Pipeline Steps for Model Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#caveats-in-imbalanced-learning">Caveats in Imbalanced Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#threshold-tuning-considerations">Threshold Tuning Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#elasticnet-regularization">ElasticNet Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="caveats.html#catboost-training-parameters">CatBoost Training Parameters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About Model Tuner</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">GitHub Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#acknowledgements">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#citing-model-tuner">Citing Model Tuner</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Model Tuner</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">iPython Notebooks</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="no-click"><a class="reference internal image-reference" href="_images/ModelTunerTarget.png"><img alt="Model Tuner Logo" class="align-left" src="_images/ModelTunerTarget.png" style="width: 250px;" />
</a>
</div><div style="height: 150px;"></div><p></p>
<section id="ipython-notebooks">
<h1>iPython Notebooks<a class="headerlink" href="#ipython-notebooks" title="Link to this heading"></a></h1>
<section id="binary-classification-examples">
<h2>Binary Classification Examples<a class="headerlink" href="#binary-classification-examples" title="Link to this heading"></a></h2>
<blockquote>
<div><p><strong>Google Colab Notebooks</strong></p>
<ul>
<li><a href="https://colab.research.google.com/drive/1bP0DzSYgV0ncHlkJq9uV3pUXn8PaR31z#scrollTo=OTWiK2ZwdeMK" target="_blank">Binary Classification + KFold Example: Titanic Dataset - Categorical Data</a></li>
<li><a href="https://colab.research.google.com/drive/12XywbGBiwlZIbi0C3JKu9NOQPPRgVwcp?usp=sharing#scrollTo=rm5TA__pC3M-" target="_blank">Binary Classification: AIDS Clinical Trials - Numerical Data</a></li>
<li><a href="https://colab.research.google.com/drive/16gWnRAJvpUjTIes5y1gFRdX1soASdV6m#scrollTo=3NYa_tQWy6HR" target="_blank">Binary Classification: Imbalanced Learning</a></li>
</ul>
<p><strong>HTML Files</strong></p>
<ul>
<li><a href="./example_htmls/Model_Tuner_Column_Transformer.html" target="_blank">Binary Classification + KFold Example: Titanic Dataset - Categorical Data</a></li>
<li><a href="./example_htmls/Model_Tuner_Binary_Classification_AIDS_Clinical_Trials.html" target="_blank">Binary Classification: AIDS Clinical Trials HTML File</a></li>
<li><a href="./example_htmls/Model_Tuner_Binary_Classification_Imbalanced_Learning.html" target="_blank">Binary Classification: Imbalanced Learning</a></li>
</ul>
</div></blockquote>
</section>
<section id="regression-example">
<h2>Regression Example<a class="headerlink" href="#regression-example" title="Link to this heading"></a></h2>
<blockquote>
<div><p><strong>Google Colab Notebook</strong></p>
<ul>
<li><a href="https://colab.research.google.com/drive/151kdlsW-WyJ0pwwt_iWpjXDuqj1Ktam_?authuser=1#scrollTo=UhfZKVoq3sAN" target="_blank">Redfin Real Estate - Los Angeles Data Colab Notebook</a></li>
</ul>
<p><strong>HTML File</strong></p>
<ul>
<li><a href="./example_htmls/Model_Tuner_Regression_Redfin_Real_Estate.html" target="_blank">Redfin Real Estate - Los Angeles Data HTML File</a></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This class is designed to be flexible and can be extended to include additional functionalities or custom metrics.</p></li>
<li><p>It is essential to properly configure the parameters during initialization to suit the specific requirements of your machine learning task.</p></li>
<li><p>Ensure that all dependencies are installed and properly imported before using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class from the <code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> library.</p></li>
</ul>
</div>
</section>
</section>
<section id="input-parameters">
<h1>Input Parameters<a class="headerlink" href="#input-parameters" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kfold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imbalance_sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['roc_auc']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomized_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boost_early</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_selection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sigmoid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_scorer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bayesian</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Model" title="Link to this definition"></a></dt>
<dd><p>A class for building, tuning, and evaluating machine learning models, supporting both classification and regression tasks, as well as multi-label classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – A unique name for the model, helpful for tracking outputs and logs.</p></li>
<li><p><strong>estimator_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Prefix for the estimator in the pipeline, used for setting parameters in tuning (e.g., estimator_name + <code class="docutils literal notranslate"><span class="pre">__param_name</span></code>).</p></li>
<li><p><strong>estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The machine learning model to be trained and tuned.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Specifies the type of model, must be either <code class="docutils literal notranslate"><span class="pre">classification</span></code> or <code class="docutils literal notranslate"><span class="pre">regression</span></code>.</p></li>
<li><p><strong>calibrate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to calibrate the model’s probability estimates. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>kfold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to perform k-fold cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>imbalance_sampler</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a><em>, </em><em>optional</em>) – An imbalanced data sampler from the imblearn library, e.g., <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code> or <code class="docutils literal notranslate"><span class="pre">RandomOverSampler</span></code>.</p></li>
<li><p><strong>train_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for training. Default is <code class="docutils literal notranslate"><span class="pre">0.6</span></code>.</p></li>
<li><p><strong>validation_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for validation. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>test_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to be used for testing. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>stratify_y</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to stratify by the target variable during data splitting. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>stratify_cols</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, or </em><em>pandas.DataFrame</em><em>, </em><em>optional</em>) – Columns to use for stratification during data splitting.
Can be a single column name (as a string), a list of column names (as strings),
or a DataFrame containing the columns for stratification. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>grid</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Hyperparameter grid for model tuning, supporting both regular and Bayesian search.</p></li>
<li><p><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – List of scoring metrics for evaluation, e.g., <code class="docutils literal notranslate"><span class="pre">[&quot;roc_auc&quot;,</span> <span class="pre">&quot;accuracy&quot;]</span></code>.</p></li>
<li><p><strong>n_splits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of splits for k-fold cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed for random number generation to ensure reproducibility. Default is <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of parallel jobs to run for model fitting. Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><strong>display</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to print messages during the tuning and training process. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>randomized_grid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use randomized grid search. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>n_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of iterations for randomized grid search. Default is <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><strong>pipeline_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – List of steps for the pipeline, e.g., preprocessing and feature selection steps. Default is <code class="docutils literal notranslate"><span class="pre">[]</span></code>.</p></li>
<li><p><strong>boost_early</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to enable early stopping for boosting algorithms like XGBoost. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>feature_selection</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to enable feature selection. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>class_labels</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – List of labels for multi-class classification. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>multi_label</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether the task is a multi-label classification problem. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>calibration_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Method for calibration; options include <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> and <code class="docutils literal notranslate"><span class="pre">isotonic</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>.</p></li>
<li><p><strong>custom_scorer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><em>optional</em>) – Dictionary of custom scoring functions, allowing additional metrics to be evaluated. Default is <code class="docutils literal notranslate"><span class="pre">[]</span></code>.</p></li>
<li><p><strong>bayesian</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to perform Bayesian hyperparameter tuning using <code class="docutils literal notranslate"><span class="pre">BayesSearchCV</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ImportError" title="(in Python v3.13)"><strong>ImportError</strong></a> – If the <code class="docutils literal notranslate"><span class="pre">bootstrapper</span></code> module is not found or not installed.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised for various issues, such as:
- Invalid <code class="docutils literal notranslate"><span class="pre">model_type</span></code> value. The <code class="docutils literal notranslate"><span class="pre">model_type</span></code> must be explicitly specified as either <code class="docutils literal notranslate"><span class="pre">classification</span></code> or <code class="docutils literal notranslate"><span class="pre">regression</span></code>.
- Invalid hyperparameter configurations or mismatched <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> shapes.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – Raised if an expected pipeline step is missing, or if <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> is improperly initialized.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – Raised when an incorrect parameter type is provided, such as passing <code class="docutils literal notranslate"><span class="pre">None</span></code> instead of a valid object.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#IndexError" title="(in Python v3.13)"><strong>IndexError</strong></a> – Raised for indexing issues, particularly in confusion matrix formatting functions.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised when accessing dictionary keys that are not available, such as missing scores in <code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.13)"><strong>RuntimeError</strong></a> – Raised for unexpected issues during model fitting or transformations that do not fit into the other exception categories.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="key-methods-and-functionalities">
<h1>Key Methods and Functionalities<a class="headerlink" href="#key-methods-and-functionalities" title="Link to this heading"></a></h1>
<section id="init">
<h2><code class="docutils literal notranslate"><span class="pre">__init__(...)</span></code><a class="headerlink" href="#init" title="Link to this heading"></a></h2>
<blockquote>
<div><p>Initializes the model tuner with configurations, including estimator, cross-validation settings, scoring metrics, pipeline steps, feature selection, imbalance sampler, Bayesian search, and model calibration options.</p>
</div></blockquote>
</section>
<section id="reset-estimator">
<h2><code class="docutils literal notranslate"><span class="pre">reset_estimator()</span></code><a class="headerlink" href="#reset-estimator" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reset_estimator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Resets the estimator and pipeline configuration.</p>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This function reinitializes the <code class="docutils literal notranslate"><span class="pre">estimator</span></code> attribute of the class based on the current pipeline configuration.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">pipeline_steps</span></code> are defined, it creates a new pipeline using <code class="docutils literal notranslate"><span class="pre">self.PipelineClass</span></code> and a deep copy of the steps.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">pipeline_steps</span></code> are not defined, it resets the <code class="docutils literal notranslate"><span class="pre">estimator</span></code> to a single-step pipeline containing the original estimator.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code> is not empty:</p>
<ul>
<li><p>Creates a pipeline using the defined steps.</p></li>
</ul>
</li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code> is empty:</p>
<ul>
<li><p>Resets the <code class="docutils literal notranslate"><span class="pre">estimator</span></code> to a single-step pipeline with the original estimator.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code>: The steps of the pipeline (if defined).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.PipelineClass</span></code>: The class used to construct pipelines.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.estimator_name</span></code>: The name of the primary estimator step.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.original_estimator</span></code>: The original estimator to be reset.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>The function updates the <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> attribute and does not return a value.</p></li>
</ul>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li><p>This function is intended for internal use as a helper function to manage pipeline and estimator states.</p></li>
<li><p>Ensures that the pipeline or estimator is always in a valid state after modifications or resets.</p></li>
</ul>
</dd></dl>

</section>
<section id="process-imbalance-sampler">
<h2><code class="docutils literal notranslate"><span class="pre">process_imbalance_sampler()</span></code><a class="headerlink" href="#process-imbalance-sampler" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">process_imbalance_sampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Processes the imbalance sampler, applying it to resample the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – Training features to be resampled.</p></li>
<li><p><strong>y_train</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – Training target labels to be resampled.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised if the <code class="docutils literal notranslate"><span class="pre">resampler</span></code> step is missing in the pipeline.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if <code class="docutils literal notranslate"><span class="pre">X_train</span></code> or <code class="docutils literal notranslate"><span class="pre">y_train</span></code> are incompatible with the pipeline or resampler.</p></li>
</ul>
</dd>
</dl>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints the class distribution of <code class="docutils literal notranslate"><span class="pre">y_train</span></code> after resampling.</p></li>
<li><p>Does not modify the original <code class="docutils literal notranslate"><span class="pre">X_train</span></code> or <code class="docutils literal notranslate"><span class="pre">y_train</span></code>.</p></li>
</ul>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This function applies an imbalance sampler to resample the training data, ensuring the target distribution is balanced.</p></li>
<li><p>If preprocessing steps are defined in the pipeline, they are applied to the training features before resampling.</p></li>
<li><p>Prints the distribution of <code class="docutils literal notranslate"><span class="pre">y_train</span></code> after resampling to provide visibility into the balance of classes.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>If preprocessing steps exist (<code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code>):</p>
<ul>
<li><p>Applies preprocessing to <code class="docutils literal notranslate"><span class="pre">X_train</span></code> using the preprocessing pipeline obtained from <code class="docutils literal notranslate"><span class="pre">get_preprocessing_pipeline()</span></code>.</p></li>
</ul>
</li>
<li><p>Clones the <code class="docutils literal notranslate"><span class="pre">resampler</span></code> step from the pipeline to ensure independent operation.</p></li>
<li><p>Resamples the training data using the cloned resampler, modifying the distribution of <code class="docutils literal notranslate"><span class="pre">y_train</span></code>.</p></li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code>: Indicates whether preprocessing steps are defined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.get_preprocessing_pipeline()</span></code>: Retrieves the preprocessing pipeline (if available).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.estimator.named_steps[&quot;resampler&quot;]</span></code>: The resampler to apply for balancing the target classes.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The function assumes that the pipeline includes a valid <code class="docutils literal notranslate"><span class="pre">resampler</span></code> step under <code class="docutils literal notranslate"><span class="pre">named_steps</span></code>.</p></li>
<li><p>Ensures compatibility with <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and array-like structures for <code class="docutils literal notranslate"><span class="pre">y_train</span></code>.</p></li>
<li><p>Prints the class distribution of <code class="docutils literal notranslate"><span class="pre">y_train</span></code> after resampling for user awareness.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="calibratemodel">
<h2><code class="docutils literal notranslate"><span class="pre">calibrateModel()</span></code><a class="headerlink" href="#calibratemodel" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">calibrateModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Calibrates the model with cross-validation support and configurable calibration methods, improving probability estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – Feature set used for model calibration.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – Target set corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Optional scoring metric(s) for evaluating the calibration. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if incompatible parameters (e.g., invalid scoring metric) are passed.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised if required attributes or parameters are missing.</p></li>
</ul>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>Supports model calibration with both k-fold cross-validation and a pre-split train-validation-test workflow.</p></li>
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">CalibratedClassifierCV</span></code> for calibration with methods such as <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> or <code class="docutils literal notranslate"><span class="pre">isotonic</span></code> (defined by <code class="docutils literal notranslate"><span class="pre">self.calibration_method</span></code>).</p></li>
<li><p>Handles cases where imbalance sampling or early stopping is applied during training.</p></li>
<li><p>Provides additional support for CPU/GPU device management if applicable.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>With K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Resets the estimator to avoid conflicts with pre-calibrated models.</p></li>
<li><p>Calibrates the model using k-fold splits with the configured calibration method.</p></li>
<li><p>Optionally evaluates calibration using the provided scoring metric(s).</p></li>
<li><p>Generates and prints confusion matrices for each fold (if applicable).</p></li>
</ul>
</li>
<li><p><strong>Without K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Performs a train-validation-test split using <code class="docutils literal notranslate"><span class="pre">train_val_test_split</span></code>.</p></li>
<li><p>Resets the estimator and applies preprocessing or imbalance sampling if configured.</p></li>
<li><p>Fits the model on training data, with or without early stopping.</p></li>
<li><p>Calibrates the pre-trained model on the test set and evaluates calibration results.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.kfold</span></code>: Indicates whether k-fold cross-validation is enabled.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.calibrate</span></code>: Determines whether calibration is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.calibration_method</span></code>: Specifies the calibration method (e.g., <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> or <code class="docutils literal notranslate"><span class="pre">isotonic</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>: Stores the best parameters for each scoring metric.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.n_splits</span></code>: Number of splits for cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.stratify_y</span></code>, <code class="docutils literal notranslate"><span class="pre">self.stratify_cols</span></code>: Used for stratified train-validation-test splitting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.imbalance_sampler</span></code>: Indicates if an imbalance sampler is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.boost_early</span></code>: Enables early stopping during training.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Modifies the class attribute <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> to include the calibrated model.</p></li>
<li><p>Generates calibration reports and scoring metrics if applicable.</p></li>
<li><p>Prints performance metrics (e.g., scores and confusion matrices) for the calibrated model.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>When <code class="docutils literal notranslate"><span class="pre">score</span></code> is provided, the function evaluates calibration using the specified metric(s).</p></li>
<li><p>Requires the estimator to be compatible with <code class="docutils literal notranslate"><span class="pre">CalibratedClassifierCV</span></code>.</p></li>
<li><p>Handles both balanced and imbalanced datasets with preprocessing support.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="get-train-val-test-data">
<h2>Get train, val, test data<a class="headerlink" href="#get-train-val-test-data" title="Link to this heading"></a></h2>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>These functions return subsets of the dataset (features and labels) based on predefined indices stored in the class attributes:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">self.X_train_index</span></code> and <code class="docutils literal notranslate"><span class="pre">self.y_train_index</span></code> for training data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.X_valid_index</span></code> and <code class="docutils literal notranslate"><span class="pre">self.y_valid_index</span></code> for validation data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.X_test_index</span></code> and <code class="docutils literal notranslate"><span class="pre">self.y_test_index</span></code> for test data.</p></li>
</ul>
</li>
<li><p>Designed to work with <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> objects.</p></li>
</ul>
<section id="get-train-data">
<h3><code class="docutils literal notranslate"><span class="pre">get_train_data()</span></code><a class="headerlink" href="#get-train-data" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_train_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Retrieves the training data based on specified indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>) – Full dataset containing features.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>) – Full dataset containing target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the training features and labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-valid-data">
<h3><code class="docutils literal notranslate"><span class="pre">get_valid_data()</span></code><a class="headerlink" href="#get-valid-data" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_valid_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Retrieves the validation data based on specified indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>) – Full dataset containing features.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>) – Full dataset containing target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the validation features and labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-test-data">
<h3><code class="docutils literal notranslate"><span class="pre">get_test_data()</span></code><a class="headerlink" href="#get-test-data" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_test_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Retrieves the test data based on specified indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>) – Full dataset containing features.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>) – Full dataset containing target labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the test features and labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>These methods assume that the indices (e.g., <code class="docutils literal notranslate"><span class="pre">self.X_train_index</span></code>) are defined and valid.</p></li>
<li><p>The methods return subsets of the provided <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> data by indexing the rows based on the stored indices.</p></li>
<li><p>Useful for workflows where train, validation, and test splits are dynamically managed or predefined.</p></li>
</ul>
</div>
</section>
</section>
<section id="calibrate-report">
<h2><code class="docutils literal notranslate"><span class="pre">calibrate_report()</span></code><a class="headerlink" href="#calibrate-report" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">calibrate_report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generates a calibration report, including a confusion matrix and classification report.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – Features dataset for validation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – True labels for the validation dataset.</p></li>
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Optional scoring metric name to include in the report. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the provided <code class="docutils literal notranslate"><span class="pre">X</span></code> or <code class="docutils literal notranslate"><span class="pre">y</span></code> are incompatible with the model or metrics.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method evaluates the performance of a calibrated model on the validation dataset.</p></li>
<li><p>Generates and prints:
- A confusion matrix, with support for multi-label classification if applicable.
- A classification report summarizing precision, recall, and F1-score for each class.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>Calls the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method to obtain predictions for the validation dataset.</p></li>
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code> or <code class="docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code> based on the value of <code class="docutils literal notranslate"><span class="pre">self.multi_label</span></code> to compute the confusion matrix.</p></li>
<li><p>Prints a labeled confusion matrix using the <code class="docutils literal notranslate"><span class="pre">_confusion_matrix_print()</span></code> function.</p></li>
<li><p>Generates a classification report using <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code> and assigns it to the <code class="docutils literal notranslate"><span class="pre">self.classification_report</span></code> attribute.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints the following to the console:</p>
<ul>
<li><p>The confusion matrix with labels.</p></li>
<li><p>The classification report.</p></li>
<li><p>A separator line for readability.</p></li>
</ul>
</li>
<li><p>Updates the attribute <code class="docutils literal notranslate"><span class="pre">self.classification_report</span></code> with the generated classification report.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>If the model is multi-label, a confusion matrix is generated for each label.</p></li>
<li><p>The optional <code class="docutils literal notranslate"><span class="pre">score</span></code> parameter can be used to specify and display a scoring metric in the report heading.</p></li>
<li><p>Designed to work with models that support binary, multi-class, or multi-label predictions.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="fit">
<h2><code class="docutils literal notranslate"><span class="pre">fit()</span></code><a class="headerlink" href="#fit" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Fits the model to training data and, if applicable, tunes thresholds and performs early stopping. Allows feature selection and processing steps as part of the pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – Training features.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – Training target labels.</p></li>
<li><p><strong>validation_data</strong> (tuple of (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>), optional) – Tuple containing validation features and labels. Required for early stopping. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Optional scoring metric to guide the fitting process. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if invalid scoring metrics or parameters are provided.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method trains the model with support for both k-fold cross-validation and single train-validation-test workflows.</p></li>
<li><p>If feature selection or preprocessing steps are configured, they are applied before fitting.</p></li>
<li><p>For certain estimators, early stopping is supported when validation data is provided.</p></li>
<li><p>The method dynamically sets model parameters based on tuning results for the specified or default scoring metric.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>With K-Fold Cross-Validation</strong>:</p></li>
<li><p>Resets the estimator and fits the model using k-fold splits.</p></li>
<li><p>If a scoring metric is provided, applies it to guide the cross-validation.</p></li>
<li><p>Stores cross-validation results in the <cite>self.xval_output</cite> attribute.</p></li>
<li><p><strong>Without K-Fold Cross-Validation</strong>:</p></li>
<li><p>Resets the estimator and applies feature selection or preprocessing if configured.</p></li>
<li><p>Fits the model on training data. If early stopping is enabled, uses validation data to monitor performance and stop training early.</p></li>
</ul>
</div></blockquote>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.kfold</span></code>: Indicates whether k-fold cross-validation is enabled.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>: Stores tuned parameters for different scoring metrics.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.feature_selection</span></code>, <code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code>: Flags for feature selection and preprocessing steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.imbalance_sampler</span></code>: Specifies whether imbalance sampling is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.boost_early</span></code>: Enables early stopping during training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.estimator_name</span></code>: Name of the estimator in the pipeline.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Updates the class attribute <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> with the fitted model.</p></li>
<li><p>For k-fold cross-validation, stores results in <code class="docutils literal notranslate"><span class="pre">self.xval_output</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Early stopping requires both validation features and labels.</p></li>
<li><p>Feature selection and preprocessing steps are dynamically applied based on the pipeline configuration.</p></li>
<li><p>When a custom scoring metric is specified, it must match one of the predefined or user-defined metrics.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="return-metrics">
<span id="id1"></span><h2><code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code><a class="headerlink" href="#return-metrics" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="return_metrics">
<span class="sig-name descname"><span class="pre">return_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimal_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_per_fold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#return_metrics" title="Link to this definition"></a></dt>
<dd><p>A flexible function to evaluate model performance by generating classification or regression metrics. It provides options to print confusion matrices, classification reports, and regression metrics, and supports optimal threshold display and dictionary outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for evaluation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector for evaluation.</p></li>
<li><p><strong>optimal_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use the optimal threshold for predictions (classification only). Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>model_metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to calculate and print detailed model metrics using <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>print_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to print the optimal threshold used for predictions (classification only). Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>return_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to return the metrics as a dictionary instead of printing them. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>print_per_fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – For cross-validation, whether to print metrics for each fold. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing metrics if <code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code>; otherwise, the metrics are printed.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a> or None</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<p>The <code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code> function is designed to be highly adaptable, allowing users to:</p>
<ul class="simple">
<li><p><strong>Print Classification Metrics</strong>: Displays a confusion matrix and the accompanying classification report when evaluating a classification model.</p></li>
<li><p><strong>Print Regression Metrics</strong>: Outputs standard regression metrics (e.g., R², Mean Absolute Error) when evaluating a regression model.</p></li>
<li><p><strong>Report Detailed Model Metrics</strong>: By setting <code class="docutils literal notranslate"><span class="pre">model_metrics=True</span></code>, the function invokes <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code> to provide detailed insights into metrics like precision, recall, and AUC-ROC.</p></li>
<li><p><strong>Display the Optimal Threshold</strong>: Setting <code class="docutils literal notranslate"><span class="pre">print_threshold=True</span></code> displays the threshold value used for classification predictions, particularly when an optimal threshold has been tuned.</p></li>
<li><p><strong>Return Results as a Dictionary</strong>: If <code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code>, the metrics are returned in a structured dictionary, allowing users to programmatically access the results. This is especially useful for further analysis or logging.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>Classification Models</strong>:</p>
<ul>
<li><p>Generates and prints a confusion matrix.</p></li>
<li><p>Prints a detailed classification report, including precision, recall, F1-score, and accuracy.</p></li>
<li><p>Optionally prints additional model metrics and the optimal threshold.</p></li>
</ul>
</li>
<li><p><strong>Regression Models</strong>:</p>
<ul>
<li><p>Outputs standard regression metrics such as R², Mean Absolute Error, and Root Mean Squared Error.</p></li>
</ul>
</li>
<li><p><strong>Cross-Validation</strong>:</p>
<ul>
<li><p>For k-fold validation, the function aggregates metrics across folds and prints the averaged results. If <code class="docutils literal notranslate"><span class="pre">print_per_fold=True</span></code>, metrics for each fold are also printed in addition to the averaged results.</p></li>
</ul>
</li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code>, returns:</p>
<ul>
<li><p><strong>Classification Models</strong>:</p>
<ul>
<li><p>A dictionary with:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Classification</span> <span class="pre">Report</span></code>: The classification report as a string.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Confusion</span> <span class="pre">Matrix</span></code>: The confusion matrix as an array.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Best</span> <span class="pre">Features</span></code>: (Optional) List of the top features if feature selection is enabled.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Regression Models</strong>:</p>
<ul>
<li><p>A dictionary with:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Regression</span> <span class="pre">Report</span></code>: A dictionary of regression metrics.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Best</span> <span class="pre">Features</span></code>: (Optional) List of the top features if feature selection is enabled.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">return_dict=False</span></code>, prints the metrics directly to the console.</p></li>
</ul>
<p><strong>Examples:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Example usage for validation metrics:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_valid</span><span class="p">,</span>
    <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1">## Example usage for test metrics:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
    <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This function is suitable for both classification and regression models.</p></li>
<li><p>Supports cross-validation workflows by calculating metrics across multiple folds.</p></li>
<li><p>Enables users to programmatically access metrics via the dictionary output for custom analysis.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="predict">
<h2><code class="docutils literal notranslate"><span class="pre">predict()</span></code><a class="headerlink" href="#predict" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimal_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Makes predictions and predicts probabilities, allowing threshold tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for prediction.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like, optional) – The true target labels, required only for k-fold predictions. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>optimal_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use an optimal classification threshold for predictions. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Predicted class labels or predictions adjusted by the optimal threshold.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> or array-like</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if invalid inputs or configurations are provided.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>Predicts target values for the input data.</p></li>
<li><p>Supports both regression and classification tasks, with specific behavior for each:</p>
<ul>
<li><p>For regression: Direct predictions are returned, ignoring thresholds.</p></li>
<li><p>For classification: Predictions are adjusted using an optimal threshold when enabled.</p></li>
</ul>
</li>
<li><p>If k-fold cross-validation is active, performs predictions for each fold using <code class="docutils literal notranslate"><span class="pre">cross_val_predict</span></code>.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>With K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Returns predictions based on cross-validated folds.</p></li>
</ul>
</li>
<li><p><strong>Without K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Uses the trained model’s <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method.</p></li>
<li><p>Applies the optimal threshold to adjust classification predictions, if specified.</p></li>
</ul>
</li>
</ul>
<p><strong>Related Methods:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predict_proba(X,</span> <span class="pre">y=None)</span></code>:</p>
<ul>
<li><p>Predicts probabilities for classification tasks.</p></li>
<li><p>Supports k-fold cross-validation using <code class="docutils literal notranslate"><span class="pre">cross_val_predict</span></code> with the <code class="docutils literal notranslate"><span class="pre">method=&quot;predict_proba&quot;</span></code> option.</p></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Optimal thresholding is useful for fine-tuning classification performance metrics such as F1-score or precision-recall balance.</p></li>
<li><p>For classification, the threshold can be tuned for specific scoring metrics (e.g., ROC-AUC).</p></li>
<li><p>Works seamlessly with pipelines or directly with the underlying model.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="grid-search-param-tuning">
<h2><code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning()</span></code><a class="headerlink" href="#grid-search-param-tuning" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">grid_search_param_tuning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f1_beta_tune</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">2]</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Performs grid or Bayesian search parameter tuning, optionally tuning F-beta score thresholds for classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for training and validation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>f1_beta_tune</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to tune F-beta score thresholds during parameter search. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>betas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – List of beta values to use for F-beta score tuning. Default is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the provided data or configurations are incompatible with parameter tuning.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised if required scoring metrics are missing.</p></li>
</ul>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method tunes hyperparameters for a model using grid search or Bayesian optimization.</p></li>
<li><p>Supports tuning F-beta thresholds for classification tasks.</p></li>
<li><p>Can handle both k-fold cross-validation and single train-validation-test workflows.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>With K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Splits data into k folds using <code class="docutils literal notranslate"><span class="pre">kfold_split</span></code> and performs parameter tuning.</p></li>
<li><p>Optionally tunes thresholds for F-beta scores on validation splits.</p></li>
</ul>
</li>
<li><p><strong>Without K-Fold Cross-Validation</strong>:</p>
<ul>
<li><p>Performs a train-validation-test split using <code class="docutils literal notranslate"><span class="pre">train_val_test_split</span></code>.</p></li>
<li><p>Applies preprocessing, feature selection, and imbalance sampling if configured.</p></li>
<li><p>Tunes parameters and thresholds based on validation scores.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.kfold</span></code>: Indicates whether k-fold cross-validation is enabled.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.scoring</span></code>: List of scoring metrics used for evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>: Stores the best parameter set for each scoring metric.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.grid</span></code>: Parameter grid for tuning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.calibrate</span></code>: Specifies whether the model calibration is enabled.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.imbalance_sampler</span></code>: Indicates if imbalance sampling is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.feature_selection</span></code>: Specifies whether feature selection is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.pipeline_steps</span></code>: Configuration for preprocessing steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.boost_early</span></code>: Enables early stopping during model training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.threshold</span></code>: Stores tuned thresholds for F-beta score optimization.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Updates the class attribute <code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code> with the best parameters and scores for each metric.</p></li>
<li><p>Optionally updates <code class="docutils literal notranslate"><span class="pre">self.threshold</span></code> with tuned F-beta thresholds.</p></li>
<li><p>Prints best parameters and scores if <code class="docutils literal notranslate"><span class="pre">self.display</span></code> is enabled.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Threshold tuning requires classification tasks and is not applicable for regression.</p></li>
<li><p>Early stopping is supported if <code class="docutils literal notranslate"><span class="pre">self.boost_early</span></code> is enabled and validation data is provided.</p></li>
<li><p>Works seamlessly with pipelines for preprocessing and feature selection.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="print-selected-best-features">
<h2><code class="docutils literal notranslate"><span class="pre">print_selected_best_features()</span></code><a class="headerlink" href="#print-selected-best-features" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">print_selected_best_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Prints and returns the selected top K best features based on the feature selection step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix used during the feature selection process.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of the selected features or column indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – Raised if the feature selection pipeline is not properly configured or trained.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method retrieves the top K features selected by the feature selection pipeline.</p></li>
<li><p>Prints the names or column indices of the selected features to the console.</p></li>
<li><p>Returns the selected features as a list.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>For DataFrames</strong>:</p>
<ul>
<li><p>Prints the names of the selected feature columns.</p></li>
<li><p>Returns a list of column names corresponding to the selected features.</p></li>
</ul>
</li>
<li><p><strong>For Array-like Data</strong>:</p>
<ul>
<li><p>Prints the indices of the selected feature columns.</p></li>
<li><p>Returns a list of column indices.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.get_feature_selection_pipeline()</span></code>: Retrieves the feature selection pipeline used for selecting features.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints the selected features or indices to the console.</p></li>
<li><p>Returns the selected features as a list.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Assumes that a feature selection pipeline has been configured and trained prior to calling this method.</p></li>
<li><p>Designed to work with both <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and array-like structures for feature matrices.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="tune-threshold-fbeta">
<h2><code class="docutils literal notranslate"><span class="pre">tune_threshold_Fbeta()</span></code><a class="headerlink" href="#tune-threshold-fbeta" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">tune_threshold_Fbeta</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_valid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_valid_proba</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kfold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Tunes classification threshold for optimal F-beta score, balancing precision and recall across various thresholds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – A label or name for the score used to store the best threshold.</p></li>
<li><p><strong>y_valid</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Ground truth (actual) labels for the validation dataset.</p></li>
<li><p><strong>betas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – A list of beta values to consider when calculating the F-beta score. Beta controls the balance between precision and recall.</p></li>
<li><p><strong>y_valid_proba</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Predicted probabilities for the positive class in the validation dataset. Used to evaluate thresholds.</p></li>
<li><p><strong>kfold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, returns the best threshold for the given score. If False, updates the <code class="docutils literal notranslate"><span class="pre">threshold</span></code> attribute in place. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The best threshold for the given score if <code class="docutils literal notranslate"><span class="pre">kfold</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, otherwise returns <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a> or None</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if input arrays have mismatched dimensions or invalid beta values.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – Raised if invalid data types are passed for parameters.</p></li>
</ul>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method identifies the optimal classification threshold for maximizing the F-beta score.</p></li>
<li><p>The F-beta score balances precision and recall, with beta determining the relative weight of recall.</p></li>
<li><p>Evaluates thresholds ranging from 0 to 1 (with a step size of 0.01) to find the best threshold for each beta value.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>Threshold Evaluation</strong>:</p>
<ul>
<li><p>For each threshold, computes binary predictions and evaluates the resulting F-beta score.</p></li>
<li><p>Penalizes thresholds leading to undesirable outcomes, such as excessive false positives compared to true negatives.</p></li>
</ul>
</li>
<li><p><strong>K-Fold Mode</strong>:</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">kfold=True</span></code>, returns the optimal threshold without modifying class attributes.</p></li>
</ul>
</li>
<li><p><strong>Non K-Fold Mode</strong>:</p>
<ul>
<li><p>Updates the <code class="docutils literal notranslate"><span class="pre">self.threshold</span></code> attribute with the optimal threshold for the specified score.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.threshold</span></code>: Stores the optimal threshold for each scoring metric.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.beta</span></code>: Stores the beta value corresponding to the maximum F-beta score.</p></li>
</ul>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li><p>The method iterates over thresholds and calculates F-beta scores for each beta value, identifying the best-performing threshold.</p></li>
<li><p>Penalizes thresholds where false positives exceed true negatives to ensure practical performance.</p></li>
<li><p>Designed to support models evaluated on binary classification tasks.</p></li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">tune_threshold_Fbeta</span><span class="p">(</span>
      <span class="n">score</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
      <span class="n">y_valid</span><span class="o">=</span><span class="n">y_valid</span><span class="p">,</span>
      <span class="n">betas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
      <span class="n">y_valid_proba</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">],</span>
      <span class="n">kfold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="train-val-test-split">
<h2><code class="docutils literal notranslate"><span class="pre">train_val_test_split()</span></code><a class="headerlink" href="#train-val-test-split" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_val_test_split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Splits data into train, validation, and test sets, supporting stratification by specific columns or the target variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix to split.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>stratify_y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or None, optional) – Specifies whether to stratify based on the target variable. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>train_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to allocate to the training set. Default is <code class="docutils literal notranslate"><span class="pre">0.6</span></code>.</p></li>
<li><p><strong>validation_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to allocate to the validation set. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>test_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Proportion of the data to allocate to the test set. Default is <code class="docutils literal notranslate"><span class="pre">0.2</span></code>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for reproducibility. Default is <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p><strong>stratify_cols</strong> (list, <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, or None, optional) – Columns to use for stratification, in addition to or instead of <code class="docutils literal notranslate"><span class="pre">y</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing train, validation, and test sets: (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">X_valid</span></code>, <code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_valid</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code>)</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the sizes for train, validation, and test do not sum to 1.0 or if invalid stratification keys are provided.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This function splits data into three sets: train, validation, and test.</p></li>
<li><p>Supports stratification based on the target variable (<code class="docutils literal notranslate"><span class="pre">y</span></code>) or specific columns (<code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code>).</p></li>
<li><p>Ensures the proportions of the split sets are consistent with the specified <code class="docutils literal notranslate"><span class="pre">train_size</span></code>, <code class="docutils literal notranslate"><span class="pre">validation_size</span></code>, and <code class="docutils literal notranslate"><span class="pre">test_size</span></code>.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>Combines <code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> (if both are provided) to create a stratification key.</p></li>
<li><p>Handles missing values in <code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code> by filling with empty strings.</p></li>
<li><p>Uses a two-step splitting approach:</p>
<ol class="arabic simple">
<li><p>Splits data into train and combined validation-test sets.</p></li>
<li><p>Further splits the combined set into validation and test sets.</p></li>
</ol>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p>Handles configurations for stratification and proportional splitting.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The sum of <code class="docutils literal notranslate"><span class="pre">train_size</span></code>, <code class="docutils literal notranslate"><span class="pre">validation_size</span></code>, and <code class="docutils literal notranslate"><span class="pre">test_size</span></code> must equal <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p>Stratification ensures the distribution of classes or categories is preserved across splits.</p></li>
<li><p>The function works seamlessly with both <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and array-like data structures.</p></li>
</ul>
</div>
<p><strong>Example:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_val_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">stratify_y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">validation_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category_column&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="get-best-score-params">
<h2><code class="docutils literal notranslate"><span class="pre">get_best_score_params()</span></code><a class="headerlink" href="#get-best-score-params" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_best_score_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Retrieves the best hyperparameters for the model based on cross-validation scores for specified metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for training during hyperparameter tuning.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code>. Updates the class attributes with the best parameters and scores.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if <code class="docutils literal notranslate"><span class="pre">self.grid</span></code> or <code class="docutils literal notranslate"><span class="pre">self.kf</span></code> is not properly configured.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#KeyError" title="(in Python v3.13)"><strong>KeyError</strong></a> – Raised if scoring metrics are missing or invalid.</p></li>
</ul>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method performs hyperparameter tuning using either grid search, randomized grid search, or Bayesian search.</p></li>
<li><p>Identifies the best parameter set for each scoring metric specified in the class’s <code class="docutils literal notranslate"><span class="pre">scoring</span></code> attribute.</p></li>
<li><p>Updates the class attributes with the best estimator and scores.</p></li>
</ul>
<p><strong>Supported Search Methods:</strong></p>
<ul class="simple">
<li><p><strong>Grid Search</strong>: Exhaustively searches over all parameter combinations.</p></li>
<li><p><strong>Randomized Grid Search</strong>: Randomly samples a subset of parameter combinations.</p></li>
<li><p><strong>Bayesian Search</strong>: Uses Bayesian optimization for hyperparameter tuning.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p><strong>Randomized Search</strong>:</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">self.randomized_grid</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, uses <code class="docutils literal notranslate"><span class="pre">`RandomizedSearchCV`</span></code> to perform hyperparameter tuning.</p></li>
</ul>
</li>
<li><p><strong>Bayesian Search</strong>:</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">self.bayesian</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, uses <code class="docutils literal notranslate"><span class="pre">BayesSearchCV</span></code> for Bayesian optimization.</p></li>
<li><p>Removes any <code class="docutils literal notranslate"><span class="pre">bayes__</span></code> prefixed parameters from the grid and uses them as additional arguments for <code class="docutils literal notranslate"><span class="pre">BayesSearchCV</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Grid Search</strong>:</p>
<ul>
<li><p>Defaults to <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> if neither <code class="docutils literal notranslate"><span class="pre">randomized_grid</span></code> nor <code class="docutils literal notranslate"><span class="pre">bayesian</span></code> is enabled.</p></li>
</ul>
</li>
<li><p>After fitting the model:</p>
<ul>
<li><p>Updates <code class="docutils literal notranslate"><span class="pre">self.estimator</span></code> and <code class="docutils literal notranslate"><span class="pre">self.test_model</span></code> with the best estimator.</p></li>
<li><p>Stores the best parameters and score for each scoring metric in <code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Updated:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.estimator</span></code>: Updated with the best model after tuning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.test_model</span></code>: Updated with the same best model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.best_params_per_score</span></code>: A dictionary storing the best parameters and scores for each scoring metric.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints:</p>
<ul>
<li><p>The best parameter set and score for each metric.</p></li>
<li><p>A summary of grid scores for all parameter combinations.</p></li>
</ul>
</li>
<li><p>Updates class attributes with the tuning results.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Supports custom scoring metrics via <code class="docutils literal notranslate"><span class="pre">self.custom_scorer</span></code>.</p></li>
<li><p>The method assumes <code class="docutils literal notranslate"><span class="pre">self.kf</span></code> is a valid cross-validator (e.g., <code class="docutils literal notranslate"><span class="pre">KFold</span></code> or <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code>) and <code class="docutils literal notranslate"><span class="pre">self.grid</span></code> is properly defined.</p></li>
<li><p>Designed to work seamlessly with classification and regression models.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="conf-mat-class-kfold">
<h2><code class="docutils literal notranslate"><span class="pre">conf_mat_class_kfold()</span></code><a class="headerlink" href="#conf-mat-class-kfold" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">conf_mat_class_kfold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generates and averages confusion matrices across k-folds, producing a combined classification report.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for k-fold cross-validation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>test_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The model to be trained and evaluated on each fold.</p></li>
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Optional scoring metric label for reporting purposes. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing the averaged classification report and confusion matrix.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the input data is incompatible with k-fold splitting.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method performs k-fold cross-validation to generate confusion matrices for each fold.</p></li>
<li><p>Averages the confusion matrices across all folds and produces a combined classification report.</p></li>
<li><p>Prints the averaged confusion matrix and classification report.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>For each fold in k-fold cross-validation:</p>
<ol class="arabic simple">
<li><p>Splits the data into training and testing subsets.</p></li>
<li><p>Fits the <code class="docutils literal notranslate"><span class="pre">test_model</span></code> on the training subset.</p></li>
<li><p>Predicts the target values for the testing subset.</p></li>
<li><p>Computes the confusion matrix for the fold and appends it to a list.</p></li>
</ol>
</li>
<li><p>Aggregates predictions and true labels across all folds.</p></li>
<li><p>Averages the confusion matrices and generates an overall classification report.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints:</p>
<ul>
<li><p>The averaged confusion matrix across all folds.</p></li>
<li><p>The overall classification report across all folds.</p></li>
</ul>
</li>
<li><p>Returns:</p>
<ul>
<li><p>A dictionary containing:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;Classification</span> <span class="pre">Report&quot;</span></code>: The averaged classification report as a dictionary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;Confusion</span> <span class="pre">Matrix&quot;</span></code>: The averaged confusion matrix as a NumPy array.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Designed for classification tasks evaluated with k-fold cross-validation.</p></li>
<li><p>Handles both <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and array-like structures for <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">score</span></code> is provided, it is included in the printed report headers.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="regression-report-kfold">
<h2><code class="docutils literal notranslate"><span class="pre">regression_report_kfold()</span></code><a class="headerlink" href="#regression-report-kfold" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">regression_report_kfold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generates averaged regression metrics across k-folds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – The feature matrix for k-fold cross-validation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – The target vector corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>test_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The model to be trained and evaluated on each fold.</p></li>
<li><p><strong>score</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Optional scoring metric label for reporting purposes. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing averaged regression metrics across all folds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the input data is incompatible with k-fold splitting.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This method evaluates regression performance metrics using k-fold cross-validation.</p></li>
<li><p>Trains the <code class="docutils literal notranslate"><span class="pre">test_model</span></code> on training splits and evaluates it on validation splits for each fold.</p></li>
<li><p>Aggregates regression metrics from all folds and calculates their averages.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>For each fold in k-fold cross-validation:</p>
<ol class="arabic simple">
<li><p>Splits the data into training and testing subsets.</p></li>
<li><p>Fits the <code class="docutils literal notranslate"><span class="pre">test_model</span></code> on the training subset.</p></li>
<li><p>Predicts the target values for the testing subset.</p></li>
<li><p>Computes regression metrics (e.g., RMSE, MAE, R²) and stores them.</p></li>
</ol>
</li>
<li><p>Aggregates metrics across all folds and calculates their mean.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints:</p>
<ul>
<li><p>The averaged regression metrics across all folds.</p></li>
</ul>
</li>
<li><p>Returns:</p>
<ul>
<li><p>A dictionary containing the averaged regression metrics.</p></li>
</ul>
</li>
</ul>
<p><strong>Attributes Used:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.regression_report()</span></code>: Used to compute regression metrics for each fold.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Designed specifically for regression tasks evaluated with k-fold cross-validation.</p></li>
<li><p>Handles both <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> and array-like structures for <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="regression-report">
<h2><code class="docutils literal notranslate"><span class="pre">regression_report()</span></code><a class="headerlink" href="#regression-report" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">regression_report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generates a regression report with metrics like Mean Absolute Error, R-squared, and Root Mean Squared Error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<em>array-like</em>) – Ground truth (actual) values for the target variable.</p></li>
<li><p><strong>y_pred</strong> (<em>array-like</em>) – Predicted values for the target variable.</p></li>
<li><p><strong>print_results</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to print the regression metrics to the console. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing various regression metrics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if <code class="docutils literal notranslate"><span class="pre">y_true</span></code> and <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> have mismatched dimensions.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>Computes common regression metrics to evaluate the performance of a regression model.</p></li>
<li><p>Metrics include R², explained variance, mean absolute error (MAE), median absolute error, mean squared error (MSE), and root mean squared error (RMSE).</p></li>
</ul>
<p><strong>Metrics Computed:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">R²</span></code>: Coefficient of determination, indicating the proportion of variance in the dependent variable explained by the independent variable(s).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Explained</span> <span class="pre">Variance</span></code>: Measures the proportion of variance explained by the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Mean</span> <span class="pre">Absolute</span> <span class="pre">Error</span> <span class="pre">(MAE)</span></code>: Average of the absolute differences between actual and predicted values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Median</span> <span class="pre">Absolute</span> <span class="pre">Error</span></code>: Median of the absolute differences between actual and predicted values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Mean</span> <span class="pre">Squared</span> <span class="pre">Error</span> <span class="pre">(MSE)</span></code>: Average of the squared differences between actual and predicted values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Root</span> <span class="pre">Mean</span> <span class="pre">Squared</span> <span class="pre">Error</span> <span class="pre">(RMSE)</span></code>: Square root of the mean squared error.</p></li>
</ul>
<p><strong>Behavior:</strong></p>
<ul class="simple">
<li><p>Computes all metrics and stores them in a dictionary.</p></li>
<li><p>Optionally prints the metrics to the console, formatted for easy readability.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Prints:</p>
<ul>
<li><p>A formatted list of regression metrics if <code class="docutils literal notranslate"><span class="pre">print_results=True</span></code>.</p></li>
</ul>
</li>
<li><p>Returns:</p>
<ul>
<li><p>A dictionary containing the computed metrics.</p></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This method is designed for regression tasks and is not applicable to classification models.</p></li>
<li><p>The returned dictionary can be used for further analysis or logging.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="report-model-metrics">
<span id="id2"></span><h2><code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code><a class="headerlink" href="#report-model-metrics" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">report_model_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_valid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_valid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_per_fold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generate a DataFrame of model performance metrics, adapting to regression,
binary classification, or multiclass classification problems.</p>
<p><strong>Key Features:</strong></p>
<ul class="simple">
<li><p>Handles regression, binary classification, and multiclass classification tasks.</p></li>
<li><p>Supports K-Fold cross-validation with optional metrics printing for individual folds.</p></li>
<li><p>Adapts metrics calculation based on the model’s <code class="docutils literal notranslate"><span class="pre">model_type</span></code> attribute.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The trained model with the necessary attributes and methods for prediction,
including <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> or <code class="docutils literal notranslate"><span class="pre">predict</span></code>, and attributes like <code class="docutils literal notranslate"><span class="pre">model_type</span></code>
and <code class="docutils literal notranslate"><span class="pre">multi_label</span></code> (for multiclass classification).</p></li>
<li><p><strong>X_valid</strong> (<em>pandas.DataFrame</em><em> or </em><em>array-like</em><em>, </em><em>optional</em>) – Feature set used for validation. If performing K-Fold validation, this
represents the entire dataset. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>y_valid</strong> (<em>pandas.Series</em><em> or </em><em>array-like</em><em>, </em><em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">True</span></code> labels for the validation dataset. If performing K-Fold validation,
this corresponds to the entire dataset. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Classification threshold for binary classification models. Predictions
above this threshold are classified as the positive class. Default is <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p></li>
<li><p><strong>print_results</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to print the metrics report. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>print_per_fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If performing K-Fold validation, specifies whether to print metrics
for each fold. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if the provided <code class="docutils literal notranslate"><span class="pre">model_type</span></code> is invalid or incompatible with the data.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – Raised if the required attributes or methods are missing from the model.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – Raised for incorrect parameter types, such as non-numeric thresholds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A pandas DataFrame containing calculated performance metrics. The structure of the
DataFrame depends on the model type:</p>
<ul class="simple">
<li><p><strong>Regression</strong>: Includes Mean Absolute Error (MAE), Mean Squared Error (MSE),
Root Mean Squared Error (RMSE), R² Score, and Explained Variance.</p></li>
<li><p><strong>Binary Classification</strong>: Includes Precision (PPV), Average Precision, Sensitivity,
Specificity, AUC-ROC, and Brier Score.</p></li>
<li><p><strong>Multiclass Classification</strong>: Includes Precision, Recall, and F1-Score for each class,
along with weighted averages and accuracy.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For regression models, standard regression metrics are calculated.</p></li>
<li><p>For binary classification models, threshold-based metrics are computed using probabilities from <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.</p></li>
<li><p>For multiclass classification models, metrics are calculated for each class, along with weighted averages.</p></li>
<li><p>K-Fold cross-validation aggregates metrics across folds, with an option to print results for each fold.</p></li>
</ul>
</div>
<p><strong>Examples:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Example for binary classification:</span>
<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">report_model_metrics</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1">## Example for regression:</span>
<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">report_model_metrics</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>

<span class="c1">## Example for K-Fold validation:</span>
<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">report_model_metrics</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">print_per_fold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="helper-functions">
<h1>Helper Functions<a class="headerlink" href="#helper-functions" title="Link to this heading"></a></h1>
<section id="kfold-split">
<h2><code class="docutils literal notranslate"><span class="pre">kfold_split()</span></code><a class="headerlink" href="#kfold-split" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">kfold_split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['roc_auc']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Splits data using k-fold or stratified k-fold cross-validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The classifier or model to be evaluated during cross-validation.</p></li>
<li><p><strong>X</strong> (<em>pandas.DataFrame</em><em> or </em><em>array-like</em>) – Features dataset to split into k-folds.</p></li>
<li><p><strong>y</strong> (<em>pandas.Series</em><em> or </em><em>array-like</em>) – Target dataset corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>stratify</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use stratified k-fold cross-validation. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, uses <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code>. Otherwise, uses <code class="docutils literal notranslate"><span class="pre">KFold</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Scoring metric(s) to evaluate during cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">[&quot;roc_auc&quot;]</span></code>.</p></li>
<li><p><strong>n_splits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of splits/folds to create for cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for reproducibility. Default is <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <code class="docutils literal notranslate"><span class="pre">KFold</span></code> or <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> cross-validator object based on the <code class="docutils literal notranslate"><span class="pre">stratify</span></code> parameter.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.KFold</span></code> or <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.StratifiedKFold</span></code></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if invalid parameters (e.g., negative <code class="docutils literal notranslate"><span class="pre">n_splits</span></code>) are provided.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stratify=True</span></code> for datasets where maintaining the proportion of classes in each fold is important.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stratify=False</span></code> for general k-fold splitting.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="get-cross-validate">
<h2><code class="docutils literal notranslate"><span class="pre">get_cross_validate()</span></code><a class="headerlink" href="#get-cross-validate" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_cross_validate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['roc_auc']</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Performs cross-validation using the provided classifier, dataset, and cross-validation strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a>) – The classifier or model to be evaluated during cross-validation.</p></li>
<li><p><strong>X</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or array-like) – Features dataset to use during cross-validation.</p></li>
<li><p><strong>y</strong> (<code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> or array-like) – Target dataset corresponding to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><strong>kf</strong> (<code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.KFold</span></code> or <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.StratifiedKFold</span></code>) – Cross-validator object, such as <code class="docutils literal notranslate"><span class="pre">KFold</span></code> or <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code>, specifying the cross-validation strategy.</p></li>
<li><p><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Scoring metric(s) to evaluate during cross-validation. Default is <code class="docutils literal notranslate"><span class="pre">[&quot;roc_auc&quot;]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A dictionary containing cross-validation results, including train and test scores for each fold.</p>
<p><strong>Returned Dictionary Keys</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">test_score</span></code>: Test scores for each fold.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_score</span></code>: Training scores for each fold.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">estimator</span></code>: The estimator fitted on each fold.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_time</span></code>: Time taken to fit the model on each fold.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">score_time</span></code>: Time taken to score the model on each fold.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – Raised if invalid <code class="docutils literal notranslate"><span class="pre">kf</span></code> or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameters are provided.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Supports multiple scoring metrics, which can be specified as a list (e.g., <code class="docutils literal notranslate"><span class="pre">[&quot;accuracy&quot;,</span> <span class="pre">&quot;roc_auc&quot;]</span></code>).</p></li>
<li><p>Returns additional information such as train scores and estimators for further analysis.</p></li>
<li><p>Ensure the classifier supports the metrics defined in the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter.</p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="confusion-matrix-print">
<h2><code class="docutils literal notranslate"><span class="pre">_confusion_matrix_print()</span></code><a class="headerlink" href="#confusion-matrix-print" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">_confusion_matrix_print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conf_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Prints the formatted confusion matrix for binary classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conf_matrix</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><em>numpy.ndarray</em></a><em> or </em><em>array-like</em>) – The confusion matrix to print, typically a 2x2 numpy array or similar structure.</p></li>
<li><p><strong>labels</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – A list of labels corresponding to the confusion matrix entries in the order <code class="docutils literal notranslate"><span class="pre">[TN,</span> <span class="pre">FP,</span> <span class="pre">FN,</span> <span class="pre">TP]</span></code>.</p></li>
</ul>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>Formats and prints a binary classification confusion matrix with labeled cells for True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN).</p></li>
<li><p>Includes additional formatting to enhance readability, such as aligned columns and labeled rows.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>The function prints a structured table representation of the confusion matrix directly to the console.</p></li>
</ul>
</dd></dl>

</section>
<section id="print-pipeline">
<h2><code class="docutils literal notranslate"><span class="pre">print_pipeline()</span></code><a class="headerlink" href="#print-pipeline" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">print_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pipeline</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Displays an ASCII representation of the pipeline steps for visual clarity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pipeline</strong> (<code class="docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code> or object with a <code class="docutils literal notranslate"><span class="pre">steps</span></code> attribute) – The pipeline object containing different steps to display. Typically, a <code class="docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code> object or similar structure.</p>
</dd>
</dl>
<p><strong>Description:</strong></p>
<ul class="simple">
<li><p>This function iterates over the steps in a pipeline and displays each step in a visually formatted ASCII art representation.</p></li>
<li><p>For each pipeline step:</p>
<ul>
<li><p>Displays the step name and its class name in a boxed format.</p></li>
<li><p>Connects steps with vertical connectors (<cite>│</cite>) and arrows (<cite>▼</cite>) for clarity.</p></li>
</ul>
</li>
<li><p>Dynamically adjusts box width based on the longest step name or class name to maintain alignment.</p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>The function prints the pipeline structure directly to the console, providing an easy-to-read ASCII visualization.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>If the pipeline has no steps or lacks a <code class="docutils literal notranslate"><span class="pre">steps</span></code> attribute, the function prints a message: <code class="docutils literal notranslate"><span class="pre">&quot;No</span> <span class="pre">steps</span> <span class="pre">found</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">pipeline!&quot;</span></code>.</p></li>
<li><p>Designed for readability, especially in terminal environments.</p></li>
</ul>
</div>
</dd></dl>

</section>
</section>
<section id="pipeline-management">
<h1>Pipeline Management<a class="headerlink" href="#pipeline-management" title="Link to this heading"></a></h1>
<p>The pipeline in the model tuner class is designed to automatically organize steps into three categories: <strong>preprocessing</strong>, <strong>feature selection</strong>, and <strong>imbalanced sampling</strong>. The steps are ordered in the following sequence:</p>
<ol class="arabic simple">
<li><p><strong>Preprocessing</strong>:</p>
<ul class="simple">
<li><p>Imputation</p></li>
<li><p>Scaling</p></li>
<li><p>Other preprocessing steps</p></li>
</ul>
</li>
<li><p><strong>Imbalanced Sampling</strong></p></li>
<li><p><strong>Feature Selection</strong></p></li>
<li><p><strong>Classifier</strong></p></li>
</ol>
<p>The <code class="docutils literal notranslate"><span class="pre">pipeline_assembly</span></code> method automatically sorts the steps into this order.</p>
<section id="specifying-pipeline-steps">
<h2>Specifying Pipeline Steps<a class="headerlink" href="#specifying-pipeline-steps" title="Link to this heading"></a></h2>
<p>Pipeline steps can be specified in multiple ways. For example, if naming a pipeline step then specify like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_steps</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()]</span>
</pre></div>
</div>
<p>Naming each step is optional and the steps can also be specified like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">SimpleImputer</span><span class="p">(),</span> <span class="n">StandardScalar</span><span class="p">(),</span> <span class="n">rfe</span><span class="p">()]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>If no name is assigned, the step will be renamed automatically to follow the convention <code class="docutils literal notranslate"><span class="pre">step_0</span></code>, <code class="docutils literal notranslate"><span class="pre">step_1</span></code>, etc.</p></li>
<li><p>Column transformers can also be included in the pipeline and are automatically categorized under the <strong>preprocessing</strong> section.</p></li>
</ul>
</section>
<section id="helper-methods-for-pipeline-extraction">
<h2>Helper Methods for Pipeline Extraction<a class="headerlink" href="#helper-methods-for-pipeline-extraction" title="Link to this heading"></a></h2>
<p>To support advanced use cases, the model tuner provides helper methods to extract parts of the pipeline for later use. For example, when generating SHAP plots, users might only need the preprocessing section of the pipeline.</p>
<p>Here are some of the available methods:</p>
<dl class="py function">
<dt class="sig sig-object py" id="get_preprocessing_and_feature_selection_pipeline">
<span class="sig-name descname"><span class="pre">get_preprocessing_and_feature_selection_pipeline</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#get_preprocessing_and_feature_selection_pipeline" title="Link to this definition"></a></dt>
<dd><p>Extracts both the preprocessing and feature selection parts of the pipeline.</p>
<p><strong>Example</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_preprocessing_and_feature_selection_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">transformer</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">transformer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">steps</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;preprocess_&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;feature_selection_&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PipelineClass</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="get_feature_selection_pipeline">
<span class="sig-name descname"><span class="pre">get_feature_selection_pipeline</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#get_feature_selection_pipeline" title="Link to this definition"></a></dt>
<dd><p>Extracts only the feature selection part of the pipeline.</p>
<p><strong>Example</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_feature_selection_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">transformer</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">transformer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">steps</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;feature_selection_&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PipelineClass</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="get_preprocessing_pipeline">
<span class="sig-name descname"><span class="pre">get_preprocessing_pipeline</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#get_preprocessing_pipeline" title="Link to this definition"></a></dt>
<dd><p>Extracts only the preprocessing part of the pipeline.</p>
<p><strong>Example</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_preprocessing_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">preprocessing_steps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">transformer</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">transformer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">steps</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;preprocess_&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PipelineClass</span><span class="p">(</span><span class="n">preprocessing_steps</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<p>By organizing pipeline steps automatically and providing helper methods for extraction, the model tuner class offers flexibility and ease of use for building and managing complex pipelines. Users can focus on specifying the steps, and the tuner handles naming, sorting, and category assignments seamlessly.</p>
</section>
</section>
<section id="binary-classification">
<h1>Binary Classification<a class="headerlink" href="#binary-classification" title="Link to this heading"></a></h1>
<p>Binary classification is a type of supervised learning where a model is trained
to distinguish between two distinct classes or categories. In essence, the model
learns to classify input data into one of two possible outcomes, typically
labeled as <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, or negative and positive. This is commonly used in
scenarios such as spam detection, disease diagnosis, or fraud detection.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> library handles binary classification seamlessly through the <code class="docutils literal notranslate"><span class="pre">Model</span></code>
class. Users can specify a binary classifier as the estimator, and the library
takes care of essential tasks like data preprocessing, model calibration, and
cross-validation. The library also provides robust support for evaluating the
model’s performance using a variety of metrics, such as <a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">accuracy, precision,
recall, and ROC-AUC</span></a>, ensuring that the model’s ability to distinguish between the
two classes is thoroughly assessed. Additionally, the library supports advanced
techniques like imbalanced data handling and model calibration to fine-tune
decision thresholds, making it easier to deploy effective binary classifiers in
real-world applications.</p>
<section id="aids-clinical-trials-group-study">
<h2>AIDS Clinical Trials Group Study<a class="headerlink" href="#aids-clinical-trials-group-study" title="Link to this heading"></a></h2>
<p>The UCI Machine Learning Repository is a well-known resource for accessing a wide
range of datasets used for machine learning research and practice. One such dataset
is the <a class="reference external" href="https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175">AIDS Clinical Trials Group Study dataset</a>, which can be used to build and
evaluate predictive models.</p>
<p>You can easily fetch this dataset using the ucimlrepo package. If you haven’t
installed it yet, you can do so by running the following command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">ucimlrepo</span>
</pre></div>
</div>
<p>Once installed, you can quickly load the AIDS Clinical Trials Group Study dataset
with a simple command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>
</pre></div>
</div>
<section id="step-1-import-necessary-libraries">
<h3>Step 1: Import Necessary libraries<a class="headerlink" href="#step-1-import-necessary-libraries" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">Model</span>
</pre></div>
</div>
</section>
<section id="step-2-load-the-dataset-define-x-y">
<h3>Step 2: Load the dataset, define X, y<a class="headerlink" href="#step-2-load-the-dataset-define-x-y" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Fetch dataset</span>
<span class="n">aids_clinical_trials_group_study_175</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">890</span><span class="p">)</span>

<span class="c1">## Data (as pandas dataframes)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">aids_clinical_trials_group_study_175</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">aids_clinical_trials_group_study_175</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1">## convert a DataFrame to Series when single column</span>
</pre></div>
</div>
</section>
<section id="step-3-check-for-zero-variance-columns-and-drop-accordingly">
<h3>Step 3: Check for zero-variance columns and drop accordingly<a class="headerlink" href="#step-3-check-for-zero-variance-columns-and-drop-accordingly" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Check for zero-variance columns and drop them</span>
<span class="n">zero_variance_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">zero_variance_columns</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
   <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">zero_variance_columns</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-create-an-instance-of-the-xgbclassifier">
<h3>Step 4: Create an instance of the XGBClassifier<a class="headerlink" href="#step-4-create-an-instance-of-the-xgbclassifier" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Creating an instance of the XGBClassifier</span>
<span class="n">xgb_name</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">objective</span><span class="o">=</span><span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-5-define-hyperparameters-for-xgboost">
<span id="xgb-hyperparams"></span><h3>Step 5: Define Hyperparameters for XGBoost<a class="headerlink" href="#step-5-define-hyperparameters-for-xgboost" title="Link to this heading"></a></h3>
<p>In binary classification, we configure the <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> for tasks where the
model predicts between two classes (e.g., positive/negative or 0/1). Here, we
define a grid of hyperparameters to fine-tune the XGBoost model.</p>
<p>The following code defines the hyperparameter grid and configuration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgbearly</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">tuned_parameters_xgb</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1">## Define model configuration</span>
<span class="n">xgb_definition</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;clc&quot;</span><span class="p">:</span> <span class="n">xgb</span><span class="p">,</span>
    <span class="s2">&quot;estimator_name&quot;</span><span class="p">:</span> <span class="n">xgb_name</span><span class="p">,</span>
    <span class="s2">&quot;tuned_parameters&quot;</span><span class="p">:</span> <span class="n">tuned_parameters_xgb</span><span class="p">,</span>
    <span class="s2">&quot;randomized_grid&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;n_iter&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>              <span class="c1">## Number of iterations if randomized_grid=True</span>
    <span class="s2">&quot;early&quot;</span><span class="p">:</span> <span class="n">xgbearly</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Key Configurations</strong></p>
<ol class="arabic simple">
<li><p><strong>Hyperparameter Grid</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: Limits the depth of each decision tree to prevent overfitting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: Controls the impact of each boosting iteration; smaller values require more boosting rounds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: Specifies the total number of boosting rounds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: Controls output during training; set to <code class="docutils literal notranslate"><span class="pre">0</span></code> for silent mode or <code class="docutils literal notranslate"><span class="pre">1</span></code> to display progress.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_metric</span></code>: Measures model performance (e.g., <code class="docutils literal notranslate"><span class="pre">logloss</span></code> for binary classification), evaluating the negative log-likelihood.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code>: Halts training early if validation performance does not improve after the specified number of rounds.</p></li>
</ul>
</li>
<li><p><strong>General Settings</strong>:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">randomized_grid=False</span></code> to perform exhaustive grid search.</p></li>
<li><p>Set the number of iterations for randomized search with <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> if needed.</p></li>
</ul>
</li>
</ol>
<p>The grid search will explore the parameter combinations to find the optimal configuration for binary classification tasks.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">verbose</span></code> parameter in XGBoost allows you to control the level of output during training:</p>
<ul class="simple">
<li><p>Set to <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>: Suppresses all training output (silent mode).</p></li>
<li><p>Set to <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">True</span></code>: Displays progress and evaluation metrics during training.</p></li>
</ul>
<p>This can be particularly useful for monitoring model performance when early stopping is enabled.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>When defining hyperparameters for boosting algorithms, frameworks like
<code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> allow straightforward configuration, such as specifying <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>
to control the number of boosting rounds. However, <code class="docutils literal notranslate"><span class="pre">CatBoost</span></code> introduces certain
pitfalls when this parameter is defined.</p>
<p>Refer to the <a class="reference internal" href="caveats.html#catboost-training-parameters"><span class="std std-ref">important caveat regarding this scenario</span></a> for further details.</p>
</div>
</section>
<section id="step-6-initialize-and-configure-the-model">
<h3>Step 6: Initialize and configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code><a class="headerlink" href="#step-6-initialize-and-configure-the-model" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> inherently handles missing values (<code class="docutils literal notranslate"><span class="pre">NaN</span></code>) without requiring explicit
imputation strategies. During training, <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> treats missing values as a
separate category and learns how to route them within its decision trees.
Therefore, passing a <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> or using an imputation strategy is unnecessary
when using <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">clc</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;clc&quot;</span><span class="p">]</span>
<span class="n">estimator_name</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;estimator_name&quot;</span><span class="p">]</span>

<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;tuned_parameters&quot;</span><span class="p">]</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;n_iter&quot;</span><span class="p">]</span>
<span class="n">rand_grid</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;randomized_grid&quot;</span><span class="p">]</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;early&quot;</span><span class="p">]</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">calibrate</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1">## Initialize model_tuner</span>
<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AIDS_Clinical_</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">clc</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">,</span> <span class="s2">&quot;race&quot;</span><span class="p">],</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="n">rand_grid</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="n">early_stop</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-7-perform-grid-search-parameter-tuning-and-retrieve-split-data">
<h3>Step 7: Perform grid search parameter tuning and retrieve split data<a class="headerlink" href="#step-7-perform-grid-search-parameter-tuning-and-retrieve-split-data" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Perform grid search parameter tuning</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">## Get the training, validation, and test data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>With the model configured, the next step is to perform grid search parameter tuning
to find the optimal hyperparameters for the <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code>. The
<code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning</span></code> method will iterate over all combinations of
hyperparameters specified in <code class="docutils literal notranslate"><span class="pre">tuned_parameters</span></code>, evaluate each one using the
specified scoring metric, and select the best performing set.</p>
<p>In this example, we pass an additional argument, <code class="docutils literal notranslate"><span class="pre">f1_beta_tune=True</span></code>, which
adjusts the F1 score to weigh precision and recall differently during
hyperparameter optimization.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For a more in depth discussion on threshold tuning, refer to <a class="reference internal" href="#f1-beta"><span class="std std-ref">this section</span></a>.</p>
<p>Why use <code class="docutils literal notranslate"><span class="pre">f1_beta_tune=True</span></code>?</p>
<ul>
<li><p>Standard F1-Score: Balances precision and recall equally (<code class="docutils literal notranslate"><span class="pre">beta=1</span></code>).</p></li>
<li><p>Custom Beta Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>With <code class="docutils literal notranslate"><span class="pre">f1_beta_tune=True</span></code>, the model tunes the decision threshold to optimize a custom F1 score using the beta value specified internally.</p></li>
<li><p>This is useful in scenarios where one metric (precision or recall) is more critical than the other.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<p>This method will:</p>
<ul>
<li><p><strong>Split the Data</strong>: The data will be split into training and validation sets. Since <code class="docutils literal notranslate"><span class="pre">stratify_y=True</span></code>, the class distribution will be maintained across splits.</p>
<blockquote>
<div><ul class="simple">
<li><p>After tuning, retrieve the training, validation, and test splits using:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">get_train_data</span></code> for training data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_valid_data</span></code> for validation data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_test_data</span></code> for test data.</p></li>
</ul>
</li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Iterate Over Hyperparameters</strong>: All combinations of hyperparameters defined in <code class="docutils literal notranslate"><span class="pre">tuned_parameters</span></code> will be tried since <code class="docutils literal notranslate"><span class="pre">randomized_grid=False</span></code>.</p></li>
<li><p><strong>Early Stopping</strong>: With <code class="docutils literal notranslate"><span class="pre">boost_early=True</span></code> and <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> set in the hyperparameters, the model will stop training early if the validation score does not improve.</p></li>
<li><p><strong>Optimize for Scoring Metric</strong>: The model uses <code class="docutils literal notranslate"><span class="pre">roc_auc</span></code> (ROC AUC) as the scoring metric suitable for binary classification.</p></li>
<li><p><strong>Select Best Model</strong>: The hyperparameter set that yields the best validation score will be selected.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Pipeline Steps:

┌─────────────────┐
│ Step 1: xgb     │
│ XGBClassifier   │
└─────────────────┘

100%|██████████| 5/5 [00:47&lt;00:00,  9.43s/it]
Fitting model with best params and tuning for best threshold ...
100%|██████████| 2/2 [00:00&lt;00:00,  2.87it/s]Best score/param set found on validation set:
{&#39;params&#39;: {&#39;xgb__early_stopping_rounds&#39;: 100,
            &#39;xgb__eval_metric&#39;: &#39;logloss&#39;,
            &#39;xgb__learning_rate&#39;: 0.0001,
            &#39;xgb__max_depth&#39;: 3,
            &#39;xgb__n_estimators&#39;: 999},
&#39;score&#39;: 0.9260891500474834}
Best roc_auc: 0.926
</pre></div>
</div>
</section>
<section id="step-8-fit-the-model">
<h3>Step 8: Fit the model<a class="headerlink" href="#step-8-fit-the-model" title="Link to this heading"></a></h3>
<p>In this step, we train the <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> using the training data and monitor
performance on the validation data during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The inclusion of <code class="docutils literal notranslate"><span class="pre">validation_data</span></code> allows XGBoost to:</p>
<ul class="simple">
<li><p><strong>Monitor Validation Performance</strong>: XGBoost evaluates the model’s performance on the validation set after each boosting round using the specified evaluation metric (e.g., <code class="docutils literal notranslate"><span class="pre">logloss</span></code>).</p></li>
<li><p><strong>Enable Early Stopping</strong>: If <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> is defined, training will stop automatically if the validation performance does not improve after a set number of rounds, preventing overfitting and saving computation time.</p></li>
</ul>
</div>
</section>
<section id="step-9-return-metrics-optional">
<h3>Step 9: Return metrics (optional)<a class="headerlink" href="#step-9-return-metrics-optional" title="Link to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Use the <a class="reference internal" href="#return-metrics"><span class="std std-ref">return metrics</span></a> function to evaluate the model by printing the output.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ------------------------- VALID AND TEST METRICS -----------------------------</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X</span><span class="o">=</span><span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y</span><span class="o">=</span><span class="n">y_valid</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
   <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Validation Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  93 (tp)   11 (fn)
        Neg  76 (fp)  248 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.550296
1  Average Precision  0.802568
2        Sensitivity  0.894231
3        Specificity  0.765432
4            AUC ROC  0.926089
5        Brier Score  0.166657
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.96      0.77      0.85       324
           1       0.55      0.89      0.68       104

    accuracy                           0.80       428
   macro avg       0.75      0.83      0.77       428
weighted avg       0.86      0.80      0.81       428

--------------------------------------------------------------------------------
Optimal threshold used: 0.26

Test Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  99 (tp)    6 (fn)
        Neg  82 (fp)  241 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.546961
1  Average Precision  0.816902
2        Sensitivity  0.942857
3        Specificity  0.746130
4            AUC ROC  0.934306
5        Brier Score  0.167377
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.98      0.75      0.85       323
           1       0.55      0.94      0.69       105

    accuracy                           0.79       428
   macro avg       0.76      0.84      0.77       428
weighted avg       0.87      0.79      0.81       428

--------------------------------------------------------------------------------
Optimal threshold used: 0.26
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A detailed classification report is also available at this stage for review.
To print and examine it, refer to this <a class="reference internal" href="#classification-report"><span class="std std-ref">Model Metrics</span></a> section for guidance on
accessing and interpreting the report.</p>
</div>
</section>
<section id="step-10-calibrate-the-model-if-needed">
<h3>Step 10: Calibrate the model (if needed)<a class="headerlink" href="#step-10-calibrate-the-model-if-needed" title="Link to this heading"></a></h3>
<p>See <a class="reference internal" href="caveats.html#model-calibration"><span class="std std-ref">this section</span></a> for more information on model calibration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="kn">import</span> <span class="n">calibration_curve</span>

<span class="c1">## Get the predicted probabilities for the validation data from uncalibrated model</span>
<span class="n">y_prob_uncalibrated</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1">## Compute the calibration curve for the uncalibrated model</span>
<span class="n">prob_true_uncalibrated</span><span class="p">,</span> <span class="n">prob_pred_uncalibrated</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">y_prob_uncalibrated</span><span class="p">,</span>
   <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">## Calibrate the model</span>
<span class="k">if</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">calibrate</span><span class="p">:</span>
   <span class="n">model_xgb</span><span class="o">.</span><span class="n">calibrateModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>

<span class="c1">## Predict on the validation set</span>
<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Change back to CPU
Confusion matrix on validation set for roc_auc
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  74 (tp)   30 (fn)
        Neg  20 (fp)  304 (tn)
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       324
           1       0.79      0.71      0.75       104

    accuracy                           0.88       428
   macro avg       0.85      0.82      0.84       428
weighted avg       0.88      0.88      0.88       428

--------------------------------------------------------------------------------
roc_auc after calibration: 0.9260891500474834
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Get the predicted probabilities for the validation data from calibrated model</span>
<span class="n">y_prob_calibrated</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1">## Compute the calibration curve for the calibrated model</span>
<span class="n">prob_true_calibrated</span><span class="p">,</span> <span class="n">prob_pred_calibrated</span> <span class="o">=</span> <span class="n">calibration_curve</span><span class="p">(</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">y_prob_calibrated</span><span class="p">,</span>
   <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1">## Plot the calibration curves</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
   <span class="n">prob_pred_uncalibrated</span><span class="p">,</span>
   <span class="n">prob_true_uncalibrated</span><span class="p">,</span>
   <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
   <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Uncalibrated XGBoost&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
   <span class="n">prob_pred_calibrated</span><span class="p">,</span>
   <span class="n">prob_true_calibrated</span><span class="p">,</span>
   <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
   <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Calibrated XGBoost&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
   <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span>
   <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Perfectly calibrated&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True probability in each bin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Calibration plot (reliability curve)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="no-click"><a class="reference internal image-reference" href="_images/calibration_plot.png"><img alt="Calibration Curve AIDs" class="align-center" src="_images/calibration_plot.png" style="width: 400px;" />
</a>
</div><div style="height: 50px;"></div></section>
</section>
<section id="f1-beta-threshold-tuning">
<h2>F1 Beta Threshold Tuning<a class="headerlink" href="#f1-beta-threshold-tuning" title="Link to this heading"></a></h2>
<p>In binary classification, selecting an optimal classification threshold is crucial for
achieving the best balance between precision and recall. The default threshold of 0.5
may not always yield optimal performance, especially when dealing with imbalanced
datasets. F1 Beta threshold tuning helps adjust this threshold to maximize the F-beta
score, which balances precision and recall according to the importance assigned to each
through the beta parameter.</p>
<section id="understanding-f1-beta-score">
<h3>Understanding F1 Beta Score<a class="headerlink" href="#understanding-f1-beta-score" title="Link to this heading"></a></h3>
<p>The F-beta score is a generalization of the F1-score that allows you to weigh recall
more heavily than precision (or vice versa) based on the beta parameter:</p>
<ul class="simple">
<li><p>F1-Score (beta = 1): Equal importance to precision and recall.</p></li>
<li><p>F-beta &gt; 1: More emphasis on recall. Useful when false negatives are more critical (e.g., disease detection).</p></li>
<li><p>F-beta &lt; 1: More emphasis on precision. Suitable when false positives are costlier (e.g., spam detection).</p></li>
</ul>
</section>
<section id="example-usage-default-beta-1">
<h3>Example usage: default (beta = 1)<a class="headerlink" href="#example-usage-default-beta-1" title="Link to this heading"></a></h3>
<p>Setting up the Model object ready for tuning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">xgb_name</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">objective</span><span class="o">=</span><span class="s2">&quot;binary:logistic&quot;</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">tuned_parameters_xgb</span> <span class="o">=</span> <span class="p">{</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Threshold Example Model&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">xgb_name</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">xgb</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_cols</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters_xgb</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In the grid_search_param_tuning use the f1_beta_tune variable when using
grid_search_param_tuning(). Set this to True to enable tuning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_model</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This will find the best hyperparameters and then find the best threshold for these
balancing both precision and recall. The threshold is stored in the Model object.
To access this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_model</span><span class="o">.</span><span class="n">threshold</span>
</pre></div>
</div>
<p>This will give the best threshold found for each score specified in the Model object.</p>
<p>When using methods to return metrics or report metrics and an optimal threshold was used
make sure to remember to specify this in them for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_model</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-usage-custom-betas-higher-recall">
<h3>Example usage: custom betas (higher recall)<a class="headerlink" href="#example-usage-custom-betas-higher-recall" title="Link to this heading"></a></h3>
<p>If we want to have a higher recall score and care less about precision then we increase
the beta value. This looks very similar to the previous example except that when we
use f1_beta_tune, we also set a beta value like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_model</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>Setting the beta value to 2 will priortise increasing the recall over the precision.</p>
</section>
<section id="example-usage-custom-betas-higher-precision">
<h3>Example usage: custom betas (higher precision)<a class="headerlink" href="#example-usage-custom-betas-higher-precision" title="Link to this heading"></a></h3>
<p>If we want to have a higher precision score and care less about recall then we decrease
the beta value. This looks very similar to the previous example except that we set the
beta value to less than 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_model</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
</pre></div>
</div>
<p>Setting the beta value to 0.5 will priortise increasing the precision over the recall.</p>
</section>
</section>
<section id="imbalanced-learning">
<h2>Imbalanced Learning<a class="headerlink" href="#imbalanced-learning" title="Link to this heading"></a></h2>
<p>In machine learning, imbalanced datasets are a frequent challenge, especially in
real-world scenarios. These datasets have an unequal distribution of target classes,
with one class (e.g., fraudulent transactions, rare diseases, or other low-frequency events)
being underrepresented compared to the majority class. Models trained on imbalanced data
often struggle to generalize, as they tend to favor the majority class, leading to
poor performance on the minority class.</p>
<p>To mitigate these issues, it is crucial to:</p>
<ol class="arabic simple">
<li><p>Understand the nature of the imbalance in the dataset.</p></li>
<li><p>Apply appropriate resampling techniques (oversampling, undersampling, or hybrid methods).</p></li>
<li><p>Use metrics beyond accuracy, such as <a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">precision, recall, and F1-score</span></a>, to evaluate model performance fairly.</p></li>
</ol>
<section id="generating-an-imbalanced-dataset">
<h3>Generating an imbalanced dataset<a class="headerlink" href="#generating-an-imbalanced-dataset" title="Link to this heading"></a></h3>
<p>Demonstrated below are the steps to generate an imbalanced dataset using
<code class="docutils literal notranslate"><span class="pre">make_classification</span></code> from the <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> module. The following
parameters are specified:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_samples=1000</span></code>: The dataset contains 1,000 samples.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_features=20</span></code>: Each sample has 20 features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_informative=2</span></code>: Two features are informative for predicting the target.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_redundant=2</span></code>: Two features are linear combinations of the informative features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights=[0.9,</span> <span class="pre">0.1]</span></code>: The target class distribution is 90% for the majority class and 10% for the minority class, creating an imbalance.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flip_y=0</span></code>: No label noise is added to the target variable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">random_state=42</span></code>: Ensures reproducibility by using a fixed random seed.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span>
   <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
   <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
   <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
   <span class="n">n_redundant</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
   <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
   <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
   <span class="n">flip_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">## Convert to a pandas DataFrame for better visualization</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;feature_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">col</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>Below, you will see that the dataset we have generated is severely imbalanced with
900 observations allocated to the majority class (0) and 100 observations to the minority class (1).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">## Create a bar plot</span>
<span class="n">value_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">value_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
   <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span>
   <span class="n">rot</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
   <span class="n">width</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">## Add labels inside the bars</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value_counts</span><span class="p">):</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
      <span class="n">index</span><span class="p">,</span>
      <span class="n">count</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">),</span>
      <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
      <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
      <span class="n">color</span><span class="o">=</span><span class="s2">&quot;yellow&quot;</span><span class="p">,</span>
   <span class="p">)</span>

<span class="c1">## Customize labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Class&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Class Distribution&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1">## Show the plot</span>
</pre></div>
</div>
<div class="no-click"><a class="reference internal image-reference" href="_images/imbalanced_classes.png"><img alt="Calibration Curve AIDs" class="align-center" src="_images/imbalanced_classes.png" style="width: 400px;" />
</a>
</div><div style="height: 50px;"></div></section>
<section id="define-hyperparameters-for-xgboost">
<h3>Define hyperparameters for XGBoost<a class="headerlink" href="#define-hyperparameters-for-xgboost" title="Link to this heading"></a></h3>
<p>Below, we will use an XGBoost classifier with the following hyperparameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">xgb_name</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">xgbearly</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">tuned_parameters_xgb</span> <span class="o">=</span> <span class="p">{</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">xgb_definition</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s2">&quot;clc&quot;</span><span class="p">:</span> <span class="n">xgb</span><span class="p">,</span>
   <span class="s2">&quot;estimator_name&quot;</span><span class="p">:</span> <span class="n">xgb_name</span><span class="p">,</span>
   <span class="s2">&quot;tuned_parameters&quot;</span><span class="p">:</span> <span class="n">tuned_parameters_xgb</span><span class="p">,</span>
   <span class="s2">&quot;randomized_grid&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
   <span class="s2">&quot;n_iter&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
   <span class="s2">&quot;early&quot;</span><span class="p">:</span> <span class="n">xgbearly</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="define-the-model-object">
<h3>Define the model object<a class="headerlink" href="#define-the-model-object" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">clc</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;clc&quot;</span><span class="p">]</span>
<span class="n">estimator_name</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;estimator_name&quot;</span><span class="p">]</span>

<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;tuned_parameters&quot;</span><span class="p">]</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;n_iter&quot;</span><span class="p">]</span>
<span class="n">rand_grid</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;randomized_grid&quot;</span><span class="p">]</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;early&quot;</span><span class="p">]</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">calibrate</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</section>
<section id="addressing-class-imbalance-in-machine-learning">
<h3>Addressing Class Imbalance in Machine Learning<a class="headerlink" href="#addressing-class-imbalance-in-machine-learning" title="Link to this heading"></a></h3>
<p>Class imbalance occurs when one class significantly outweighs another in the
dataset, leading to biased models that perform well on the majority class but
poorly on the minority class. Techniques like SMOTE and others aim to address
this issue by improving the representation of the minority class, ensuring balanced
learning and better generalization.</p>
<section id="techniques-to-address-class-imbalance">
<h4>Techniques to Address Class Imbalance<a class="headerlink" href="#techniques-to-address-class-imbalance" title="Link to this heading"></a></h4>
<p><strong>Resampling Techniques</strong></p>
<ul class="simple">
<li><p><strong>SMOTE (Synthetic Minority Oversampling Technique)</strong>: SMOTE generates synthetic samples for the minority class by interpolating between existing minority class data points and their nearest neighbors. This helps create a more balanced class distribution without merely duplicating data, thus avoiding overfitting.</p></li>
<li><p><strong>Oversampling</strong>: Randomly duplicates examples from the minority class to balance the dataset. While simple, it risks overfitting to the duplicated examples.</p></li>
<li><p><strong>Undersampling</strong>: Reduces the majority class by randomly removing samples. While effective, it can lead to loss of important information.</p></li>
</ul>
</section>
<section id="purpose-of-using-these-techniques">
<h4>Purpose of Using These Techniques<a class="headerlink" href="#purpose-of-using-these-techniques" title="Link to this heading"></a></h4>
<p>The goal of using these techniques is to improve model performance on imbalanced datasets, specifically by:</p>
<ul class="simple">
<li><p>Ensuring the model captures meaningful patterns in the minority class.</p></li>
<li><p>Reducing bias toward the majority class, which often dominates predictions in imbalanced datasets.</p></li>
<li><p>Improving metrics like <a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">recall, F1-score, and AUC-ROC</span></a> for the minority class, which are critical in applications like fraud detection, healthcare, and rare event prediction.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While we provide comprehensive examples for SMOTE, ADASYN, and
RandomUnderSampler in the <a class="reference external" href="https://colab.research.google.com/drive/16gWnRAJvpUjTIes5y1gFRdX1soASdV6m#scrollTo=3NYa_tQWy6HR">accompanying notebook</a>,
this documentation section demonstrates the implementation of SMOTE. The other
examples follow a similar workflow and can be executed by simply passing the
respective <code class="docutils literal notranslate"><span class="pre">imbalance_sampler</span></code> input to <code class="docutils literal notranslate"><span class="pre">ADASYN()</span></code> or <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler()</span></code>, as
needed. For detailed examples of all methods, please refer to the linked notebook.</p>
</div>
</section>
</section>
<section id="synthetic-minority-oversampling-technique-smote">
<h3>Synthetic Minority Oversampling Technique (SMOTE)<a class="headerlink" href="#synthetic-minority-oversampling-technique-smote" title="Link to this heading"></a></h3>
<p>SMOTE (Synthetic Minority Oversampling Technique) is a method used to address
class imbalance in datasets. It generates synthetic samples for the minority
class by interpolating between existing minority samples and their nearest neighbors,
effectively increasing the size of the minority class without duplicating data.
This helps models better learn patterns from the minority class, improving
classification performance on imbalanced datasets.</p>
<section id="step-1-initalize-and-configure-the-model">
<h4>Step 1: Initalize and configure the model<a class="headerlink" href="#step-1-initalize-and-configure-the-model" title="Link to this heading"></a></h4>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In the code block below, we initialize and configure the model by instantiating the
<code class="docutils literal notranslate"><span class="pre">Model</span></code> class and assigning it to a variable named <code class="docutils literal notranslate"><span class="pre">xgb_smote</span></code>. Note that
the <code class="docutils literal notranslate"><span class="pre">imbalance_sampler=SMOTE(random_state=42)</span></code> parameter is included to activate
the imbalanced sampler. Setting a random state of 42 ensures reproducibility of results.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="n">xgb_smote</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Make_Classification_</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">clc</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_cols</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="n">rand_grid</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="n">early_stop</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
   <span class="n">imbalance_sampler</span><span class="o">=</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-2-perform-grid-search-parameter-tuning-and-retrieve-split-data">
<h4>Step 2: Perform grid search parameter tuning and retrieve split data<a class="headerlink" href="#step-2-perform-grid-search-parameter-tuning-and-retrieve-split-data" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_smote</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">## Get the training, validation, and test data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">xgb_smote</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">xgb_smote</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">xgb_smote</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Pipeline Steps:

┌─────────────────────┐
│ Step 1: resampler   │
│ SMOTE               │
└─────────────────────┘
         │
         ▼
┌─────────────────────┐
│ Step 2: xgb         │
│ XGBClassifier       │
└─────────────────────┘

Distribution of y values after resampling: target
0         540
1         540
Name: count, dtype: int64

100%|██████████| 5/5 [00:16&lt;00:00,  3.25s/it]
Fitting model with best params and tuning for best threshold ...
100%|██████████| 2/2 [00:00&lt;00:00,  4.17it/s]Best score/param set found on validation set:
{&#39;params&#39;: {&#39;xgb__early_stopping_rounds&#39;: 100,
            &#39;xgb__eval_metric&#39;: &#39;logloss&#39;,
            &#39;xgb__learning_rate&#39;: 0.0001,
            &#39;xgb__max_depth&#39;: 3,
            &#39;xgb__n_estimators&#39;: 999},
&#39;score&#39;: 0.9969444444444445}
Best roc_auc: 0.997
</pre></div>
</div>
</section>
<section id="smote-distribution-of-y-values-after-resampling">
<h4>SMOTE: Distribution of y values after resampling<a class="headerlink" href="#smote-distribution-of-y-values-after-resampling" title="Link to this heading"></a></h4>
<p>Notice that the target has been redistributed after SMOTE to 540 observations
for the minority class and 540 observations for the majority class.</p>
</section>
<section id="step-3-fit-the-model">
<h4>Step 3: Fit the model<a class="headerlink" href="#step-3-fit-the-model" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_smote</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span>
   <span class="n">y_train</span><span class="p">,</span>
   <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-return-metrics-optional">
<h4>Step 4: Return metrics (optional)<a class="headerlink" href="#step-4-return-metrics-optional" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ------------------------- VALID AND TEST METRICS -----------------------------</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">xgb_smote</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">xgb_smote</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_test</span><span class="p">,</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Validation Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  20 (tp)    0 (fn)
        Neg   1 (fp)  179 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.952381
1  Average Precision  0.947751
2        Sensitivity  1.000000
3        Specificity  0.994444
4            AUC ROC  0.996944
5        Brier Score  0.208997
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       1.00      0.99      1.00       180
           1       0.95      1.00      0.98        20

    accuracy                           0.99       200
   macro avg       0.98      1.00      0.99       200
weighted avg       1.00      0.99      1.00       200

--------------------------------------------------------------------------------
Optimal threshold used: 0.52

Test Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  18 (tp)    2 (fn)
        Neg   3 (fp)  177 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.857143
1  Average Precision  0.897215
2        Sensitivity  0.900000
3        Specificity  0.983333
4            AUC ROC  0.966944
5        Brier Score  0.209358
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.99      0.98      0.99       180
           1       0.86      0.90      0.88        20

    accuracy                           0.97       200
   macro avg       0.92      0.94      0.93       200
weighted avg       0.98      0.97      0.98       200

--------------------------------------------------------------------------------
Optimal threshold used: 0.52
</pre></div>
</div>
</section>
</section>
</section>
<section id="recursive-feature-elimination-rfe">
<h2>Recursive Feature Elimination (RFE)<a class="headerlink" href="#recursive-feature-elimination-rfe" title="Link to this heading"></a></h2>
<p>Now that we’ve trained the models, we can also refine them by identifying which
features contribute most to their performance. One effective method for this is
Recursive Feature Elimination (RFE). This technique allows us to systematically
remove the least important features, retraining the model at each step to evaluate
how performance is affected. By focusing only on the most impactful variables,
RFE helps streamline the dataset, reduce noise, and improve both the accuracy and
interpretability of the final model.</p>
<p>It works by recursively training a model, ranking the importance of features
based on the model’s outputas (such as coefficients in linear models or
importance scores in tree-based models), and then removing the least important
features one by one. This process continues until a specified number of features
remains or the desired performance criteria are met.</p>
<p>The primary advantage of RFE is its ability to streamline datasets, improving
model performance and interpretability by focusing on features that contribute
the most to the predictive power. However, it can be computationally expensive
since it involves repeated model training, and its effectiveness depends on the
underlying model’s ability to evaluate feature importance. RFE is commonly used
with cross-validation to ensure that the selected features generalize well across
datasets, making it a robust choice for model optimization and dimensionality
reduction.</p>
<p>As an illustrative example, we will retrain the above model using RFE.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
</pre></div>
</div>
<p>We will begin by appending the feature selection technique to our <a class="reference internal" href="#xgb-hyperparams"><span class="std std-ref">tuned parameters dictionary</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_definition</span><span class="p">[</span><span class="s2">&quot;tuned_parameters&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;feature_selection_rfe__n_features_to_select&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
   <span class="kc">None</span><span class="p">,</span>
   <span class="mi">5</span><span class="p">,</span>
   <span class="mi">10</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
<section id="elastic-net-for-feature-selection-with-rfe">
<h3>Elastic Net for feature selection with RFE<a class="headerlink" href="#elastic-net-for-feature-selection-with-rfe" title="Link to this heading"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may wish to explore <a class="reference internal" href="caveats.html#elastic-net"><span class="std std-ref">this section</span></a> for the rationale in applying this technique.</p>
</div>
<p>We will use elastic net because it strikes a balance between two widely used
regularization techniques: Lasso (<span class="math notranslate nohighlight">\(L1\)</span>) and Ridge (<span class="math notranslate nohighlight">\(L2\)</span>). Elastic net
is particularly effective in scenarios where we expect the dataset to have a mix
of strongly and weakly correlated features. Lasso alone tends to select only one
feature from a group of highly correlated ones, ignoring the others, while Ridge
includes all features but may not perform well when some are entirely irrelevant.
Elastic net addresses this limitation by combining both penalties, allowing it to handle
multicollinearity more effectively while still performing feature selection.</p>
<p>Additionally, elastic net provides flexibility by controlling the ratio between
<span class="math notranslate nohighlight">\(L1\)</span> and <span class="math notranslate nohighlight">\(L2\)</span> penalties, enabling fine-tuning to suit the specific needs of
our dataset. This makes it a robust choice for datasets with many features, some
of which may be irrelevant or redundant, as it can reduce overfitting while
retaining a manageable subset of predictors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rfe_estimator</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">rfe_estimator</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AIDS_Clinical_</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">clc</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
   <span class="n">pipeline_steps</span><span class="o">=</span><span class="p">[</span>
      <span class="p">(</span><span class="s2">&quot;rfe&quot;</span><span class="p">,</span> <span class="n">rfe</span><span class="p">),</span>
   <span class="p">],</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">stratify_cols</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="n">rand_grid</span><span class="p">,</span>
   <span class="n">feature_selection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="n">early_stop</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model_xgb</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">model_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span>
   <span class="n">y_train</span><span class="p">,</span>
   <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">],</span>
<span class="p">)</span>


<span class="c1"># ------------------------- VALID AND TEST METRICS -----------------------------</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_test</span><span class="p">,</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
   <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Pipeline Steps:

┌─────────────────────────────────┐
│ Step 1: feature_selection_rfe   │
│ RFE                             │
└─────────────────────────────────┘
               │
               ▼
┌─────────────────────────────────┐
│ Step 2: xgb                     │
│ XGBClassifier                   │
└─────────────────────────────────┘

100%|██████████| 15/15 [00:40&lt;00:00,  2.70s/it]
Fitting model with best params and tuning for best threshold ...
100%|██████████| 2/2 [00:00&lt;00:00,  3.53it/s]
Best score/param set found on validation set:
{&#39;params&#39;: {&#39;feature_selection_rfe__n_features_to_select&#39;: 10,
            &#39;xgb__early_stopping_rounds&#39;: 100,
            &#39;xgb__eval_metric&#39;: &#39;logloss&#39;,
            &#39;xgb__learning_rate&#39;: 0.0001,
            &#39;xgb__max_depth&#39;: 10,
            &#39;xgb__n_estimators&#39;: 999},
&#39;score&#39;: 0.9324994064577399}
Best roc_auc: 0.932

Validation Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  94 (tp)   10 (fn)
        Neg  70 (fp)  254 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.573171
1  Average Precision  0.824825
2        Sensitivity  0.903846
3        Specificity  0.783951
4            AUC ROC  0.932499
5        Brier Score  0.165950
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.96      0.78      0.86       324
           1       0.57      0.90      0.70       104

    accuracy                           0.81       428
   macro avg       0.77      0.84      0.78       428
weighted avg       0.87      0.81      0.82       428

--------------------------------------------------------------------------------

Feature names selected:
[&#39;time&#39;, &#39;preanti&#39;, &#39;str2&#39;, &#39;strat&#39;, &#39;symptom&#39;, &#39;treat&#39;, &#39;offtrt&#39;, &#39;cd40&#39;, &#39;cd420&#39;, &#39;cd80&#39;]

Optimal threshold used: 0.25

Test Metrics
Confusion matrix on set provided:
--------------------------------------------------------------------------------
         Predicted:
            Pos   Neg
--------------------------------------------------------------------------------
Actual: Pos  93 (tp)   11 (fn)
        Neg  71 (fp)  253 (tn)
--------------------------------------------------------------------------------
********************************************************************************
Report Model Metrics: xgb

            Metric     Value
0      Precision/PPV  0.567073
1  Average Precision  0.817957
2        Sensitivity  0.894231
3        Specificity  0.780864
4            AUC ROC  0.930051
5        Brier Score  0.165771
********************************************************************************
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.96      0.78      0.86       324
           1       0.57      0.89      0.69       104

    accuracy                           0.81       428
   macro avg       0.76      0.84      0.78       428
weighted avg       0.86      0.81      0.82       428

--------------------------------------------------------------------------------

Feature names selected:
[&#39;time&#39;, &#39;preanti&#39;, &#39;str2&#39;, &#39;strat&#39;, &#39;symptom&#39;, &#39;treat&#39;, &#39;offtrt&#39;, &#39;cd40&#39;, &#39;cd420&#39;, &#39;cd80&#39;]

Optimal threshold used: 0.25
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Passing <code class="docutils literal notranslate"><span class="pre">feature_selection=True</span></code> in conjunction with accounting for <code class="docutils literal notranslate"><span class="pre">rfe</span></code> for
the <code class="docutils literal notranslate"><span class="pre">pipeline_steps</span></code> inside the <code class="docutils literal notranslate"><span class="pre">Model`</span></code> class above is necessary to print the
output of the feature names selected, thus yielding:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Feature names selected:
[&#39;time&#39;, &#39;preanti&#39;, &#39;str2&#39;, &#39;strat&#39;, &#39;symptom&#39;, &#39;treat&#39;, &#39;offtrt&#39;, &#39;cd40&#39;, &#39;cd420&#39;, &#39;cd80&#39;]
</pre></div>
</div>
</div>
</section>
</section>
<section id="shap-shapley-additive-explanations">
<h2>SHAP (SHapley Additive exPlanations)<a class="headerlink" href="#shap-shapley-additive-explanations" title="Link to this heading"></a></h2>
<p>This example demonstrates how to compute and visualize SHAP (SHapley Additive exPlanations)
values for a machine learning model with a pipeline that includes feature selection.
SHAP values provide insights into how individual features contribute to the predictions of a model.</p>
<p><strong>Steps</strong></p>
<ol class="arabic simple">
<li><p>The dataset is transformed through the model’s feature selection pipeline to ensure only the selected features are used for SHAP analysis.</p></li>
<li><p>The final model (e.g., <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> classifier) is retrieved from the custom Model object. This is required because SHAP operates on the underlying model, not the pipeline.</p></li>
<li><p>SHAP’s <code class="docutils literal notranslate"><span class="pre">TreeExplainer</span></code> is used to explain the predictions of the XGBoost classifier.</p></li>
<li><p>SHAP values are calculated for the transformed dataset to quantify the contribution of each feature to the predictions.</p></li>
<li><p>A summary plot is generated to visualize the impact of each feature across all data points.</p></li>
</ol>
<section id="step-1-transform-the-test-data-using-the-feature-selection-pipeline">
<h3>Step 1: Transform the test data using the feature selection pipeline<a class="headerlink" href="#step-1-transform-the-test-data-using-the-feature-selection-pipeline" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## The pipeline applies preprocessing (e.g., imputation, scaling) and feature</span>
<span class="c1">## selection (RFE) to X_test</span>
<span class="n">X_test_transformed</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_feature_selection_pipeline</span><span class="p">()</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-2-retrieve-the-trained-xgboost-classifier-from-the-pipeline">
<h3>Step 2: Retrieve the trained XGBoost classifier from the pipeline<a class="headerlink" href="#step-2-retrieve-the-trained-xgboost-classifier-from-the-pipeline" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## The last estimator in the pipeline is the XGBoost model</span>
<span class="n">xgb_classifier</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">estimator</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="step-3-extract-feature-names-from-the-training-data-and-initialize-the-shap-explainer-for-the-xgboost-classifier">
<h3>Step 3: Extract feature names from the training data, and initialize the SHAP explainer for the XGBoost classifier<a class="headerlink" href="#step-3-extract-feature-names-from-the-training-data-and-initialize-the-shap-explainer-for-the-xgboost-classifier" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Import SHAP for model explainability</span>
<span class="kn">import</span> <span class="nn">shap</span>

<span class="c1">## Feature names are required for interpretability in SHAP plots</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

<span class="c1">## Initialize the SHAP explainer with the model</span>
<span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">xgb_classifier</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-compute-shap-values-for-the-transformed-test-dataset-and-generate-a-summary-plot-of-shap-values">
<h3>Step 4: Compute SHAP values for the transformed test dataset and generate a summary plot of SHAP values<a class="headerlink" href="#step-4-compute-shap-values-for-the-transformed-test-dataset-and-generate-a-summary-plot-of-shap-values" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Compute SHAP values for the transformed dataset</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-5-generate-a-summary-plot-of-shap-values">
<h3>Step 5: Generate a summary plot of SHAP values<a class="headerlink" href="#step-5-generate-a-summary-plot-of-shap-values" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Plot SHAP values</span>
<span class="c1">## Summary plot of SHAP values for all features across all data points</span>
<span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test_transformed</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,)</span>
</pre></div>
</div>
<div class="no-click"><a class="reference internal image-reference" href="_images/SHAP_summary_plot.png"><img alt="Calibration Curve AIDs" class="align-center" src="_images/SHAP_summary_plot.png" style="width: 600px;" />
</a>
</div><div style="height: 50px;"></div></section>
<section id="feature-importance-and-impact">
<h3>Feature Importance and Impact<a class="headerlink" href="#feature-importance-and-impact" title="Link to this heading"></a></h3>
<p>This SHAP summary plot provides a detailed visualization of how each feature
contributes to the model’s predictions, offering insight into feature importance
and their directional effects. The X-axis represents SHAP values, which quantify
the magnitude and direction of a feature’s influence. Positive SHAP values
indicate that the feature increases the predicted output, while negative values
suggest a decrease. Along the Y-axis, features are ranked by their overall importance,
with the most influential features, such as <code class="docutils literal notranslate"><span class="pre">time</span></code>, positioned at the top.</p>
<p>Each point on the plot corresponds to an individual observation, where the color
gradient reflects the feature value. Blue points represent lower feature values,
while pink points indicate higher values, allowing us to observe how varying
feature values affect the prediction. For example, the time feature shows a wide
range of SHAP values, with higher values (pink) strongly increasing the prediction
and lower values (blue) reducing it, demonstrating its critical role in driving
the model’s output.</p>
<p>In contrast, features like <code class="docutils literal notranslate"><span class="pre">hemo</span></code> and <code class="docutils literal notranslate"><span class="pre">age</span></code> exhibit SHAP values closer to zero,
signifying a lower overall impact on predictions. Features such as <code class="docutils literal notranslate"><span class="pre">homo</span></code>, <code class="docutils literal notranslate"><span class="pre">karnof</span></code>,
and <code class="docutils literal notranslate"><span class="pre">trt</span></code> show more variability in their influence, indicating that their effect is
context-dependent and can significantly shift predictions in certain cases. This
plot provides a holistic view of feature behavior, enabling a deeper understanding
of the model’s decision-making process.</p>
</section>
</section>
</section>
<section id="multi-class-classification">
<h1>Multi-Class Classification<a class="headerlink" href="#multi-class-classification" title="Link to this heading"></a></h1>
<p>Multi-class classification involves training a model to predict one of three or
more distinct classes for each instance in a dataset. Unlike binary classification,
where the model predicts between two classes (e.g., positive/negative),
multi-class classification applies to problems where multiple outcomes exist,
such as predicting the species of flowers in the Iris dataset.</p>
<p>This section demonstrates how to perform multi-class classification using the
<code class="docutils literal notranslate"><span class="pre">model_tuner</span></code> library, with <code class="docutils literal notranslate"><span class="pre">XGBoostClassifier</span></code> as the base estimator
and the Iris dataset as the example.</p>
<section id="iris-dataset-with-xgboost">
<h2>Iris Dataset with XGBoost<a class="headerlink" href="#iris-dataset-with-xgboost" title="Link to this heading"></a></h2>
<p>The Iris dataset is a benchmark dataset
commonly used for multi-class classification. It contains 150 samples from three
species of Iris flowers (Setosa, Versicolour, and Virginica), with four features:
sepal length, sepal width, petal length, and petal width.</p>
<section id="id3">
<h3>Step 1: Import Necessary Libraries<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">model_tuner.model_tuner_utils</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">report_model_metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</pre></div>
</div>
</section>
<section id="id4">
<h3>Step 2: Load the dataset. Define X, y<a class="headerlink" href="#id4" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-define-the-preprocessing-steps">
<h3>Step 3: Define the preprocessing steps<a class="headerlink" href="#step-3-define-the-preprocessing-steps" title="Link to this heading"></a></h3>
<p>Preprocessing is a crucial step in machine learning workflows to ensure the
input data is properly formatted and cleaned for the model. In this case, we
define a preprocessing pipeline to handle scaling and missing values in
numerical features. This ensures that the data is standardized and ready for
training without introducing bias from inconsistent feature ranges or missing values.</p>
<p>The preprocessing pipeline consists of the following components:</p>
<ol class="arabic simple">
<li><p><strong>Numerical Transformer</strong>: A pipeline that applies:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> for standardizing numerical features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> for imputing missing values with the mean strategy.</p></li>
</ul>
</li>
<li><p><strong>Column Transformer</strong>: Applies the numerical transformer to all columns and passes any remaining features through without transformation.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scalercols</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>

<span class="n">numerical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Create the ColumnTransformer with passthrough</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">numerical_transformer</span><span class="p">,</span> <span class="n">scalercols</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s2">&quot;passthrough&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-define-the-estimator-and-hyperparameters">
<h3>Step 4: Define the estimator and hyperparameters<a class="headerlink" href="#step-4-define-the-estimator-and-hyperparameters" title="Link to this heading"></a></h3>
<p>In this step, we configure the <code class="docutils literal notranslate"><span class="pre">XGBoostClassifier</span></code> as the model estimator and define its hyperparameters for multi-class classification.</p>
<ol class="arabic">
<li><p>We use <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> with the <code class="docutils literal notranslate"><span class="pre">objective=&quot;multi:softprob&quot;</span></code> parameter, which specifies multi-class classification using the softmax probability output.</p></li>
<li><p>Assign a name to the estimator for identification in the pipeline (e.g., <code class="docutils literal notranslate"><span class="pre">xgb_mc</span></code> for “XGBoost Multi-Class”).</p></li>
<li><p>Enable early stopping (<code class="docutils literal notranslate"><span class="pre">early_stopping_rounds=20</span></code>) to prevent overfitting by halting training if validation performance does not improve after 20 rounds.</p></li>
<li><p>Define a hyperparameter grid for tuning:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: The maximum depth of a tree (e.g., 3, 10, 15).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: The number of boosting rounds (e.g., 5, 10, 15, 20).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_metric</span></code>: Evaluation metric (<code class="docutils literal notranslate"><span class="pre">mlogloss</span></code> for multi-class log-loss).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: Controls verbosity of output during training (1 = show progress).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code>: Number of rounds for early stopping.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Additional Configuration</strong>:</p>
<ul class="simple">
<li><p>Disable cross-validation (<code class="docutils literal notranslate"><span class="pre">kfold=False</span></code>) and calibration (<code class="docutils literal notranslate"><span class="pre">calibrate=False</span></code>).</p></li>
</ul>
</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s2">&quot;multi:softprob&quot;</span><span class="p">)</span>

<span class="n">estimator_name</span> <span class="o">=</span> <span class="s2">&quot;xgb_mc&quot;</span>
<span class="n">xgbearly</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">kfold</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">calibrate</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</section>
<section id="step-5-initialize-and-configure-the-model">
<h3>Step 5: Initialize and configure the model<a class="headerlink" href="#step-5-initialize-and-configure-the-model" title="Link to this heading"></a></h3>
<p>After defining the preprocessing steps and estimator, the next step is to initialize the <cite>Model</cite> class from the <cite>model_tuner</cite> library. This class brings together all essential components, including the preprocessing pipeline, estimator, hyperparameters, and scoring metrics, to streamline the model training and evaluation process.</p>
<p>The updated configuration includes:</p>
<ol class="arabic simple">
<li><p><strong>Name and Type</strong>:</p>
<ul class="simple">
<li><p>Specify a descriptive <code class="docutils literal notranslate"><span class="pre">name</span></code> for the model (e.g., “XGB Multi Class”).</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">model_type</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;classification&quot;</span></code> for multi-class classification.</p></li>
</ul>
</li>
<li><p>Incorporate the <code class="docutils literal notranslate"><span class="pre">preprocessor</span></code> defined earlier using the <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code>, which handles scaling and imputation for numerical features.</p></li>
<li><p><strong>Estimator and Hyperparameters</strong>:</p>
<ul class="simple">
<li><p>Link the <code class="docutils literal notranslate"><span class="pre">estimator_name</span></code> to the hyperparameter grid defined earlier (<code class="docutils literal notranslate"><span class="pre">tuned_parameters</span></code>).</p></li>
<li><p>Pass the <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> as the <code class="docutils literal notranslate"><span class="pre">estimator</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Early Stopping and Cross-Validation</strong>:</p>
<ul class="simple">
<li><p>Enable early stopping with <code class="docutils literal notranslate"><span class="pre">boost_early=True</span></code>.</p></li>
<li><p>Disable cross-validation with <code class="docutils literal notranslate"><span class="pre">kfold=False</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Additional Configurations</strong>:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stratify_y=True</span></code> for stratified splits.</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">multi_label=True</span></code> to enable multi-class classification.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">roc_auc_ovr</span></code> (One-vs-Rest ROC AUC) as the scoring metric.</p></li>
<li><p>Specify the class labels for the Iris dataset (<code class="docutils literal notranslate"><span class="pre">[&quot;1&quot;,</span> <span class="pre">&quot;2&quot;,</span> <span class="pre">&quot;3&quot;]</span></code>).</p></li>
</ul>
</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_xgb</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;XGB Multi Class&quot;</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
    <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
    <span class="n">pipeline_steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;ColumnTransformer&quot;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">)],</span>
    <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
    <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
    <span class="n">stratify_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">boost_early</span><span class="o">=</span><span class="n">xgbearly</span><span class="p">,</span>
    <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
    <span class="n">multi_label</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">randomized_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">n_iter</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roc_auc_ovr&quot;</span><span class="p">],</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">class_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-6-perform-grid-search-parameter-tuning">
<h3>Step 6: Perform grid search parameter tuning<a class="headerlink" href="#step-6-perform-grid-search-parameter-tuning" title="Link to this heading"></a></h3>
<p>With the model configured, the next step is to perform grid search parameter tuning
to find the optimal hyperparameters for the <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code>. The
<code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning</span></code> method will iterate over all combinations of
hyperparameters specified in <code class="docutils literal notranslate"><span class="pre">tuned_parameters</span></code>, evaluate each one using the
specified scoring metric, and select the best performing set.</p>
<p>This method will:</p>
<ul class="simple">
<li><p><strong>Split the Data</strong>: The data will be split into training and validation sets. Since <code class="docutils literal notranslate"><span class="pre">stratify_y=True</span></code>, the class distribution will be maintained across splits.</p></li>
<li><p><strong>Iterate Over Hyperparameters</strong>: All combinations of hyperparameters defined in <code class="docutils literal notranslate"><span class="pre">tuned_parameters</span></code> will be tried since <code class="docutils literal notranslate"><span class="pre">randomized_grid=False</span></code>.</p></li>
<li><p><strong>Early Stopping</strong>: With <code class="docutils literal notranslate"><span class="pre">boost_early=True</span></code> and <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> set in the hyperparameters, the model will stop training early if the validation score does not improve.</p></li>
<li><p><strong>Scoring</strong>: The model uses <code class="docutils literal notranslate"><span class="pre">roc_auc_ovr</span></code> (One-vs-Rest ROC AUC) as the scoring metric suitable for multi-class classification.</p></li>
<li><p><strong>Select Best Model</strong>: The hyperparameter set that yields the best validation score will be selected.</p></li>
</ul>
<p>To execute the grid search, simply call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Pipeline Steps:

┌───────────────────────────────────────────────────────────┐
│ Step 1: preprocess_column_transformer_ColumnTransformer   │
│ ColumnTransformer                                         │
└───────────────────────────────────────────────────────────┘
                           │
                           ▼
┌───────────────────────────────────────────────────────────┐
│ Step 2: xgb_mc                                            │
│ XGBClassifier                                             │
└───────────────────────────────────────────────────────────┘

100%|██████████| 12/12 [00:00&lt;00:00, 22.10it/s]Best score/param set found on validation set:
{&#39;params&#39;: {&#39;xgb_mc__early_stopping_rounds&#39;: 20,
            &#39;xgb_mc__eval_metric&#39;: &#39;mlogloss&#39;,
            &#39;xgb_mc__max_depth&#39;: 10,
            &#39;xgb_mc__n_estimators&#39;: 10},
&#39;score&#39;: 0.9666666666666668}
Best roc_auc_ovr: 0.967
</pre></div>
</div>
</section>
<section id="step-7-generate-data-splits">
<h3>Step 7: Generate data splits<a class="headerlink" href="#step-7-generate-data-splits" title="Link to this heading"></a></h3>
<p>Once the best hyperparameters are identified through grid search, the next step
is to generate the training, validation, and test splits. The <code class="docutils literal notranslate"><span class="pre">Model</span></code> class
provides built-in methods for creating these splits while maintaining the class
distribution (as specified by <code class="docutils literal notranslate"><span class="pre">stratify_y=True</span></code>).</p>
<p>Use the following code to generate the splits:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Get the training, validation, and test data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Description of Splits</strong>:</p>
<ul class="simple">
<li><p><strong>Training Data</strong> (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>): Used to train the model.</p></li>
<li><p><strong>Validation Data</strong> (<code class="docutils literal notranslate"><span class="pre">X_valid</span></code>, <code class="docutils literal notranslate"><span class="pre">y_valid</span></code>): Used during training for monitoring and fine-tuning, including techniques like early stopping.</p></li>
<li><p><strong>Test Data</strong> (<code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>): Reserved for evaluating the final performance of the trained model.</p></li>
</ul>
<p>These splits ensure that each phase of model development (training, validation, and testing) is performed on separate portions of the dataset, providing a robust evaluation pipeline.</p>
</section>
<section id="id5">
<h3>Step 8: Fit the model<a class="headerlink" href="#id5" title="Link to this heading"></a></h3>
<p>After generating the data splits, the next step is to train the model using the
training data and validate its performance on the validation data during training.
The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method in the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class handles this process seamlessly,
leveraging the best hyperparameters found during grid search.</p>
<p>Use the following code to fit the model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><strong>Training Data</strong> (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>): The model is trained on this data to learn patterns.</p></li>
<li><p><strong>Validation Data</strong> (<code class="docutils literal notranslate"><span class="pre">X_valid</span></code>, <code class="docutils literal notranslate"><span class="pre">y_valid</span></code>): During training, the model monitors its performance on this data to avoid overfitting and apply techniques like early stopping.</p></li>
<li><p><strong>Early Stopping</strong>: If <code class="docutils literal notranslate"><span class="pre">boost_early=True</span></code> and <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> is defined, training will halt early when validation performance stops improving.</p></li>
</ul>
<p>This step ensures that the model is fitted using the best configuration from the grid search and optimized for generalization. With the model trained, proceed to Step 9 to evaluate its performance on validation and test datasets.</p>
</div>
</section>
<section id="id6">
<h3>Step 9: Return metrics (optional)<a class="headerlink" href="#id6" title="Link to this heading"></a></h3>
<p>Once the model is trained, you can evaluate its performance on the validation
and test datasets by returning key metrics. The <code class="docutils literal notranslate"><span class="pre">return_metrics</span></code> method from
the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class calculates and displays metrics like <a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">ROC AUC, precision, recall, and F1-score</span></a>.</p>
<p>Use the following code to return metrics:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate on validation data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_valid</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Predict probabilities for the test data</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate on test data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Metrics&quot;</span><span class="p">)</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
   <span class="n">X_test</span><span class="p">,</span>
   <span class="n">y_test</span><span class="p">,</span>
   <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Validation Metrics
--------------------------------------------------------------------------------
1
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 19 (tn)   1 (fp)
        Neg  0 (fn)  10 (tp)
--------------------------------------------------------------------------------
2
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 19 (tn)   1 (fp)
        Neg  2 (fn)   8 (tp)
--------------------------------------------------------------------------------
3
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 19 (tn)   1 (fp)
        Neg  1 (fn)   9 (tp)
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.91      1.00      0.95        10
           1       0.89      0.80      0.84        10
           2       0.90      0.90      0.90        10

    accuracy                           0.90        30
   macro avg       0.90      0.90      0.90        30
weighted avg       0.90      0.90      0.90        30

--------------------------------------------------------------------------------
Test Metrics
--------------------------------------------------------------------------------
1
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 18 (tn)   2 (fp)
        Neg  0 (fn)  10 (tp)
--------------------------------------------------------------------------------
2
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 19 (tn)   1 (fp)
        Neg  2 (fn)   8 (tp)
--------------------------------------------------------------------------------
3
         Predicted:
            Pos  Neg
--------------------------------------------------------------------------------
Actual: Pos 20 (tn)   0 (fp)
        Neg  1 (fn)   9 (tp)
--------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.83      1.00      0.91        10
           1       0.89      0.80      0.84        10
           2       1.00      0.90      0.95        10

    accuracy                           0.90        30
   macro avg       0.91      0.90      0.90        30
weighted avg       0.91      0.90      0.90        30

--------------------------------------------------------------------------------
{&#39;Classification Report&#39;: {&#39;0&#39;: {&#39;precision&#39;: 0.8333333333333334,
   &#39;recall&#39;: 1.0,
   &#39;f1-score&#39;: 0.9090909090909091,
   &#39;support&#39;: 10.0},
&#39;1&#39;: {&#39;precision&#39;: 0.8888888888888888,
   &#39;recall&#39;: 0.8,
   &#39;f1-score&#39;: 0.8421052631578948,
   &#39;support&#39;: 10.0},
&#39;2&#39;: {&#39;precision&#39;: 1.0,
   &#39;recall&#39;: 0.9,
   &#39;f1-score&#39;: 0.9473684210526316,
   &#39;support&#39;: 10.0},
&#39;accuracy&#39;: 0.9,
&#39;macro avg&#39;: {&#39;precision&#39;: 0.9074074074074074,
   &#39;recall&#39;: 0.9,
   &#39;f1-score&#39;: 0.8995215311004786,
   &#39;support&#39;: 30.0},
&#39;weighted avg&#39;: {&#39;precision&#39;: 0.9074074074074073,
   &#39;recall&#39;: 0.9,
   &#39;f1-score&#39;: 0.8995215311004785,
   &#39;support&#39;: 30.0}},
&#39;Confusion Matrix&#39;: array([[[18,  2],
        [ 0, 10]],

       [[19,  1],
        [ 2,  8]],

       [[20,  0],
        [ 1,  9]]])}
</pre></div>
</div>
<section id="id7">
<h4>Report Model Metrics<a class="headerlink" href="#id7" title="Link to this heading"></a></h4>
<p>You can summarize and display the model’s performance metrics using the
<code class="docutils literal notranslate"><span class="pre">report_model_metrics</span></code> function. This function computes key metrics like
<a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">precision, recall, F1-score, and ROC AUC</span></a> for each class, as well as macro and weighted averages.</p>
<p>Use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metrics_df</span> <span class="o">=</span> <span class="n">report_model_metrics</span><span class="p">(</span>
   <span class="n">model</span><span class="o">=</span><span class="n">model_xgb</span><span class="p">,</span>
   <span class="n">X_valid</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
   <span class="n">y_valid</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
   <span class="n">threshold</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">model_xgb</span><span class="o">.</span><span class="n">threshold</span><span class="o">.</span><span class="n">values</span><span class="p">())),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics_df</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>0 Precision/PPV                  0.833333
0 Sensitivity/Recall             1.000000
0 F1-Score                       0.909091
1 Precision/PPV                  0.888889
1 Sensitivity/Recall             0.800000
1 F1-Score                       0.842105
2 Precision/PPV                  1.000000
2 Sensitivity/Recall             0.900000
2 F1-Score                       0.947368
macro avg Precision/PPV          0.907407
macro avg Sensitivity/Recall     0.900000
macro avg F1-Score               0.899522
weighted avg Precision/PPV       0.907407
weighted avg Sensitivity/Recall  0.900000
weighted avg F1-Score            0.899522
Weighted Average Precision       0.907407
Weighted Average Recall          0.900000
Multiclass AUC ROC               0.933333
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Validation Metrics: Provide insights into how well the model performed during training and tuning on unseen validation data.</p></li>
<li><p>Test Metrics: Assess the final model’s generalization performance on completely unseen test data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>: Outputs the predicted probabilities for each class, useful for calculating metrics like ROC AUC or understanding the model’s confidence in its predictions.</p></li>
</ul>
</div>
<p>By examining these metrics, you can evaluate the model’s strengths and weaknesses and determine if further fine-tuning or adjustments are necessary.</p>
</section>
</section>
<section id="step-10-predict-probabilities-and-generate-predictions">
<h3>Step 10: Predict probabilities and generate predictions<a class="headerlink" href="#step-10-predict-probabilities-and-generate-predictions" title="Link to this heading"></a></h3>
<p>As an additional step, you can use the trained model to predict probabilities and
generate predictions for the test data. This is particularly useful for analyzing
model outputs or evaluating predictions with custom thresholds.</p>
<p>Use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Predict probabilities for the test data</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1">## Predict class labels using the optimal threshold</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Print results</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted Probabilities: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">y_prob</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">y_pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Predicted Probabilities:
[0.961671   0.02298635 0.749543   0.02298635 0.0244073  0.02298635
0.94500786 0.02298635 0.0227305  0.02298635 0.14078036 0.32687086
0.94500786 0.961671   0.95576227 0.02298635 0.02298635 0.02298635
0.961671   0.0244073  0.0227305  0.02298635 0.02298635 0.38560066
0.02298635 0.02298635 0.961671   0.0227305  0.0227305  0.4547262 ]

Predictions:
[1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><strong>Predicted Probabilities</strong> (<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>): Returns the probabilities for each class. The <code class="docutils literal notranslate"><span class="pre">[:,</span> <span class="pre">1]</span></code> selects the probabilities for the second class (or one of interest).</p></li>
<li><p><strong>Predicted Labels</strong> (<code class="docutils literal notranslate"><span class="pre">predict</span></code>): Generates class predictions using the optimal threshold, which is tuned during grid search or based on the scoring metric.</p></li>
<li><p><strong>Optimal Threshold</strong>: When <code class="docutils literal notranslate"><span class="pre">optimal_threshold=True</span></code>, the model uses the threshold that maximizes a selected performance metric (e.g., F1-score or ROC AUC) instead of the default threshold of 0.5.</p></li>
<li><p><strong>Analysis</strong>: Inspecting probabilities and predictions helps to interpret the model’s confidence and accuracy in making decisions.</p></li>
</ul>
<p>This step allows for a deeper understanding of the model’s predictions and can be used to fine-tune decision thresholds or evaluate specific cases.</p>
</div>
</section>
</section>
</section>
<section id="regression">
<span id="id8"></span><h1>Regression<a class="headerlink" href="#regression" title="Link to this heading"></a></h1>
<p>Here is an example of using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class for a <strong>regression task</strong> with <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> on the <strong>California Housing dataset</strong>.</p>
<p>The California Housing dataset, available in the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> library, is a commonly used benchmark dataset for regression problems. It contains features such as median income, housing age, and population, which are used to predict the median house value for California districts.</p>
<p>In this example, we leverage the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class to:</p>
<ul class="simple">
<li><p>Set up an <strong>XGBoost regressor</strong> as the estimator.</p></li>
<li><p>Define a hyperparameter grid for tuning the model.</p></li>
<li><p>Preprocess the dataset, train the model, and evaluate its performance using the <span class="math notranslate nohighlight">\(R^2\)</span> metric.</p></li>
</ul>
<p>The workflow highlights how the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class simplifies regression tasks, including hyperparameter tuning, and performance evaluation.</p>
<section id="california-housing-with-xgboost">
<h2>California Housing with XGBoost<a class="headerlink" href="#california-housing-with-xgboost" title="Link to this heading"></a></h2>
<section id="id9">
<h3>Step 1: Import necessary libraries<a class="headerlink" href="#id9" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">model_tuner</span> <span class="kn">import</span> <span class="n">Model</span>
</pre></div>
</div>
</section>
<section id="step-2-load-the-dataset">
<h3>Step 2: Load the dataset<a class="headerlink" href="#step-2-load-the-dataset" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Load the California Housing dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-create-an-instance-of-the-xgbregressor">
<h3>Step 3: Create an instance of the XGBRegressor<a class="headerlink" href="#step-3-create-an-instance-of-the-xgbregressor" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_name</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-4-define-hyperparameters-for-xgbregressor">
<h3>Step 4: Define Hyperparameters for XGBRegressor<a class="headerlink" href="#step-4-define-hyperparameters-for-xgbregressor" title="Link to this heading"></a></h3>
<p>In this step, we configure the <code class="docutils literal notranslate"><span class="pre">XGBRegressor</span></code> for a regression task.
The hyperparameter grid includes key settings to control the learning process,
tree construction, and generalization performance of the model.</p>
<p>The hyperparameter grid and model configuration are defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tuned_parameters_xgb</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">][:</span><span class="mi">1</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">][:</span><span class="mi">1</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__colsample_bytree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">][:</span><span class="mi">1</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__early_stopping_rounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__tree_method&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;hist&quot;</span><span class="p">],</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">xgb_name</span><span class="si">}</span><span class="s2">__verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">xgb_definition</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;clc&quot;</span><span class="p">:</span> <span class="n">xgb</span><span class="p">,</span>
    <span class="s2">&quot;estimator_name&quot;</span><span class="p">:</span> <span class="n">xgb_name</span><span class="p">,</span>
    <span class="s2">&quot;tuned_parameters&quot;</span><span class="p">:</span> <span class="n">tuned_parameters_xgb</span><span class="p">,</span>
    <span class="s2">&quot;randomized_grid&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;early&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">model_definition</span> <span class="o">=</span> <span class="p">{</span><span class="n">xgb_name</span><span class="p">:</span> <span class="n">xgb_definition</span><span class="p">}</span>
</pre></div>
</div>
<p><strong>Key Configurations</strong></p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: Controls the contribution of each boosting round to the final prediction.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: Specifies the total number of boosting rounds (trees).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: Limits the depth of each tree to prevent overfitting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">subsample</span></code>: Fraction of training data used for fitting each tree, introducing randomness to improve generalization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">colsample_bytree</span></code>: Fraction of features considered for each boosting round.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_metric</span></code>: Specifies the evaluation metric to monitor during training (e.g., <code class="docutils literal notranslate"><span class="pre">&quot;logloss&quot;</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code>: Stops training if validation performance does not improve for a set number of rounds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tree_method</span></code>: Chooses the algorithm used for tree construction (<code class="docutils literal notranslate"><span class="pre">&quot;hist&quot;</span></code> for histogram-based methods, optimized for speed).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: Controls output display during training (set to <code class="docutils literal notranslate"><span class="pre">0</span></code> for silent mode).</p></li>
</ol>
</section>
<section id="id10">
<h3>Step 5: Initialize and configure the <code class="docutils literal notranslate"><span class="pre">Model</span></code><a class="headerlink" href="#id10" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">XGBRegressor</span></code> inherently handles missing values (<code class="docutils literal notranslate"><span class="pre">NaN</span></code>) without requiring explicit
imputation strategies. During training, <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> treats missing values as a
separate category and learns how to route them within its decision trees.
Therefore, passing a <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> or using an imputation strategy is unnecessary
when using <code class="docutils literal notranslate"><span class="pre">XGBRegressor</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kfold</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">calibrate</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1">## Define model object</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;xgb&quot;</span>
<span class="n">clc</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="s2">&quot;clc&quot;</span><span class="p">]</span>
<span class="n">estimator_name</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="s2">&quot;estimator_name&quot;</span><span class="p">]</span>

<span class="c1">## Set the parameters by cross-validation</span>
<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="s2">&quot;tuned_parameters&quot;</span><span class="p">]</span>
<span class="n">rand_grid</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="s2">&quot;randomized_grid&quot;</span><span class="p">]</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="s2">&quot;early&quot;</span><span class="p">]</span>

<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
   <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;xgb_</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
   <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
   <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;regression&quot;</span><span class="p">,</span>
   <span class="n">calibrate</span><span class="o">=</span><span class="n">calibrate</span><span class="p">,</span>
   <span class="n">estimator</span><span class="o">=</span><span class="n">clc</span><span class="p">,</span>
   <span class="n">kfold</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
   <span class="n">stratify_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
   <span class="n">grid</span><span class="o">=</span><span class="n">tuned_parameters</span><span class="p">,</span>
   <span class="n">randomized_grid</span><span class="o">=</span><span class="n">rand_grid</span><span class="p">,</span>
   <span class="n">boost_early</span><span class="o">=</span><span class="n">early_stop</span><span class="p">,</span>
   <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;r2&quot;</span><span class="p">],</span>
   <span class="n">random_state</span><span class="o">=</span><span class="mi">222</span><span class="p">,</span>
   <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-6-perform-grid-search-parameter-tuning-and-retrieve-split-data">
<h3>Step 6: Perform grid search parameter tuning and retrieve split data<a class="headerlink" href="#step-6-perform-grid-search-parameter-tuning-and-retrieve-split-data" title="Link to this heading"></a></h3>
<p>To execute the grid search, simply call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_xgb</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">## Get the training, validation, and test data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_train_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_valid_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">get_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>With the model configured, the next step is to perform grid search parameter tuning
to find the optimal hyperparameters for the <code class="docutils literal notranslate"><span class="pre">XGBRegressor</span></code>. The
<code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning</span></code> method will iterate over all combinations of
hyperparameters specified in <code class="docutils literal notranslate"><span class="pre">tuned_parameters_xgb</span></code>, evaluate each one using the
specified scoring metric, and select the best performing set.</p>
<p>This method will:</p>
<ul class="simple">
<li><p><strong>Split the Data</strong>: The data will be split into training and validation sets. Since <code class="docutils literal notranslate"><span class="pre">stratify_y=False</span></code>, the class distribution will not be maintained across splits.</p></li>
<li><p><strong>Iterate Over Hyperparameters</strong>: All combinations of hyperparameters defined in <code class="docutils literal notranslate"><span class="pre">tuned_parameters_xgb</span></code> will be tried since <code class="docutils literal notranslate"><span class="pre">randomized_grid=False</span></code>.</p></li>
<li><p><strong>Early Stopping</strong>: With <code class="docutils literal notranslate"><span class="pre">boost_early=True</span></code> and <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> set in the hyperparameters, the model will stop training early if the validation score does not improve.</p></li>
<li><p><strong>Scoring</strong>: The model uses <span class="math notranslate nohighlight">\(R^2\)</span> as the scoring metric, which is suitable for evaluating regression models.</p></li>
<li><p><strong>Select Best Model</strong>: The hyperparameter set that yields the best validation score based on the specified metric (<span class="math notranslate nohighlight">\(R^2\)</span>) will be selected.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Pipeline Steps:

┌────────────────┐
│ Step 1: xgb    │
│ XGBRegressor   │
└────────────────┘

100%|██████████| 9/9 [00:22&lt;00:00,  2.45s/it]Best score/param set found on validation set:
{&#39;params&#39;: {&#39;xgb__colsample_bytree&#39;: 0.8,
            &#39;xgb__early_stopping_rounds&#39;: 10,
            &#39;xgb__eval_metric&#39;: &#39;logloss&#39;,
            &#39;xgb__learning_rate&#39;: 0.1,
            &#39;xgb__max_depth&#39;: 3,
            &#39;xgb__n_estimators&#39;: 67,
            &#39;xgb__subsample&#39;: 0.8,
            &#39;xgb__tree_method&#39;: &#39;hist&#39;},
&#39;score&#39;: 0.7651490279157868}
Best r2: 0.765
</pre></div>
</div>
</section>
<section id="step-7-fit-the-model">
<h3>Step 7: Fit the model<a class="headerlink" href="#step-7-fit-the-model" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
   <span class="n">X_train</span><span class="p">,</span>
   <span class="n">y_train</span><span class="p">,</span>
   <span class="n">validation_data</span><span class="o">=</span><span class="p">[</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-8-return-metrics-optional">
<h3>Step 8: Return metrics (optional)<a class="headerlink" href="#step-8-return-metrics-optional" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Validation</span> <span class="n">Metrics</span>
<span class="o">********************************************************************************</span>
<span class="p">{</span><span class="s1">&#39;Explained Variance&#39;</span><span class="p">:</span> <span class="mf">0.7647451659057567</span><span class="p">,</span>
<span class="s1">&#39;Mean Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.3830825326824073</span><span class="p">,</span>
<span class="s1">&#39;Mean Squared Error&#39;</span><span class="p">:</span> <span class="mf">0.3066172248224347</span><span class="p">,</span>
<span class="s1">&#39;Median Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.2672762813568116</span><span class="p">,</span>
<span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.7647433075624044</span><span class="p">,</span>
<span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="mf">0.5537302816556403</span><span class="p">}</span>
<span class="o">********************************************************************************</span>
<span class="n">Test</span> <span class="n">Metrics</span>
<span class="o">********************************************************************************</span>
<span class="p">{</span><span class="s1">&#39;Explained Variance&#39;</span><span class="p">:</span> <span class="mf">0.7888942913974833</span><span class="p">,</span>
<span class="s1">&#39;Mean Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.3743548199982513</span><span class="p">,</span>
<span class="s1">&#39;Mean Squared Error&#39;</span><span class="p">:</span> <span class="mf">0.28411432705731066</span><span class="p">,</span>
<span class="s1">&#39;Median Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.26315186452865597</span><span class="p">,</span>
<span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.7888925135381788</span><span class="p">,</span>
<span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="mf">0.533023758436067</span><span class="p">}</span>
<span class="o">********************************************************************************</span>
<span class="p">{</span><span class="s1">&#39;Explained Variance&#39;</span><span class="p">:</span> <span class="mf">0.7888942913974833</span><span class="p">,</span>
<span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.7888925135381788</span><span class="p">,</span>
<span class="s1">&#39;Mean Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.3743548199982513</span><span class="p">,</span>
<span class="s1">&#39;Median Absolute Error&#39;</span><span class="p">:</span> <span class="mf">0.26315186452865597</span><span class="p">,</span>
<span class="s1">&#39;Mean Squared Error&#39;</span><span class="p">:</span> <span class="mf">0.28411432705731066</span><span class="p">,</span>
<span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="mf">0.533023758436067</span><span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="performance-evaluation-metrics">
<h1>Performance Evaluation Metrics<a class="headerlink" href="#performance-evaluation-metrics" title="Link to this heading"></a></h1>
<section id="using-report-model-metrics">
<h2>Using <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code><a class="headerlink" href="#using-report-model-metrics" title="Link to this heading"></a></h2>
<p>The <a class="reference internal" href="#report-model-metrics"><span class="std std-ref">report_model_metrics()</span></a> method provides detailed insights into model
performance, including metrics such as <a class="reference internal" href="caveats.html#limitations-of-accuracy"><span class="std std-ref">precision, recall, sensitivity, specificity, and AUC-ROC</span></a>.
For regression models, it includes key metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE),
Root Mean Squared Error (RMSE), R² Score, and Explained Variance.</p>
<p>While this method is integrated into <code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code>, it can also be invoked independently for
custom evaluation workflows. For example, it can be used to focus on specific metrics or to analyze
a subset of the data.</p>
</section>
<section id="using-return-metrics">
<h2>Using <code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code><a class="headerlink" href="#using-return-metrics" title="Link to this heading"></a></h2>
<p>A key feature of <a class="reference internal" href="#return-metrics"><span class="std std-ref">return_metrics()</span></a> is its ability to retrieve and print the
threshold value used to train the model. This threshold can be passed directly
into <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code> for consistent evaluation.</p>
</section>
<section id="threshold-tuning">
<h2>Threshold Tuning<a class="headerlink" href="#threshold-tuning" title="Link to this heading"></a></h2>
<p>Model thresholding is a critical concept in classification tasks, allowing you
to fine-tune the decision boundary for predicting positive or negative classes.
Instead of relying on the default threshold of 0.5, which may not suit all
datasets or evaluation metrics, <a class="reference internal" href="caveats.html#threshold-tuning-considerations"><span class="std std-ref">thresholds can be adjusted</span></a>
to optimize metrics like <a class="reference internal" href="caveats.html#precision"><span class="std std-ref">precision</span></a>, <a class="reference internal" href="caveats.html#recall"><span class="std std-ref">recall</span></a>, or <a class="reference internal" href="caveats.html#f1-score"><span class="std std-ref">F1-score</span></a>
based on your specific objectives.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">model.threshold</span></code> attribute provides a dictionary where each scoring metric
is paired with its corresponding optimal threshold, enabling precise control over
predictions. This is particularly useful in applications where the cost of false
positives and false negatives differs significantly.</p>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Accessing the optimal thresholds for each scoring metric</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_xgb</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;roc_auc&#39;: 0.25}
</pre></div>
</div>
<p><strong>When to Use Custom Thresholds</strong>:</p>
<ul class="simple">
<li><p><strong>Imbalanced Datasets</strong>: Adjusting thresholds can help mitigate the effects of class imbalance by prioritizing recall or precision for the minority class.</p></li>
<li><p><strong>Domain-Specific Goals</strong>: In medical diagnostics, for instance, you might prefer a lower threshold to maximize sensitivity (recall) and minimize false negatives.</p></li>
<li><p><strong>Optimizing for Specific Metrics</strong>: If your primary evaluation metric is F-beta, tuning the threshold ensures better alignment with your goals.</p></li>
</ul>
<section id="how-to-automatically-tune-thresholds">
<span id="f1-beta"></span><h3>How to Automatically Tune Thresholds<a class="headerlink" href="#how-to-automatically-tune-thresholds" title="Link to this heading"></a></h3>
<p>The optimal threshold can be automatically tuned by enabling F-beta optimization
during parameter tuning. This can be done by setting <code class="docutils literal notranslate"><span class="pre">f1_beta_tune=True</span></code> in
the <code class="docutils literal notranslate"><span class="pre">grid_search_param_tuning()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Automatically tune thresholds for F-beta optimization</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">grid_search_param_tuning</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f1_beta_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>After tuning, the optimal thresholds will be stored in the <code class="docutils literal notranslate"><span class="pre">model.threshold</span></code>
attribute for each scoring metric:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Retrieve the optimal threshold for a specific metric</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="using-threshold-in-report-model-metrics">
<h3>Using threshold in <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code><a class="headerlink" href="#using-threshold-in-report-model-metrics" title="Link to this heading"></a></h3>
<p>After calling <code class="docutils literal notranslate"><span class="pre">return_metrics()</span></code> with <code class="docutils literal notranslate"><span class="pre">optimal_threshold=True</span></code>,
you can reuse the threshold in <code class="docutils literal notranslate"><span class="pre">report_model_metrics()</span></code> as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">]</span>  <span class="c1"># Retrieve the optimal threshold</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">report_model_metrics</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="reporting-threshold-in-return-metrics">
<h3>Reporting Threshold in <code class="docutils literal notranslate"><span class="pre">return_metrics</span></code><a class="headerlink" href="#reporting-threshold-in-return-metrics" title="Link to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">return_metrics</span></code> method provides the flexibility to retrieve and print the
threshold used during model evaluation, enabling seamless reuse in other methods
or manual experimentation. When <code class="docutils literal notranslate"><span class="pre">print_threshold=True</span></code> is specified, the
threshold will be included as part of the output, making it easy to reference
and apply in subsequent analyses.</p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve metrics and threshold using return_metrics</span>
<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_metrics</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_valid</span><span class="p">,</span>
    <span class="n">optimal_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">print_threshold</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">model_metrics</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>By including <code class="docutils literal notranslate"><span class="pre">print_threshold=True</span></code>, the optimal threshold used for predictions
is displayed, ensuring transparency and providing a valuable reference for further
evaluations or custom workflows.</p>
</section>
</section>
<section id="classification-report-optional">
<span id="classification-report"></span><h2>Classification report (optional)<a class="headerlink" href="#classification-report-optional" title="Link to this heading"></a></h2>
<p>A call to <code class="docutils literal notranslate"><span class="pre">print(model_xgb.classification_report)</span></code> will
output the classification report as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model_xgb</span><span class="o">.</span><span class="n">classification_report</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.91      0.94      0.92       324
           1       0.79      0.71      0.75       104

    accuracy                           0.88       428
   macro avg       0.85      0.82      0.84       428
weighted avg       0.88      0.88      0.88       428
</pre></div>
</div>
</section>
</section>
<section id="bootstrap-metrics">
<h1>Bootstrap Metrics<a class="headerlink" href="#bootstrap-metrics" title="Link to this heading"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">bootstrapper.py</span></code> module provides utility functions for input type checking,
data resampling, and evaluating bootstrap metrics.</p>
<dl class="py function">
<dt class="sig sig-object py" id="check_input_type">
<span class="sig-name descname"><span class="pre">check_input_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#check_input_type" title="Link to this definition"></a></dt>
<dd><p>Validates and normalizes the input type for data processing. Converts NumPy arrays, Pandas Series, and DataFrames into a standard Pandas DataFrame with a reset index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array-like</em>) – Input data (NumPy array, Pandas Series, or DataFrame).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalized input as a Pandas DataFrame.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If the input type is not supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sampling_method">
<span class="sig-name descname"><span class="pre">sampling_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_proportions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sampling_method" title="Link to this definition"></a></dt>
<dd><p>Resamples a dataset based on specified options for balancing, stratification, or custom class proportions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>pandas.Series</em>) – Target variable to resample.</p></li>
<li><p><strong>n_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of samples to draw.</p></li>
<li><p><strong>stratify</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to stratify based on the provided target variable.</p></li>
<li><p><strong>balance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to balance class distributions equally.</p></li>
<li><p><strong>class_proportions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><em>optional</em>) – Custom proportions for each class. Must sum to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Resampled target variable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If class proportions do not sum to 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="evaluate_bootstrap_metrics">
<span class="sig-name descname"><span class="pre">evaluate_bootstrap_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_resamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['roc_auc',</span> <span class="pre">'f1_weighted',</span> <span class="pre">'average_precision']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'classification'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_proportions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#evaluate_bootstrap_metrics" title="Link to this definition"></a></dt>
<dd><p>Evaluates classification or regression metrics on bootstrap samples using a pre-trained model or pre-computed predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><em>object</em></a><em>, </em><em>optional</em>) – Pre-trained model with a <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method. Required if <code class="docutils literal notranslate"><span class="pre">y_pred_prob</span></code> is not provided.</p></li>
<li><p><strong>X</strong> (<em>array-like</em><em>, </em><em>optional</em>) – Input features. Not required if <code class="docutils literal notranslate"><span class="pre">y_pred_prob</span></code> is provided.</p></li>
<li><p><strong>y</strong> (<em>array-like</em>) – Ground truth labels.</p></li>
<li><p><strong>y_pred_prob</strong> (<em>array-like</em><em>, </em><em>optional</em>) – Pre-computed predicted probabilities.</p></li>
<li><p><strong>n_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of samples per bootstrap iteration. Default is 500.</p></li>
<li><p><strong>num_resamples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of bootstrap iterations. Default is 1000.</p></li>
<li><p><strong>metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – List of metrics to calculate (e.g., <code class="docutils literal notranslate"><span class="pre">&quot;roc_auc&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;f1_weighted&quot;</span></code>).</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for reproducibility. Default is 42.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Classification threshold for probability predictions. Default is 0.5.</p></li>
<li><p><strong>model_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Specifies the task type, either <code class="docutils literal notranslate"><span class="pre">&quot;classification&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;regression&quot;</span></code>.</p></li>
<li><p><strong>stratify</strong> (<em>pandas.Series</em><em>, </em><em>optional</em>) – Variable for stratified sampling.</p></li>
<li><p><strong>balance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to balance class distributions.</p></li>
<li><p><strong>class_proportions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><em>optional</em>) – Custom class proportions for sampling.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>DataFrame with mean and confidence intervals for each metric.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If invalid parameters or metrics are provided.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.13)"><strong>RuntimeError</strong></a> – If sample size is insufficient for metric calculation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">model_tuner_utils.py</span></code> module includes utility functions for evaluating bootstrap metrics in the context of model tuning.</p>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="return_bootstrap_metrics">
<span class="sig-name descname"><span class="pre">return_bootstrap_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_resamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#return_bootstrap_metrics" title="Link to this definition"></a></dt>
<dd><p>Evaluates bootstrap metrics for a trained model using the test dataset. This function supports both classification and regression tasks by leveraging <cite>evaluate_bootstrap_metrics</cite> to compute confidence intervals for the specified metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_test</strong> (<em>pandas.DataFrame</em>) – Test dataset features.</p></li>
<li><p><strong>y_test</strong> (<em>pandas.Series</em><em> or </em><em>pandas.DataFrame</em>) – Test dataset labels.</p></li>
<li><p><strong>metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – List of metric names to calculate (e.g., <code class="docutils literal notranslate"><span class="pre">&quot;roc_auc&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;f1_weighted&quot;</span></code>).</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold for converting predicted probabilities into class predictions. Default is 0.5.</p></li>
<li><p><strong>num_resamples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of bootstrap iterations. Default is 500.</p></li>
<li><p><strong>n_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of samples per bootstrap iteration. Default is 500.</p></li>
<li><p><strong>balance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to balance the class distribution during resampling. Default is False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>DataFrame containing mean and confidence intervals for the specified metrics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">X_test</span></code> or <code class="docutils literal notranslate"><span class="pre">y_test</span></code> are not provided as Pandas DataFrames or if unsupported input types are specified.</p>
</dd>
</dl>
</dd></dl>

<section id="bootstrap-metrics-example">
<h2>Bootstrap metrics example<a class="headerlink" href="#bootstrap-metrics-example" title="Link to this heading"></a></h2>
<p>Continuing from the model output object (<code class="docutils literal notranslate"><span class="pre">model_xgb</span></code>) from the <a class="reference internal" href="#regression"><span class="std std-ref">regression example</span></a> above, we leverage the <code class="docutils literal notranslate"><span class="pre">return_bootstrap_metrics</span></code> method from <code class="docutils literal notranslate"><span class="pre">model_tuner_utils.py</span></code> to print bootstrap performance metrics (<span class="math notranslate nohighlight">\(R^2\)</span> and <span class="math notranslate nohighlight">\(\text{explained variance}\)</span>) at 95% confidence levels as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bootstrap Metrics&quot;</span><span class="p">)</span>

<span class="n">model_xgb</span><span class="o">.</span><span class="n">return_bootstrap_metrics</span><span class="p">(</span>
   <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
   <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
   <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="s2">&quot;explained_variance&quot;</span><span class="p">],</span>
   <span class="n">n_samples</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
   <span class="n">num_resamples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Bootstrap Metrics
100%|██████████| 300/300 [00:00&lt;00:00, 358.05it/s]
Metric                     Mean  95% CI Lower  95% CI Upper
0                 r2   0.781523      0.770853      0.792193
1 explained_variance   0.788341      0.777898      0.798785
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="getting_started.html" class="btn btn-neutral float-left" title="Welcome to Model Tuner’s Documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="caveats.html" class="btn btn-neutral float-right" title="Zero Variance Columns" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, UCLA CTSI ML Team: Leonid Shpaner, Arthur Funnell, Panayiotis Petousis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>