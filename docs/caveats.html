

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Zero Variance Columns &mdash; Model Tuner 0.0.15a0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=f712845e" />

  
    <link rel="canonical" href="https://uclamii.github.io/model_tuner/caveats.html" />
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=e34472b7"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
      <script src="_static/custom.js?v=59429b38"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="GitHub Repository" href="about.html" />
    <link rel="prev" title="iPython Notebooks" href="usage_guide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Model Tuner
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Welcome to Model Tuner’s Documentation!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html">iPython Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html#key-methods-and-functionalities">Key Methods and Functionalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html#helper-functions">Helper Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html#input-parameters">Input Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html#binary-classification">Binary Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_guide.html#regression">Regression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Caveats</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Zero Variance Columns</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#effects-on-model-training">Effects on Model Training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#dependent-variable">Dependent Variable</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#target-variable-shape-and-its-effects">Target Variable Shape and Its Effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#solution">Solution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#imputation-before-scaling">Imputation Before Scaling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#accurate-calculation-of-scaling-parameters">1. Accurate Calculation of Scaling Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#consistency-in-data-transformation">2. Consistency in Data Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prevention-of-distortion-in-scaling">3. Prevention of Distortion in Scaling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#column-stratification-with-cross-validation">Column Stratification with Cross-Validation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#cross-validation-and-stratification">Cross-Validation and Stratification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model-calibration">Model Calibration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#goal-of-calibration">Goal of Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="#calibration-curve">Calibration Curve</a></li>
<li class="toctree-l1"><a class="reference internal" href="#brier-score">Brier Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="#platt-scaling">Platt Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="#isotonic-regression">Isotonic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="#example-calibration-in-logistic-regression">Example: Calibration in Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About Model Tuner</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">GitHub Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#acknowledgements">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html#citing-model-tuner">Citing Model Tuner</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Model Tuner</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Zero Variance Columns</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="no-click"><a class="reference internal image-reference" href="_images/ModelTunerTarget.png"><img alt="Model Tuner Logo" class="align-left" src="_images/ModelTunerTarget.png" style="width: 250px;" />
</a>
</div><div style="height: 150px;"></div><p></p>
<section id="zero-variance-columns">
<h1>Zero Variance Columns<a class="headerlink" href="#zero-variance-columns" title="Link to this heading"></a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Ensure that your feature set <cite>X</cite> is free of zero-variance columns before using this method.
Zero-variance columns can lead to issues such as <code class="docutils literal notranslate"><span class="pre">UserWarning:</span> <span class="pre">Features[feat_num]</span> <span class="pre">are</span> <span class="pre">constant</span></code>
and <code class="docutils literal notranslate"><span class="pre">RuntimeWarning:</span> <span class="pre">invalid</span> <span class="pre">value</span> <span class="pre">encountered</span> <span class="pre">in</span> <span class="pre">divide</span> <span class="pre">f</span> <span class="pre">=</span> <span class="pre">msb/msw</span></code> during the model training process.</p>
<p>To check for and remove zero-variance columns, you can use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check for zero-variance columns and drop them</span>
<span class="n">zero_variance_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">zero_variance_columns</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">zero_variance_columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Zero-variance columns in the feature set <span class="math notranslate nohighlight">\(X\)</span> refer to columns where all values are identical.
Mathematically, if <span class="math notranslate nohighlight">\(X_j\)</span> is a column in <span class="math notranslate nohighlight">\(X\)</span>, the variance of this column is calculated as:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(X_j) = \frac{1}{n} \sum_{i=1}^{n} (X_{ij} - \bar{X}_j)^2 = 0\]</div>
<p>where <span class="math notranslate nohighlight">\(X_{ij}\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th observation of feature <span class="math notranslate nohighlight">\(j\)</span>, and <span class="math notranslate nohighlight">\(\bar{X}_j\)</span> is the mean of the <span class="math notranslate nohighlight">\(j\)</span>-th feature.
Since all <span class="math notranslate nohighlight">\(X_{ij}\)</span> are equal, <span class="math notranslate nohighlight">\(\text{Var}(X_j)\)</span> is zero.</p>
<section id="effects-on-model-training">
<h2>Effects on Model Training<a class="headerlink" href="#effects-on-model-training" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>UserWarning:</strong></p>
<p>During model training, algorithms often check for variability in features to determine their usefulness in predicting the target variable. A zero-variance column provides no information, leading to the following warning:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>UserWarning: Features[feat_num] are constant
</pre></div>
</div>
<p>This indicates that the feature <span class="math notranslate nohighlight">\(X_j\)</span> has no variability and, therefore, cannot contribute to the model’s predictive power.</p>
</li>
<li><p><strong>RuntimeWarning:</strong></p>
<p>When calculating metrics like the F-statistic used in Analysis of Variance (ANOVA) or feature importance metrics, the following ratio is computed:</p>
<div class="math notranslate nohighlight">
\[F = \frac{\text{MSB}}{\text{MSW}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\text{MSB}\)</span> (Mean Square Between) and <span class="math notranslate nohighlight">\(\text{MSW}\)</span> (Mean Square Within) are defined as:</p>
<div class="math notranslate nohighlight">
\[\text{MSB} = \frac{1}{k-1} \sum_{j=1}^{k} n_j (\bar{X}_j - \bar{X})^2\]</div>
<div class="math notranslate nohighlight">
\[\text{MSW} = \frac{1}{n-k} \sum_{j=1}^{k} \sum_{i=1}^{n_j} (X_{ij} - \bar{X}_j)^2\]</div>
<p>If <span class="math notranslate nohighlight">\(X_j\)</span> is a zero-variance column, then <span class="math notranslate nohighlight">\(\text{MSW} = 0\)</span> because all <span class="math notranslate nohighlight">\(X_{ij}\)</span> are equal to <span class="math notranslate nohighlight">\(\bar{X}_j\)</span>. This leads to a division by zero in the calculation of <span class="math notranslate nohighlight">\(F\)</span>:</p>
<div class="math notranslate nohighlight">
\[F = \frac{\text{MSB}}{0} \rightarrow \text{undefined}\]</div>
<p>which triggers a runtime warning:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>RuntimeWarning: invalid value encountered in divide f = msb/msw
</pre></div>
</div>
<p>indicating that the calculation involves dividing by zero, resulting in undefined or infinite values.</p>
</li>
</ol>
<p>To avoid these issues, ensure that zero-variance columns are removed from <span class="math notranslate nohighlight">\(X\)</span> before proceeding with model training.</p>
</section>
</section>
<section id="dependent-variable">
<h1>Dependent Variable<a class="headerlink" href="#dependent-variable" title="Link to this heading"></a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Additionally, ensure that <cite>y</cite> (the target variable) is passed as a Series and not as a DataFrame.
Passing <cite>y</cite> as a DataFrame can cause issues such as <code class="docutils literal notranslate"><span class="pre">DataConversionWarning:</span> <span class="pre">A</span> <span class="pre">column-vector</span> <span class="pre">y</span> <span class="pre">was</span> <span class="pre">passed</span>
<span class="pre">when</span> <span class="pre">a</span> <span class="pre">1d</span> <span class="pre">array</span> <span class="pre">was</span> <span class="pre">expected.</span> <span class="pre">Please</span> <span class="pre">change</span> <span class="pre">the</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">y</span> <span class="pre">to</span> <span class="pre">(n_samples,)</span></code>.</p>
<p>If <cite>y</cite> is a DataFrame, you can convert it to a Series using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert y to a Series if it&#39;s a DataFrame</span>
<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</pre></div>
</div>
<p>This conversion ensures that the target variable <cite>y</cite> has the correct shape, preventing the aforementioned warning.</p>
</div>
<section id="target-variable-shape-and-its-effects">
<h2>Target Variable Shape and Its Effects<a class="headerlink" href="#target-variable-shape-and-its-effects" title="Link to this heading"></a></h2>
<p>The target variable <span class="math notranslate nohighlight">\(y\)</span> should be passed as a 1-dimensional array (Series) and not as a 2-dimensional array (DataFrame).
If <span class="math notranslate nohighlight">\(y\)</span> is passed as a DataFrame, the model training process might raise the following warning:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>DataConversionWarning: A column-vector y was passed when a 1d array was expected.
Please change the shape of y to (n_samples,).
</pre></div>
</div>
<p><strong>Explanation:</strong></p>
<p>Machine learning models generally expect the target variable <span class="math notranslate nohighlight">\(y\)</span> to be in the shape of a 1-dimensional array,
denoted as <span class="math notranslate nohighlight">\(y = \{y_1, y_2, \dots, y_n\}\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is the number of samples.
Mathematically, <span class="math notranslate nohighlight">\(y\)</span> is represented as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}y = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}\end{split}\]</div>
<p>When <span class="math notranslate nohighlight">\(y\)</span> is passed as a DataFrame, it is treated as a 2-dimensional array, which has the form:</p>
<div class="math notranslate nohighlight">
\[y = \begin{pmatrix} y_1, y_2, \dots , y_n \end{pmatrix}\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[\begin{split}y = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}\end{split}\]</div>
<p>where each sample is represented as a column vector. This discrepancy in dimensionality can cause the model to misinterpret the data,
leading to the <code class="docutils literal notranslate"><span class="pre">DataConversionWarning</span></code>.</p>
</section>
<section id="solution">
<h2>Solution<a class="headerlink" href="#solution" title="Link to this heading"></a></h2>
<p>To ensure <span class="math notranslate nohighlight">\(y\)</span> is interpreted correctly as a 1-dimensional array, it should be passed as a Series.
If <span class="math notranslate nohighlight">\(y\)</span> is currently a DataFrame, you can convert it to a Series using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert y to a Series if it&#39;s a DataFrame</span>
<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</pre></div>
</div>
<p>The method <code class="code docutils literal notranslate"><span class="pre">squeeze()</span></code> effectively removes any unnecessary dimensions, converting a 2-dimensional DataFrame
with a single column into a 1-dimensional Series. This ensures that <span class="math notranslate nohighlight">\(y\)</span> has the correct shape, preventing
the aforementioned warning and ensuring the model processes the target variable correctly.</p>
</section>
</section>
<section id="imputation-before-scaling">
<h1>Imputation Before Scaling<a class="headerlink" href="#imputation-before-scaling" title="Link to this heading"></a></h1>
<p><strong>Ensuring Correct Data Preprocessing Order: Imputation Before Scaling</strong></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is crucial to apply imputation before scaling during the data preprocessing
pipeline to preserve the mathematical integrity of the transformations. The
correct sequence for the pipeline is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_steps</span> <span class="o">=</span> <span class="p">[</span>
   <span class="p">(</span><span class="s2">&quot;Preprocessor&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
   <span class="p">(</span><span class="s2">&quot;StandardScaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<section id="accurate-calculation-of-scaling-parameters">
<h2>1. Accurate Calculation of Scaling Parameters<a class="headerlink" href="#accurate-calculation-of-scaling-parameters" title="Link to this heading"></a></h2>
<p>Scaling methods, such as standardization or min-max scaling, rely on the calculation of statistical properties, such as the mean (<span class="math notranslate nohighlight">\(\mu\)</span>), standard deviation (<span class="math notranslate nohighlight">\(\sigma\)</span>), minimum (<span class="math notranslate nohighlight">\(x_{\min}\)</span>), and maximum (<span class="math notranslate nohighlight">\(x_{\max}\)</span>) of the dataset. These statistics are computed over the full set of available data. If missing values are present during this calculation, the resulting parameters will be incorrect, leading to improper scaling.</p>
<p>For example, in Z-score standardization, the transformation is defined as:</p>
<div class="math notranslate nohighlight">
\[z = \frac{x - \mu}{\sigma}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu = \frac{1}{N} \sum_{i=1}^{N} x_i\)</span> and <span class="math notranslate nohighlight">\(\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2}\)</span>, with <span class="math notranslate nohighlight">\(N\)</span> representing the number of data points. If missing values are not imputed first, both <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> will be computed based on incomplete data, resulting in inaccurate transformations for all values.</p>
<p>In contrast, if we impute the missing values first (e.g., by replacing them with the mean or median), the complete dataset is used for calculating these parameters. This ensures the scaling transformation is applied consistently across all data points.</p>
</section>
<section id="consistency-in-data-transformation">
<h2>2. Consistency in Data Transformation<a class="headerlink" href="#consistency-in-data-transformation" title="Link to this heading"></a></h2>
<p>Imputing missing values before scaling ensures that the transformation applied is consistent across the entire dataset, including previously missing values. For instance, consider a feature <span class="math notranslate nohighlight">\(X = [1, 2, \text{NaN}, 4, 5]\)</span>. If we impute the missing value using the mean (<span class="math notranslate nohighlight">\(\mu = \frac{1 + 2 + 4 + 5}{4} = 3\)</span>), the imputed dataset becomes:</p>
<div class="math notranslate nohighlight">
\[X_{\text{imputed}} = [1, 2, 3, 4, 5]\]</div>
<p>Now, applying standardization on the imputed dataset results in consistent Z-scores for each value, based on the correct parameters <span class="math notranslate nohighlight">\(\mu = 3\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1.58\)</span>.</p>
<p>Had scaling been applied first, without imputing, the calculated mean and standard deviation would be incorrect, leading to inconsistent transformations when imputation is subsequently applied. For example, if we calculated:</p>
<div class="math notranslate nohighlight">
\[z_{\text{incomplete}} = \frac{x - 3}{1.58} \quad \text{(based on non-imputed data)}\]</div>
<p>and later imputed the missing value, the transformed imputed value would not be aligned with the scaled distribution.</p>
</section>
<section id="prevention-of-distortion-in-scaling">
<h2>3. Prevention of Distortion in Scaling<a class="headerlink" href="#prevention-of-distortion-in-scaling" title="Link to this heading"></a></h2>
<p>Placeholder values used to represent missing data (e.g., large negative numbers like -999) can severely distort scaling transformations if not handled prior to scaling. In min-max scaling, the transformation is:</p>
<div class="math notranslate nohighlight">
\[x_{\text{scaled}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{\min}\)</span> and <span class="math notranslate nohighlight">\(x_{\max}\)</span> represent the minimum and maximum values of the feature. If a placeholder value like -999 is included, the range <span class="math notranslate nohighlight">\(x_{\max} - x_{\min}\)</span> will be artificially inflated, leading to a heavily skewed scaling of all values. For instance, the min-max scaling of <span class="math notranslate nohighlight">\(X = [1, 2, -999, 4, 5]\)</span> would produce extreme distortions due to the influence of -999 on <span class="math notranslate nohighlight">\(x_{\min}\)</span>.</p>
<p>By imputing missing values before scaling, we avoid these distortions, ensuring that the scaling operation reflects the true range of the data.</p>
</section>
</section>
<section id="column-stratification-with-cross-validation">
<h1>Column Stratification with Cross-Validation<a class="headerlink" href="#column-stratification-with-cross-validation" title="Link to this heading"></a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>Using</strong> <code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code> <strong>with Cross-Validation</strong></p>
<p>It is important to note that <code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code> cannot be used when performing cross-validation.
Cross-validation involves repeatedly splitting the dataset into training and validation sets to
evaluate the model’s performance across different subsets of the data.</p>
<p><strong>Explanation:</strong></p>
<p>When using cross-validation, the process automatically handles the stratification of the target variable <span class="math notranslate nohighlight">\(y\)</span>,
if specified. This ensures that each fold is representative of the overall distribution of <span class="math notranslate nohighlight">\(y\)</span>. However,
<code class="docutils literal notranslate"><span class="pre">stratify_cols</span></code> is designed to stratify based on specific columns in the feature set <span class="math notranslate nohighlight">\(X\)</span>, which can lead to
inconsistencies or even errors when applied in the context of cross-validation.</p>
<p>Since cross-validation inherently handles stratification based on the target variable, attempting to apply
additional stratification based on specific columns would conflict with the cross-validation process.
This can result in unpredictable behavior or failure of the cross-validation routine.</p>
<p>However, you can use <code class="docutils literal notranslate"><span class="pre">stratify_y</span></code> during cross-validation to ensure that each fold of the dataset is representative
of the distribution of the target variable <span class="math notranslate nohighlight">\(y\)</span>. This is a common practice to maintain consistency in the distribution
of the target variable across the different training and validation sets.</p>
</div>
<section id="cross-validation-and-stratification">
<h2>Cross-Validation and Stratification<a class="headerlink" href="#cross-validation-and-stratification" title="Link to this heading"></a></h2>
<p>Let <span class="math notranslate nohighlight">\(D = \{(X_i, y_i)\}_{i=1}^n\)</span> be the dataset with <span class="math notranslate nohighlight">\(n\)</span> samples, where <span class="math notranslate nohighlight">\(X_i\)</span> is the feature set and <span class="math notranslate nohighlight">\(y_i\)</span> is the target variable.</p>
<p>In <cite>k-fold</cite> cross-validation, the dataset <span class="math notranslate nohighlight">\(D\)</span> is split into <span class="math notranslate nohighlight">\(k\)</span> folds <span class="math notranslate nohighlight">\(\{D_1, D_2, \dots, D_k\}\)</span>.</p>
<p>When stratifying by <span class="math notranslate nohighlight">\(y\)</span> using <code class="code docutils literal notranslate"><span class="pre">stratify_y</span></code>, each fold <span class="math notranslate nohighlight">\(D_j\)</span> is constructed such that the distribution of <span class="math notranslate nohighlight">\(y\)</span> in each fold is similar to the distribution of <span class="math notranslate nohighlight">\(y\)</span> in <span class="math notranslate nohighlight">\(D\)</span>.</p>
<p>Mathematically, if <span class="math notranslate nohighlight">\(P(y=c)\)</span> is the probability of the target variable <span class="math notranslate nohighlight">\(y\)</span> taking on class <span class="math notranslate nohighlight">\(c\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[P(y=c \mid D_j) \approx P(y=c \mid D)\]</div>
<p>for all folds <span class="math notranslate nohighlight">\(D_j\)</span> and all classes <span class="math notranslate nohighlight">\(c\)</span>.</p>
<p>This ensures that the stratified folds preserve the same class proportions as the original dataset.</p>
<p>On the other hand, <code class="code docutils literal notranslate"><span class="pre">stratify_cols</span></code> stratifies based on specific columns of <span class="math notranslate nohighlight">\(X\)</span>. However, in cross-validation, the primary focus is on the target variable <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Attempting to stratify based on <span class="math notranslate nohighlight">\(X\)</span> columns during cross-validation can disrupt the process of ensuring a representative sample of <span class="math notranslate nohighlight">\(y\)</span> in each fold. This can lead to unreliable performance estimates and, in some cases, errors.</p>
<p>Therefore, the use of <code class="code docutils literal notranslate"><span class="pre">stratify_y</span></code> is recommended during cross-validation to maintain consistency in the target variable distribution across folds, while <code class="code docutils literal notranslate"><span class="pre">stratify_cols</span></code> should be avoided.</p>
<section id="model-calibration">
<h3>Model Calibration<a class="headerlink" href="#model-calibration" title="Link to this heading"></a></h3>
<p>Model calibration refers to the process of adjusting the predicted probabilities of a model so that they more accurately reflect the true likelihood of outcomes. This is crucial in machine learning, particularly for classification problems where the model outputs probabilities rather than just class labels.</p>
</section>
</section>
</section>
<section id="goal-of-calibration">
<h1>Goal of Calibration<a class="headerlink" href="#goal-of-calibration" title="Link to this heading"></a></h1>
<p>The goal of calibration is to ensure that the predicted probability <span class="math notranslate nohighlight">\(\hat{p}(x)\)</span> is equal to the true probability that <span class="math notranslate nohighlight">\(y = 1\)</span> given <span class="math notranslate nohighlight">\(x\)</span>. Mathematically, this can be expressed as:</p>
<div class="math notranslate nohighlight">
\[\hat{p}(x) = P(y = 1 \mid \hat{p}(x) = p)\]</div>
<p>This equation states that for all instances where the model predicts a probability <span class="math notranslate nohighlight">\(p\)</span>, the true fraction of positive cases should also be <span class="math notranslate nohighlight">\(p\)</span>.</p>
</section>
<section id="calibration-curve">
<h1>Calibration Curve<a class="headerlink" href="#calibration-curve" title="Link to this heading"></a></h1>
<p>To assess calibration, we often use a <em>calibration curve</em>. This involves:</p>
<ol class="arabic simple">
<li><p><strong>Binning</strong> the predicted probabilities <span class="math notranslate nohighlight">\(\hat{p}(x)\)</span> into intervals (e.g., [0.0, 0.1), [0.1, 0.2), …, [0.9, 1.0]).</p></li>
<li><p><strong>Calculating the mean predicted probability</strong> <span class="math notranslate nohighlight">\(\hat{p}_i\)</span> for each bin <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p><strong>Calculating the empirical frequency</strong> <span class="math notranslate nohighlight">\(f_i\)</span> (the fraction of positives) in each bin.</p></li>
</ol>
<p>For a perfectly calibrated model:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_i = f_i \quad \text{for all bins } i\]</div>
</section>
<section id="brier-score">
<h1>Brier Score<a class="headerlink" href="#brier-score" title="Link to this heading"></a></h1>
<p>The <strong>Brier score</strong> is one way to measure the calibration of a model. It’s calculated as:</p>
<div class="math notranslate nohighlight">
\[\text{Brier Score} = \frac{1}{N} \sum_{i=1}^{N} (\hat{p}(x_i) - y_i)^2\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N\)</span> is the number of instances.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{p}(x_i)\)</span> is the predicted probability for instance <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> is the actual label for instance <span class="math notranslate nohighlight">\(i\)</span> (0 or 1).</p></li>
</ul>
<p>The Brier score penalizes predictions that are far from the true outcome. A lower Brier score indicates better calibration and accuracy.</p>
</section>
<section id="platt-scaling">
<h1>Platt Scaling<a class="headerlink" href="#platt-scaling" title="Link to this heading"></a></h1>
<p>One common method to calibrate a model is <strong>Platt Scaling</strong>. This involves fitting a logistic regression model to the predictions of the original model. The logistic regression model adjusts the raw predictions <span class="math notranslate nohighlight">\(\hat{p}(x)\)</span> to output calibrated probabilities.</p>
<p>Mathematically, Platt scaling is expressed as:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_{\text{calibrated}}(x) = \frac{1}{1 + \exp(-(A \hat{p}(x) + B))}\]</div>
<p>Where <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are parameters learned from the data. These parameters adjust the original probability estimates to better align with the true probabilities.</p>
</section>
<section id="isotonic-regression">
<h1>Isotonic Regression<a class="headerlink" href="#isotonic-regression" title="Link to this heading"></a></h1>
<p>Another method is <strong>Isotonic Regression</strong>, a non-parametric approach that fits a piecewise constant function. Unlike Platt Scaling, which assumes a logistic function, Isotonic Regression only assumes that the function is monotonically increasing. The goal is to find a set of probabilities <span class="math notranslate nohighlight">\(p_i\)</span> that are as close as possible to the true probabilities while maintaining a monotonic relationship.</p>
<p>The isotonic regression problem can be formulated as:</p>
<div class="math notranslate nohighlight">
\[\min_{p_1 \leq p_2 \leq \dots \leq p_n} \sum_{i=1}^{n} (p_i - y_i)^2\]</div>
<p>Where <span class="math notranslate nohighlight">\(p_i\)</span> are the adjusted probabilities, and the constraint ensures that the probabilities are non-decreasing.</p>
</section>
<section id="example-calibration-in-logistic-regression">
<h1>Example: Calibration in Logistic Regression<a class="headerlink" href="#example-calibration-in-logistic-regression" title="Link to this heading"></a></h1>
<p>In a standard logistic regression model, the predicted probability is given by:</p>
<div class="math notranslate nohighlight">
\[\hat{p}(x) = \sigma(w^\top x) = \frac{1}{1 + \exp(-w^\top x)}\]</div>
<p>Where <span class="math notranslate nohighlight">\(w\)</span> is the vector of weights, and <span class="math notranslate nohighlight">\(x\)</span> is the input feature vector.</p>
<p>If this model is well-calibrated, <span class="math notranslate nohighlight">\(\hat{p}(x)\)</span> should closely match the true conditional probability <span class="math notranslate nohighlight">\(P(y = 1 \mid x)\)</span>. If not, techniques like Platt Scaling or Isotonic Regression can be applied to adjust <span class="math notranslate nohighlight">\(\hat{p}(x)\)</span> to be more accurate.</p>
</section>
<section id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><strong>Model calibration</strong> is about aligning predicted probabilities with actual outcomes.</p></li>
<li><p><strong>Mathematically</strong>, calibration ensures <span class="math notranslate nohighlight">\(\hat{p}(x) = P(y = 1 \mid \hat{p}(x) = p)\)</span>.</p></li>
<li><p><strong>Platt Scaling</strong> and <strong>Isotonic Regression</strong> are two common methods to achieve calibration.</p></li>
<li><p><strong>Brier Score</strong> is a metric that captures both the calibration and accuracy of probabilistic predictions.</p></li>
</ul>
<p>Calibration is essential when the probabilities output by a model need to be trusted, such as in risk assessment, medical diagnosis, and other critical applications.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage_guide.html" class="btn btn-neutral float-left" title="iPython Notebooks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="about.html" class="btn btn-neutral float-right" title="GitHub Repository" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, UCLA CTSI ML Team: Leonid Shpaner, Arthur Funnell, Panayiotis Petousis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>