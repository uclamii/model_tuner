{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model_tuner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1.post1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the California housing dataset\n",
    "# california_housing = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = california_housing[\"frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris = pd.DataFrame(\n",
    "    data=np.c_[iris[\"data\"], iris[\"target\"]],\n",
    "    columns=iris[\"feature_names\"] + [\"target\"],\n",
    ")\n",
    "features = [col for col in iris.columns if col != \"target\"]\n",
    "target = \"target\"\n",
    "\n",
    "X = iris[features].values  # independant variables\n",
    "y = iris[target].values.astype(int)  # dependent variable\n",
    "\n",
    "# breast_sk = load_breast_cancer()\n",
    "# breast = pd.DataFrame(\n",
    "#     data=np.c_[breast_sk.data, breast_sk.target],\n",
    "# )\n",
    "# breast.columns = list(breast_sk.feature_names) + [\"target\"]\n",
    "# features = [col for col in breast.columns if col != \"target\"]\n",
    "# target = \"target\"\n",
    "\n",
    "# X = breast[features].values  # independant variables\n",
    "# y = breast[target].values.astype(int)  # dependent variable\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\", C=1, max_iter=1000)\n",
    "\n",
    "estimator_name = \"lr\"\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{estimator_name + \"__C\": np.logspace(-4, 0, 10)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc_ovr\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END .......................................lr__C=0.0001; total time=   0.0s\n",
      "[CV] END .......................................lr__C=0.0001; total time=   0.0s\n",
      "[CV] END ........................lr__C=0.0002782559402207126; total time=   0.0s\n",
      "[CV] END ........................lr__C=0.0002782559402207126; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.000774263682681127; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.000774263682681127; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.002154434690031882; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.002154434690031882; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.005994842503189409; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.005994842503189409; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.016681005372000592; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.016681005372000592; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.046415888336127774; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.046415888336127774; total time=   0.0s\n",
      "[CV] END ..........................lr__C=0.12915496650148828; total time=   0.0s\n",
      "[CV] END ..........................lr__C=0.12915496650148828; total time=   0.0s\n",
      "[CV] END ...........................lr__C=0.3593813663804626; total time=   0.0s\n",
      "[CV] END ...........................lr__C=0.3593813663804626; total time=   0.0s\n",
      "[CV] END ..........................................lr__C=1.0; total time=   0.0s\n",
      "[CV] END ..........................................lr__C=1.0; total time=   0.0s\n",
      "\n",
      "Best score/param set found on development set:\n",
      "{0.9822666666666666: {'lr__C': 1.0}}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.848 (+/-0.013) for {'lr__C': 0.0001}\n",
      "0.848 (+/-0.012) for {'lr__C': 0.0002782559402207126}\n",
      "0.848 (+/-0.011) for {'lr__C': 0.000774263682681127}\n",
      "0.850 (+/-0.012) for {'lr__C': 0.002154434690031882}\n",
      "0.853 (+/-0.012) for {'lr__C': 0.005994842503189409}\n",
      "0.870 (+/-0.014) for {'lr__C': 0.016681005372000592}\n",
      "0.916 (+/-0.003) for {'lr__C': 0.046415888336127774}\n",
      "0.959 (+/-0.001) for {'lr__C': 0.12915496650148828}\n",
      "0.975 (+/-0.007) for {'lr__C': 0.3593813663804626}\n",
      "0.982 (+/-0.011) for {'lr__C': 1.0}\n",
      "\n",
      "Detailed classification report for Iris_model:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "# Tuning hyper-parameters for precision_macro\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END .......................................lr__C=0.0001; total time=   0.0s\n",
      "[CV] END .......................................lr__C=0.0001; total time=   0.0s\n",
      "[CV] END ........................lr__C=0.0002782559402207126; total time=   0.0s\n",
      "[CV] END ........................lr__C=0.0002782559402207126; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.000774263682681127; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.000774263682681127; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.002154434690031882; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.002154434690031882; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.005994842503189409; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.005994842503189409; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.016681005372000592; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.016681005372000592; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.046415888336127774; total time=   0.0s\n",
      "[CV] END .........................lr__C=0.046415888336127774; total time=   0.0s\n",
      "[CV] END ..........................lr__C=0.12915496650148828; total time=   0.0s\n",
      "[CV] END ..........................lr__C=0.12915496650148828; total time=   0.0s\n",
      "[CV] END ...........................lr__C=0.3593813663804626; total time=   0.0s\n",
      "[CV] END ...........................lr__C=0.3593813663804626; total time=   0.0s\n",
      "[CV] END ..........................................lr__C=1.0; total time=   0.0s\n",
      "[CV] END ..........................................lr__C=1.0; total time=   0.0s\n",
      "\n",
      "Best score/param set found on development set:\n",
      "{0.9216317767042406: {'lr__C': 1.0}}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.851 (+/-0.002) for {'lr__C': 0.0001}\n",
      "0.849 (+/-0.003) for {'lr__C': 0.0002782559402207126}\n",
      "0.849 (+/-0.003) for {'lr__C': 0.000774263682681127}\n",
      "0.851 (+/-0.002) for {'lr__C': 0.002154434690031882}\n",
      "0.836 (+/-0.033) for {'lr__C': 0.005994842503189409}\n",
      "0.845 (+/-0.034) for {'lr__C': 0.016681005372000592}\n",
      "0.877 (+/-0.007) for {'lr__C': 0.046415888336127774}\n",
      "0.881 (+/-0.016) for {'lr__C': 0.12915496650148828}\n",
      "0.903 (+/-0.028) for {'lr__C': 0.3593813663804626}\n",
      "0.922 (+/-0.054) for {'lr__C': 1.0}\n",
      "\n",
      "Detailed classification report for Iris_model:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = True\n",
    "calibrate = True\n",
    "\n",
    "model = Model(\n",
    "    name=\"Iris_model\",\n",
    "    estimator_name=estimator_name,\n",
    "    calibrate=calibrate,\n",
    "    estimator=lr,\n",
    "    kfold=kfold,\n",
    "    stratify=True,\n",
    "    grid=tuned_parameters,\n",
    "    randomized_grid=False,\n",
    "    n_iter=3,\n",
    "    scoring=[\"roc_auc_ovr\", \"precision_macro\"],\n",
    "    n_splits=2,\n",
    "    random_state=3,\n",
    ")\n",
    "\n",
    "model.grid_search_param_tuning(X, y)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97893333 0.96666667] [0.95786667 0.97893333]\n",
      "\n",
      "0 Fold: \n",
      "Feature: sepal width (cm), Score: 0.66715\n",
      "Feature: sepal length (cm), Score: -0.95095\n",
      "Feature: petal width (cm), Score: -1.34057\n",
      "Feature: petal length (cm), Score: -1.65491\n",
      "\n",
      "1 Fold: \n",
      "Feature: sepal width (cm), Score: 0.85867\n",
      "Feature: sepal length (cm), Score: -0.94016\n",
      "Feature: petal width (cm), Score: -1.49184\n",
      "Feature: petal length (cm), Score: -1.54397\n"
     ]
    }
   ],
   "source": [
    "if model.calibrate:\n",
    "    model.calibrateModel(X, y)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if kfold:\n",
    "    print(model.xval_output[\"train_score\"], model.xval_output[\"test_score\"])\n",
    "    for i in range(len(model.xval_output[\"estimator\"])):\n",
    "        print(\"\\n\" + str(i) + \" Fold: \")\n",
    "        if calibrate:\n",
    "            importance = (\n",
    "                model.xval_output[\"estimator\"][i]\n",
    "                .calibrated_classifiers_[i]\n",
    "                .estimator.steps[1][1]\n",
    "                .coef_[0]\n",
    "            )\n",
    "        else:\n",
    "            importance = model.xval_output[\"estimator\"][i].steps[1][1].coef_[0]\n",
    "\n",
    "        sort_imp_indx = np.argsort(importance)[::-1]\n",
    "        # print(importance)\n",
    "        # print(sort_imp_indx)\n",
    "        for i in sort_imp_indx:\n",
    "            print(\"Feature: %s, Score: %.5f\" % (features[i], importance[i]))\n",
    "else:\n",
    "    if calibrate:\n",
    "        importance = model.estimator.estimator.steps[1][1].coef_[0]\n",
    "    else:\n",
    "        importance = model.estimator.steps[1][1].coef_[0]\n",
    "    sort_imp_indx = np.argsort(importance)[::-1]\n",
    "    # print(importance)\n",
    "    # print(sort_imp_indx)\n",
    "    # summarize feature importance\n",
    "    for i in sort_imp_indx:\n",
    "        print(\"Feature: %s, Score: %.5f\" % (features[i], importance[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_tuner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
