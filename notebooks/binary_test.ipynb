{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from model_tuner.model_tuner_utils import Model\n",
    "from model_tuner.bootstrapper import evaluate_bootstrap_metrics\n",
    "from model_tuner.pickleObjects import dumpObjects, loadObjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = load_breast_cancer(as_frame=True)[\"frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_cols = [cols for cols in bc.columns if \"target\" not in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bc[bc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bc[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "\n",
    "estimator_name = \"lg\"\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        estimator_name + \"__C\": np.logspace(-4, 0, 3),\n",
    "        \"selectKBest__k\": [5, 10, 11, 12, 13, 8, 6, 9, 20],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = False\n",
    "calibrate = False\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Model(\n",
    "    name=\"Logistic Regression\",\n",
    "    estimator_name=estimator_name,\n",
    "    calibrate=calibrate,\n",
    "    estimator=lr,\n",
    "    kfold=kfold,\n",
    "    stratify_y=True,\n",
    "    stratify_cols=[\"mean radius\"],\n",
    "    grid=tuned_parameters,\n",
    "    randomized_grid=True,\n",
    "    n_iter=40,\n",
    "    scoring=[\"roc_auc\"],\n",
    "    n_splits=10,\n",
    "    selectKBest=True,\n",
    "    n_jobs=-2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "model.grid_search_param_tuning(X, y)\n",
    "\n",
    "X_train, y_train = model.get_train_data(X, y)\n",
    "X_test, y_test = model.get_test_data(X, y)\n",
    "X_valid, y_valid = model.get_valid_data(X, y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Validation Metrics\")\n",
    "model.return_metrics(X_valid, y_valid)\n",
    "print(\"Test Metrics\")\n",
    "model.return_metrics(X_test, y_test)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "### F1 Weighted\n",
    "y_pred = model.predict(X_test, optimal_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = y_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(y_prob, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bootstrap_metrics(y=y_test, y_pred_prob=y_prob, n_samples=2, num_resamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "estimator = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "\n",
    "estimator_name = \"xgb\"\n",
    "xgbearly = True\n",
    "\n",
    "tuned_parameters = {\n",
    "    f\"{estimator_name}__max_depth\": [3],\n",
    "    f\"{estimator_name}__learning_rate\": [1e-4],\n",
    "    f\"{estimator_name}__n_estimators\": [100000],\n",
    "    f\"{estimator_name}__early_stopping_rounds\": [2],\n",
    "    f\"{estimator_name}__verbose\": [True],\n",
    "    f\"{estimator_name}__eval_metric\": [\"logloss\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = False\n",
    "calibrate = False\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Model(\n",
    "    name=\"XGBoost Early\",\n",
    "    estimator_name=estimator_name,\n",
    "    calibrate=calibrate,\n",
    "    estimator=estimator,\n",
    "    kfold=kfold,\n",
    "    stratify_y=True,\n",
    "    grid=tuned_parameters,\n",
    "    randomized_grid=True,\n",
    "    n_iter=1,\n",
    "    xgboost_early=True,\n",
    "    scoring=[\"roc_auc\"],\n",
    "    n_splits=10,\n",
    "    selectKBest=False,\n",
    "    n_jobs=-2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "model.grid_search_param_tuning(X, y)\n",
    "\n",
    "X_train, y_train = model.get_train_data(X, y)\n",
    "X_test, y_test = model.get_test_data(X, y)\n",
    "X_valid, y_valid = model.get_valid_data(X, y)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=[X_valid, y_valid])\n",
    "\n",
    "print(\"Validation Metrics\")\n",
    "model.return_metrics(X_valid, y_valid)\n",
    "print(\"Test Metrics\")\n",
    "model.return_metrics(X_test, y_test)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "### F1 Weighted\n",
    "y_pred = model.predict(X_test, optimal_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_per_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_tuner import Model\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head()\n",
    "\n",
    "X = titanic[[col for col in titanic.columns if col != \"survived\"]]\n",
    "### Removing repeated data\n",
    "X = X.drop(columns=[\"alive\", \"class\", \"embarked\"])\n",
    "y = titanic[\"survived\"]\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "estimator_name = \"rf\"\n",
    "\n",
    "tuned_parameters = {\n",
    "    f\"{estimator_name}__max_depth\": [3, 5, 10, None],\n",
    "    f\"{estimator_name}__n_estimators\": [10, 100, 200],\n",
    "    f\"{estimator_name}__max_features\": [1, 3, 5, 7],\n",
    "    f\"{estimator_name}__min_samples_leaf\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "X.head()\n",
    "\n",
    "### Defining columns to be scaled and columns to be onehotencoded\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ohencoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "ohcols = [\"parch\", \"embark_town\", \"who\", \"sex\", \"adult_male\"]\n",
    "\n",
    "ordencoder = OrdinalEncoder()\n",
    "\n",
    "ordcols = [\"deck\"]\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "\n",
    "scalercols = [\"fare\", \"age\", \"pclass\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", ohencoder, ohcols),\n",
    "        (\"OrdinalEncoder\", ordencoder, ordcols),\n",
    "        (\"MinMaxScaler\", minmaxscaler, scalercols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Initialize ModelTuner\n",
    "ModelTuner = Model(\n",
    "    name=\"RandomForest_Titanic\",\n",
    "    estimator_name=estimator_name,\n",
    "    calibrate=True,\n",
    "    estimator=rf,\n",
    "    kfold=True,\n",
    "    impute=True,\n",
    "    pipeline_steps=[(\"ColumnTransformer\", ct)],\n",
    "    stratify_y=False,\n",
    "    n_splits=10,\n",
    "    grid=tuned_parameters,\n",
    "    randomized_grid=True,\n",
    "    n_iter=1,\n",
    "    scoring=[\"roc_auc\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelTuner.grid_search_param_tuning(X, y, f1_beta_tune=True)\n",
    "\n",
    "ModelTuner.return_metrics(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
